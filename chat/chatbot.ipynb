{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ce73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.get_default_device() 함수가 없다고 떠서 대체 함수 정의\n",
    "\n",
    "\n",
    "def _get_default_device():\n",
    "    \"\"\"torch.get_default_device() 대체 함수\"\"\"\n",
    "\n",
    "    # gpu가 있으면 cuda 디바이스로 반환\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # apple m1,m2 칩이 있으면 mps 디바이스로 반환\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    # 그 외는 cpu 디바이스로 반환\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617dbce",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898ce71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "chatnge_ai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_teddynote import logging\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"chatnge_ai\")\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0435c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer 임포트 전에 환경 설정\n",
    "\n",
    "# transformers 라이브러리가 온라인 모드로 동작하도록 설정\n",
    "## 모델 다운로드 설정\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "# KLUE/BERT 모델 사용하기 위해 Hugging Face 모델 접근할 수 있도록 설정\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b638caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformers 라이브러리 로드 완료\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel, logging as transformers_logging\n",
    "\n",
    "    transformers_logging.set_verbosity_error()  # 경고 메시지 최소화\n",
    "    print(\"✅ Transformers 라이브러리 로드 완료\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Transformers 라이브러리 임포트 실패: {e}\")\n",
    "    print(\"pip install transformers를 실행해주세요.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torch에 없는 함수 추가\n",
    "torch.get_default_device = _get_default_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707289",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 불용어 리스트\n",
    "KOREAN_STOPWORDS = [\n",
    "    \"이\",\n",
    "    \"그\",\n",
    "    \"저\",\n",
    "    \"것\",\n",
    "    \"및\",\n",
    "    \"에\",\n",
    "    \"를\",\n",
    "    \"은\",\n",
    "    \"는\",\n",
    "    \"이런\",\n",
    "    \"저런\",\n",
    "    \"그런\",\n",
    "    \"한\",\n",
    "    \"이르\",\n",
    "    \"또한\",\n",
    "    \"있\",\n",
    "    \"하\",\n",
    "    \"에서\",\n",
    "    \"으로\",\n",
    "    \"으로써\",\n",
    "    \"로써\",\n",
    "    \"로서\",\n",
    "    \"로\",\n",
    "    \"와\",\n",
    "    \"과\",\n",
    "    \"이고\",\n",
    "    \"이며\",\n",
    "    \"이다\",\n",
    "    \"있다\",\n",
    "    \"하다\",\n",
    "    \"되다\",\n",
    "    \"이\",\n",
    "    \"가\",\n",
    "    \"을\",\n",
    "    \"를\",\n",
    "    \"에게\",\n",
    "    \"의\",\n",
    "    \"뿐\",\n",
    "    \"다\",\n",
    "    \"적\",\n",
    "    \"데\",\n",
    "    \"때\",\n",
    "    \"나\",\n",
    "    \"도\",\n",
    "    \"만\",\n",
    "    \"께\",\n",
    "    \"에게서\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6f6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 텍스트 전처리\n",
    "def preprocess_korean_text(text):\n",
    "    # 만약에 텍스트가 없으면 그냥 빈칸 반환\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # 반복 문자 정규화\n",
    "    text = re.sub(r\"[^가-힣a-zA-Z0-9\\s\\.,!?]\", \" \", text)  # 특수문자 제거\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 공백 정리\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stopwords=KOREAN_STOPWORDS):\n",
    "    \"\"\"주어진 텍스트에서 불용어 제거\"\"\"\n",
    "    # 아무것도 없으면 그냥 반환\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95013df4",
   "metadata": {},
   "source": [
    "## 감정 분류기 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(torch.nn.Module):\n",
    "    \"\"\"감정 분류기 모델 - BERT 기반의 감정 분류를 위한 신경망 모델\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model, num_classes, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        모델 초기화\n",
    "\n",
    "        Args:\n",
    "            bert_model: 사전 훈련된 BERT 모델 (예: BertModel)\n",
    "            num_classes: 분류할 감정 클래스의 개수\n",
    "            dropout_rate: 드롭아웃 비율 (기본값: 0.3)\n",
    "        \"\"\"\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "\n",
    "        # BERT 모델을 백본으로 사용\n",
    "        self.bert = bert_model\n",
    "        # BERT의 히든 사이즈 (일반적으로 768)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # 과적합 방지를 위한 드롭아웃 레이어\n",
    "        self.dropout1 = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 어텐션 메커니즘: 각 토큰의 중요도를 계산\n",
    "        self.attention = torch.nn.Sequential(\n",
    "            # 히든 사이즈를 256차원으로 축소\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # Tanh 활성화 함수로 비선형성 추가\n",
    "            torch.nn.Tanh(),\n",
    "            # 256차원을 1차원으로 축소하여 어텐션 스코어 생성\n",
    "            torch.nn.Linear(256, 1),\n",
    "            # Softmax로 어텐션 가중치를 정규화 (합이 1이 되도록)\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        # 최종 분류를 위한 분류기\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # 히든 사이즈를 256차원으로 축소\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # ReLU 활성화 함수\n",
    "            torch.nn.ReLU(),\n",
    "            # 배치 정규화로 학습 안정성 향상\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            # 드롭아웃으로 과적합 방지\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            # 최종 감정 클래스 개수만큼 출력\n",
    "            torch.nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            input_ids: 토크나이징된 입력 텍스트의 ID\n",
    "            attention_mask: 패딩 토큰을 무시하기 위한 마스크\n",
    "            token_type_ids: 문장 구분을 위한 토큰 타입 ID\n",
    "\n",
    "        Returns:\n",
    "            logits: 각 감정 클래스에 대한 점수\n",
    "        \"\"\"\n",
    "        # BERT 모델에 입력을 통과시켜 임베딩 생성\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True,  # 딕셔너리 형태로 결과 반환\n",
    "        )\n",
    "\n",
    "        # 모든 토큰의 히든 상태 (배치 크기, 시퀀스 길이, 히든 크기)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        # [CLS] 토큰의 풀링된 표현 (배치 크기, 히든 크기)\n",
    "        pooled_output = outputs.pooler_output\n",
    "\n",
    "        # 어텐션 가중치 계산: 각 토큰의 중요도 결정\n",
    "        attention_weights = self.attention(sequence_output)\n",
    "\n",
    "        # 가중합을 통해 컨텍스트 벡터 생성\n",
    "        # attention_weights와 sequence_output을 곱하고 시퀀스 차원을 따라 합산\n",
    "        context_vector = torch.sum(attention_weights * sequence_output, dim=1)\n",
    "\n",
    "        # 어텐션 기반 컨텍스트 벡터와 BERT의 풀링 출력을 결합\n",
    "        # 두 표현을 더해서 더 풍부한 표현 생성\n",
    "        final_output = context_vector + pooled_output\n",
    "\n",
    "        # 드롭아웃 적용하여 과적합 방지\n",
    "        final_output = self.dropout1(final_output)\n",
    "\n",
    "        # 분류기를 통과시켜 최종 로짓 계산\n",
    "        logits = self.classifier(final_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba10aed",
   "metadata": {},
   "source": [
    "## 계층적 감정 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7057fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalEmotionClassifier:\n",
    "    def __init__(self, model_dir):\n",
    "        self.model_dir = model_dir  # 모델 경로 설정\n",
    "        self.device = _get_default_device()  # 디바이스 설정\n",
    "        self.max_len = 128  # 최대 길이 설정\n",
    "\n",
    "        # 디버깅용\n",
    "        print(f\"모델 디렉토리: {self.model_dir}\")\n",
    "        print(f\"디바이스: {self.device}\")\n",
    "\n",
    "        # 변수 초기화\n",
    "        self.tokenizer = None\n",
    "        self.bert_model = None\n",
    "        self.level1_model = None\n",
    "        self.level2_model = None\n",
    "        self.level3_model = None\n",
    "        self.level1_labels = None\n",
    "        self.level2_labels = None\n",
    "        self.level3_labels = None\n",
    "\n",
    "        # 모델 로드\n",
    "        self._load_models()\n",
    "\n",
    "    def _check_files(self):\n",
    "        print(\"1단계 : 파일 확인\")\n",
    "        # 필수 파일들 정의\n",
    "        required_files = [\n",
    "            \"level1_best_model.pt\",\n",
    "            \"level2_best_model.pt\",\n",
    "            \"level3_best_model.pt\",\n",
    "            \"level1_label_encoder.pkl\",\n",
    "            \"level2_label_encoder.pkl\",\n",
    "            \"level3_label_encoder.pkl\",\n",
    "        ]\n",
    "\n",
    "        # 없는 파일 확인 리스트\n",
    "        missing_files = []\n",
    "\n",
    "        for file in required_files:\n",
    "            filepath = os.path.join(self.model_dir, file)\n",
    "            if not os.path.exists(filepath):\n",
    "                missing_files.append(file)\n",
    "            else:\n",
    "                print(f\"✅ {file} 파일이 존재합니다.\")\n",
    "\n",
    "        # 만약에 누락된 파일이 있으면 예외 발생\n",
    "        if missing_files:\n",
    "            raise FileExistsError(f\"파일 누락 목록:{missing_files}\")\n",
    "\n",
    "    # 라벨 인코터 로드\n",
    "    def _load_label_encoders(self):\n",
    "        print(\"2단계: 라벨 인코더 로드\")\n",
    "\n",
    "        encoders = [\n",
    "            (\"level1_label_encoder.pkl\", \"level1_encoder\"),\n",
    "            (\"level2_label_encoder.pkl\", \"level2_encoder\"),\n",
    "            (\"level3_label_encoder.pkl\", \"level3_encoder\"),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name in encoders:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                encoder = pickle.load(f)\n",
    "                setattr(self, attr_name, encoder)\n",
    "            print(f\"{filename} 파일에서 {attr_name} 로드 완료\")\n",
    "\n",
    "    # 3단계 bert 모델 로드\n",
    "    def _load_bert_model(self):\n",
    "\n",
    "        try:\n",
    "            print(\"3단계: BERT 모델 로드\")\n",
    "            # BERT 모델과 토크나이저 로드\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "            self.bert_model = AutoModel.from_pretrained(\"klue/bert-base\")\n",
    "\n",
    "            # 디바이스 이동\n",
    "            self.bert_model = self.bert_model.to(self.device)\n",
    "            print(\"BERT 모델과 토크나이저 로드 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ BERT 모델 로드 실패: {e}\")\n",
    "            raise ImportError(\n",
    "                \"BERT 모델을 로드하는 데 실패했습니다. 'transformers' 라이브러리가 설치되어 있는지 확인하세요.\"\n",
    "            )\n",
    "\n",
    "    def _load_emotion_models(self):\n",
    "        \"\"\"감정 분류 모델들 로드\"\"\"\n",
    "        print(\"😊 감정 분류 모델 로드 중...\")\n",
    "\n",
    "        models = [\n",
    "            (\"level1_best_model.pt\", \"level1_model\", self.level1_encoder),\n",
    "            (\"level2_best_model.pt\", \"level2_model\", self.level2_encoder),\n",
    "            (\"level3_best_model.pt\", \"level3_model\", self.level3_encoder),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name, encoder in models:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "\n",
    "            print(f\"  🔄 {filename} 로드 중...\")\n",
    "\n",
    "            # 모델 초기화\n",
    "            model = EmotionClassifier(\n",
    "                copy.deepcopy(self.bert_model.to(\"cpu\")), len(encoder.classes_)\n",
    "            )\n",
    "\n",
    "            # 가중치 로드\n",
    "            try:\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n",
    "            except TypeError:  # 구버전 PyTorch\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\")\n",
    "\n",
    "            model.load_state_dict(state_dict)\n",
    "\n",
    "            # 디바이스 이동 및 평가 모드\n",
    "            model = model.to(self.device)\n",
    "            model.eval()\n",
    "\n",
    "            setattr(self, attr_name, model)\n",
    "            print(f\"  ✅ {filename} 로드 완료\")\n",
    "\n",
    "    def _load_models(self):\n",
    "        \"\"\"모든 모델 로드\"\"\"\n",
    "        try:\n",
    "            # 1단계 : 파일 존재 확인\n",
    "            self._check_files()\n",
    "\n",
    "            # 2단계 : 라벨 인코더 로드\n",
    "            self._load_label_encoders()\n",
    "\n",
    "            # 3단계\n",
    "            self._load_bert_model()\n",
    "\n",
    "            # 4단계\n",
    "            self._load_emotion_models()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 모델 로드 중 오류 발생: {e}\")\n",
    "            raise\n",
    "\n",
    "    # 단일 모델 분류\n",
    "    def _predict_single(self, model, text):\n",
    "        # 전처리\n",
    "        preprocessed = preprocess_korean_text(text)\n",
    "        preprocessed = remove_stopwords(preprocessed)\n",
    "\n",
    "        # 토큰화\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            preprocessed,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # 디바이스 이동\n",
    "        input_ids = encoding[\"input_ids\"].to(self.device)\n",
    "        attention_mask = encoding[\"attention_mask\"].to(self.device)\n",
    "        token_type_ids = encoding[\"token_type_ids\"].to(self.device)\n",
    "\n",
    "        # 예측\n",
    "        with torch.no_grad():  # 그래디어언트 계산 비활성화 : 메모리 절약 + 속도 향상\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)  # 로짓 출력\n",
    "            probs = torch.nn.functional.softmax(\n",
    "                outputs, dim=1\n",
    "            )  # 확률 변환, 각 클래스별 확률값\n",
    "            _, preds = torch.max(outputs, dim=1)  # 가장 높은 확률을 가진 클래스 선택\n",
    "\n",
    "        return preds.item(), probs[0]\n",
    "\n",
    "    # 계층적 감정 분류\n",
    "    def predict_hierarchical(self, text):\n",
    "        \"\"\"계층적 예측\"\"\"\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"levels\": {},\n",
    "        }\n",
    "\n",
    "        # 1단계\n",
    "        pred1, probs1 = self._predict_single(self.level1_model, text)\n",
    "        label1 = self.level1_encoder.inverse_transform([pred1])[0]\n",
    "\n",
    "        result[\"levels\"][\"level1\"] = {\n",
    "            \"step\": \"1단계: 일반대화 vs 감정\",\n",
    "            \"prediction\": label1,\n",
    "            \"confidence\": float(probs1[pred1]),\n",
    "            \"probabilities\": {\n",
    "                self.level1_encoder.classes_[i]: float(probs1[i])\n",
    "                for i in range(len(self.level1_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label1 == \"일반대화\":\n",
    "            result[\"final\"] = {\n",
    "                \"prediction\": \"일반대화\",\n",
    "                \"confidence\": float(probs1[pred1]),\n",
    "            }\n",
    "            result[\"path\"] = [\"일반대화\"]\n",
    "            return result\n",
    "\n",
    "        # 2단계\n",
    "        pred2, probs2 = self._predict_single(self.level2_model, text)\n",
    "        label2 = self.level2_encoder.inverse_transform([pred2])[0]\n",
    "\n",
    "        result[\"levels\"][\"level2\"] = {\n",
    "            \"step\": \"2단계: 기쁨 vs 기타감정\",\n",
    "            \"prediction\": label2,\n",
    "            \"confidence\": float(probs2[pred2]),\n",
    "            \"probabilities\": {\n",
    "                self.level2_encoder.classes_[i]: float(probs2[i])\n",
    "                for i in range(len(self.level2_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label2 == \"기쁨\":\n",
    "            result[\"final\"] = {\"prediction\": \"기쁨\", \"confidence\": float(probs2[pred2])}\n",
    "            result[\"path\"] = [\"감정\", \"기쁨\"]\n",
    "            return result\n",
    "\n",
    "        # 3단계\n",
    "        pred3, probs3 = self._predict_single(self.level3_model, text)\n",
    "        label3 = self.level3_encoder.inverse_transform([pred3])[0]\n",
    "\n",
    "        result[\"levels\"][\"level3\"] = {\n",
    "            \"step\": \"3단계: 세부 감정 분류\",\n",
    "            \"prediction\": label3,\n",
    "            \"confidence\": float(probs3[pred3]),\n",
    "            \"probabilities\": {\n",
    "                self.level3_encoder.classes_[i]: float(probs3[i])\n",
    "                for i in range(len(self.level3_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        result[\"final\"] = {\"prediction\": label3, \"confidence\": float(probs3[pred3])}\n",
    "        result[\"path\"] = [\"감정\", \"기타감정\", label3]\n",
    "\n",
    "        return result\n",
    "    \n",
    "    #임계값 이상의 모든 감정들을 반환\n",
    "    def predict_with_threshold_emotion(self,text,threshold=0.3):\n",
    "        result={\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"detected_emotions\": [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccf1d9",
   "metadata": {},
   "source": [
    "## 챗봇 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a362c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "class EmotionChatbot:\n",
    "    def __init__(self, model_dir):\n",
    "        # 감정 분류기 초기화\n",
    "        self.classifier = HierarchicalEmotionClassifier(model_dir)\n",
    "        try:\n",
    "            # 챗봇 초기화\n",
    "            self.llm = ChatOpenAI(\n",
    "                model=\"gpt-4o\", temperature=0.4, max_tokens=1000, api_key=api_key\n",
    "            )\n",
    "\n",
    "            # 메모리 초기화\n",
    "            self.memory = ConversationSummaryBufferMemory(\n",
    "                llm=self.llm,\n",
    "                return_messages=True,\n",
    "                max_token_limit=2000,\n",
    "                memory_key=\"chat_history\",\n",
    "            )\n",
    "\n",
    "            # 프롬프트 로드\n",
    "            system_prompt = load_prompt(\"prompts/emcprompt3.yaml\", encoding=\"utf-8\")\n",
    "\n",
    "            self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", system_prompt.template),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.chain = self.chat_prompt | self.llm\n",
    "            print(\"챗봇 초기화 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"챗봇 초기화 중 오류 발생: {e}\")\n",
    "\n",
    "    def classify_emotion(self, text):\n",
    "        # 감정 분류\n",
    "        return self.classifier.predict_hierarchical(text)\n",
    "\n",
    "    # 감정 분석\n",
    "    def format_analysis(self, result):\n",
    "        \"\"\"분석 결과 포맷팅\"\"\"\n",
    "        output = f\"\"\"\n",
    "📝 입력: {result['original_text']}\n",
    "🔍 전처리: {result['preprocessed_text']}\n",
    "\n",
    "🎯 최종 결과: {result['final']['prediction']} (신뢰도: {result['final']['confidence']:.4f})\n",
    "📊 예측 경로: {' → '.join(result['path'])}\n",
    "\n",
    "📈 단계별 분석:\n",
    "\"\"\"\n",
    "\n",
    "        for level, data in result[\"levels\"].items():\n",
    "            output += f\"\\n🔸 {data['step']}\\n\"\n",
    "            output += f\"   결과: {data['prediction']} ({data['confidence']:.4f})\\n\"\n",
    "            output += f\"   확률: \"\n",
    "            for emotion, prob in data[\"probabilities\"].items():\n",
    "                output += f\"{emotion}({prob:.3f}) \"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        return output\n",
    "\n",
    "    # 챗봇 응답 생성\n",
    "    # 메모리 추가\n",
    "    def generate_response(self, text):\n",
    "        try:\n",
    "            # 감정 분류\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "\n",
    "            #감정 분석 포맷팅\n",
    "            emotion_info = f\"감정: {emotion_result['final']['prediction']}, 신뢰도: {emotion_result['final']['confidence']:.2f}, 경로: {' → '.join(emotion_result['path'])}\"\n",
    "\n",
    "\n",
    "            # 메모리에서 대화 기록 가져오기\n",
    "            chat_history = self.memory.chat_memory.messages\n",
    "\n",
    "            # 체인 실행\n",
    "            response = self.chain.invoke(\n",
    "                {\"message\": text, \n",
    "                 \"emotion_info\":emotion_info,\n",
    "                 \"chat_history\": chat_history}\n",
    "            )\n",
    "\n",
    "            # 응답 추출\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # 메모리에 대화저장\n",
    "                self.memory.chat_memory.add_user_message(text)\n",
    "                self.memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"응답생성에 실패했습니다\"\n",
    "        except Exception as e:\n",
    "            print(f\"응답 생성 중 오류 발생: {e}\")\n",
    "            return \"응답 생성 중 오류가 발생했습니다. 다시 시도해주세요.\"\n",
    "\n",
    "    def process_message(self, text, include_ai_response=True):\n",
    "        \"\"\"메시지 전체 처리\"\"\"\n",
    "        # 감정 분석\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "        emotion_analysis = self.format_analysis(emotion_result)\n",
    "\n",
    "        result = {\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"emotion_result\": emotion_result,\n",
    "        }\n",
    "\n",
    "        # AI 응답\n",
    "        if include_ai_response:\n",
    "            ai_response = self.generate_response(text)\n",
    "            result[\"ai_response\"] = ai_response\n",
    "            result[\"full_response\"] = f\"{emotion_analysis}\\n💬 AI 상담:\\n{ai_response}\"\n",
    "        else:\n",
    "            result[\"full_response\"] = emotion_analysis\n",
    "\n",
    "        return result\n",
    "\n",
    "    # 메모리 관련 유틸리티 메서드들\n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"현재 대화 요약 가져오기\"\"\"\n",
    "        return self.memory.predict_new_summary(self.memory.chat_memory.messages, \"\")\n",
    "\n",
    "    def get_chat_history(self):\n",
    "        \"\"\"전체 대화 기록 가져오기\"\"\"\n",
    "        return self.memory.chat_memory.messages\n",
    "\n",
    "    def clear_memory(self):\n",
    "        \"\"\"메모리 초기화\"\"\"\n",
    "        self.memory.clear()\n",
    "        print(\"💭 대화 기록이 초기화되었습니다.\")\n",
    "\n",
    "    def get_memory_status(self):\n",
    "        \"\"\"메모리 상태 확인\"\"\"\n",
    "        messages = self.memory.chat_memory.messages\n",
    "        token_count = self.memory.llm.get_num_tokens_from_messages(messages)\n",
    "\n",
    "        return {\n",
    "            \"message_count\": len(messages),\n",
    "            \"token_count\": token_count,\n",
    "            \"max_token_limit\": self.memory.max_token_limit,\n",
    "            \"is_summarizing\": token_count > self.memory.max_token_limit,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8171dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chatbot(model_dir):\n",
    "    \"\"\"챗봇 생성\"\"\"\n",
    "    try:\n",
    "        return EmotionChatbot(model_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 챗봇 생성 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae1a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 디렉토리: /Users/hwangeunbi/chatnge_AI/chat/model\n",
      "디바이스: mps\n",
      "1단계 : 파일 확인\n",
      "✅ level1_best_model.pt 파일이 존재합니다.\n",
      "✅ level2_best_model.pt 파일이 존재합니다.\n",
      "✅ level3_best_model.pt 파일이 존재합니다.\n",
      "✅ level1_label_encoder.pkl 파일이 존재합니다.\n",
      "✅ level2_label_encoder.pkl 파일이 존재합니다.\n",
      "✅ level3_label_encoder.pkl 파일이 존재합니다.\n",
      "2단계: 라벨 인코더 로드\n",
      "level1_label_encoder.pkl 파일에서 level1_encoder 로드 완료\n",
      "level2_label_encoder.pkl 파일에서 level2_encoder 로드 완료\n",
      "level3_label_encoder.pkl 파일에서 level3_encoder 로드 완료\n",
      "3단계: BERT 모델 로드\n",
      "BERT 모델과 토크나이저 로드 완료\n",
      "😊 감정 분류 모델 로드 중...\n",
      "  🔄 level1_best_model.pt 로드 중...\n",
      "  ✅ level1_best_model.pt 로드 완료\n",
      "  🔄 level2_best_model.pt 로드 중...\n",
      "  ✅ level2_best_model.pt 로드 완료\n",
      "  🔄 level3_best_model.pt 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_77496/4267706820.py:17: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationSummaryBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ level3_best_model.pt 로드 완료\n",
      "챗봇 초기화 완료\n",
      "💬 심리상담 챗봇이 준비되었습니다!\n",
      "언제든 'quit' 또는 '종료'를 입력하면 종료됩니다.\n",
      "\n",
      "\n",
      "🤖 상담사가 분석 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 감정 분석:\n",
      "\n",
      "📝 입력: 안녕\n",
      "🔍 전처리: 안녕\n",
      "\n",
      "🎯 최종 결과: 일반대화 (신뢰도: 1.0000)\n",
      "📊 예측 경로: 일반대화\n",
      "\n",
      "📈 단계별 분석:\n",
      "\n",
      "🔸 1단계: 일반대화 vs 감정\n",
      "   결과: 일반대화 (1.0000)\n",
      "   확률: 감정(0.000) 일반대화(1.000) \n",
      "\n",
      "\n",
      "💬 상담사: 안녕하세요. 이렇게 찾아와 주셔서 고마워요. 오늘 어떤 이야기를 나누고 싶으신가요?\n",
      "--------------------------------------------------\n",
      "\n",
      "🤖 상담사가 분석 중...\n",
      "\n",
      "📊 감정 분석:\n",
      "\n",
      "📝 입력: 아 너무 그냥 짜증나고 다 때려치고 싶어\n",
      "🔍 전처리: 아 너무 그냥 짜증나고 때려치고 싶어\n",
      "\n",
      "🎯 최종 결과: 분노 (신뢰도: 0.9623)\n",
      "📊 예측 경로: 감정 → 기타감정 → 분노\n",
      "\n",
      "📈 단계별 분석:\n",
      "\n",
      "🔸 1단계: 일반대화 vs 감정\n",
      "   결과: 감정 (1.0000)\n",
      "   확률: 감정(1.000) 일반대화(0.000) \n",
      "\n",
      "🔸 2단계: 기쁨 vs 기타감정\n",
      "   결과: 기타감정 (0.9999)\n",
      "   확률: 기쁨(0.000) 기타감정(1.000) \n",
      "\n",
      "🔸 3단계: 세부 감정 분류\n",
      "   결과: 분노 (0.9623)\n",
      "   확률: 당황(0.010) 분노(0.962) 불안(0.011) 상처(0.008) 슬픔(0.009) \n",
      "\n",
      "\n",
      "💬 상담사: 그렇게 느끼는 건 정말 힘들 수 있겠네요. 무언가가 당신을 많이 지치게 하고 있는 것 같아요. 혹시 어떤 상황이나 일이 그런 감정을 불러일으키고 있는지 조금 더 이야기해 줄 수 있을까요?\n",
      "--------------------------------------------------\n",
      "\n",
      "🤖 상담사가 분석 중...\n",
      "\n",
      "📊 감정 분석:\n",
      "\n",
      "📝 입력: 그냥 취업도 잘 안되고 되는게 없어\n",
      "🔍 전처리: 그냥 취업도 잘 안되고 되는게 없어\n",
      "\n",
      "🎯 최종 결과: 불안 (신뢰도: 0.4865)\n",
      "📊 예측 경로: 감정 → 기타감정 → 불안\n",
      "\n",
      "📈 단계별 분석:\n",
      "\n",
      "🔸 1단계: 일반대화 vs 감정\n",
      "   결과: 감정 (1.0000)\n",
      "   확률: 감정(1.000) 일반대화(0.000) \n",
      "\n",
      "🔸 2단계: 기쁨 vs 기타감정\n",
      "   결과: 기타감정 (0.9999)\n",
      "   확률: 기쁨(0.000) 기타감정(1.000) \n",
      "\n",
      "🔸 3단계: 세부 감정 분류\n",
      "   결과: 불안 (0.4865)\n",
      "   확률: 당황(0.040) 분노(0.113) 불안(0.487) 상처(0.093) 슬픔(0.267) \n",
      "\n",
      "\n",
      "💬 상담사: 취업이 잘 안 되면 정말 답답하고 불안할 수 있죠. 많은 노력을 하고 있는데도 결과가 따라주지 않는 것 같아서 더 힘들겠어요. 지금 이 상황에서 가장 큰 걱정이나 고민은 무엇인가요? 그리고 혹시 당신이 지금까지 해왔던 노력 중에 어떤 부분이 가장 어려웠는지 나눠줄 수 있을까요?\n",
      "--------------------------------------------------\n",
      "\n",
      "🤖 상담사가 분석 중...\n",
      "\n",
      "📊 감정 분석:\n",
      "\n",
      "📝 입력: 취업도 안되고 아무것도 안되는 기부니야\n",
      "🔍 전처리: 취업도 안되고 아무것도 안되는 기부니야\n",
      "\n",
      "🎯 최종 결과: 분노 (신뢰도: 0.3065)\n",
      "📊 예측 경로: 감정 → 기타감정 → 분노\n",
      "\n",
      "📈 단계별 분석:\n",
      "\n",
      "🔸 1단계: 일반대화 vs 감정\n",
      "   결과: 감정 (1.0000)\n",
      "   확률: 감정(1.000) 일반대화(0.000) \n",
      "\n",
      "🔸 2단계: 기쁨 vs 기타감정\n",
      "   결과: 기타감정 (0.9999)\n",
      "   확률: 기쁨(0.000) 기타감정(1.000) \n",
      "\n",
      "🔸 3단계: 세부 감정 분류\n",
      "   결과: 분노 (0.3065)\n",
      "   확률: 당황(0.270) 분노(0.306) 불안(0.099) 상처(0.163) 슬픔(0.162) \n",
      "\n",
      "\n",
      "💬 상담사: 그런 기분이 드는 건 정말 힘들 것 같아요. 마치 모든 것이 막힌 듯한 느낌이 들 수 있겠네요. 지금 이 순간에 당신에게 가장 필요한 것이 무엇일까요? 그리고 혹시 지금까지의 경험에서 배운 점이나 스스로에게 칭찬해주고 싶은 부분이 있다면 무엇일까요?\n",
      "--------------------------------------------------\n",
      "\n",
      "🤖 상담사가 분석 중...\n",
      "\n",
      "📊 감정 분석:\n",
      "\n",
      "📝 입력: 너무 겁먹지 마는것 그리고 나에게 스스로 칭찬을 해줄것\n",
      "🔍 전처리: 너무 겁먹지 마는것 그리고 나에게 스스로 칭찬을 해줄것\n",
      "\n",
      "🎯 최종 결과: 불안 (신뢰도: 0.2811)\n",
      "📊 예측 경로: 감정 → 기타감정 → 불안\n",
      "\n",
      "📈 단계별 분석:\n",
      "\n",
      "🔸 1단계: 일반대화 vs 감정\n",
      "   결과: 감정 (1.0000)\n",
      "   확률: 감정(1.000) 일반대화(0.000) \n",
      "\n",
      "🔸 2단계: 기쁨 vs 기타감정\n",
      "   결과: 기타감정 (0.9999)\n",
      "   확률: 기쁨(0.000) 기타감정(1.000) \n",
      "\n",
      "🔸 3단계: 세부 감정 분류\n",
      "   결과: 불안 (0.2811)\n",
      "   확률: 당황(0.274) 분노(0.208) 불안(0.281) 상처(0.102) 슬픔(0.134) \n",
      "\n",
      "\n",
      "💬 상담사: 자신을 격려하고 칭찬하는 건 정말 중요한 일이에요. 지금처럼 스스로에게 용기를 주려는 마음이 있다는 것 자체가 큰 강점이에요. 혹시 최근에 스스로에게 칭찬하고 싶은 순간이 있었다면 어떤 것이었을까요? 그리고 그 순간이 당신에게 어떤 의미가 있었는지 나눠줄 수 있을까요?\n",
      "--------------------------------------------------\n",
      "상담이 종료되었습니다. 좋은 하루 보내세요!\n"
     ]
    }
   ],
   "source": [
    "# run_chatbot.py - 챗봇 실행\n",
    "\n",
    "# 1. 챗봇 생성\n",
    "model_dir = \"/Users/hwangeunbi/chatnge_AI/chat/model\"  # 모델 파일들이 있는 폴더 경로\n",
    "chatbot = create_chatbot(model_dir)\n",
    "\n",
    "if chatbot is None:\n",
    "    print(\"챗봇 생성에 실패했습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 2. 대화 시작\n",
    "print(\"💬 심리상담 챗봇이 준비되었습니다!\")\n",
    "print(\"언제든 'quit' 또는 '종료'를 입력하면 종료됩니다.\\n\")\n",
    "\n",
    "while True:\n",
    "    # 사용자 입력\n",
    "    user_input = input(\"당신: \")\n",
    "    \n",
    "    # 종료 조건\n",
    "    if user_input.lower() in ['quit', 'exit', '종료', '끝']:\n",
    "        print(\"상담이 종료되었습니다. 좋은 하루 보내세요!\")\n",
    "        break\n",
    "    \n",
    "    # 특수 명령어\n",
    "    if user_input == '/clear':\n",
    "        chatbot.clear_memory()\n",
    "        continue\n",
    "    elif user_input == '/status':\n",
    "        status = chatbot.get_memory_status()\n",
    "        print(f\"💭 메모리 상태: {status}\")\n",
    "        continue\n",
    "    \n",
    "    # 챗봇 응답 생성\n",
    "    print(\"\\n🤖 상담사가 분석 중...\")\n",
    "    result = chatbot.process_message(user_input, include_ai_response=True)\n",
    "    \n",
    "    # 감정 분석 결과 출력 (선택사항)\n",
    "    print(\"\\n📊 감정 분석:\")\n",
    "    print(result['emotion_analysis'])\n",
    "    \n",
    "    # AI 상담 응답 출력\n",
    "    print(f\"\\n💬 상담사: {result['ai_response']}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatnge-ai-rActT2Je-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
