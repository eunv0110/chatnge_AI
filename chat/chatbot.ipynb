{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3ce73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.get_default_device() 함수가 없다고 떠서 대체 함수 정의\n",
    "\n",
    "\n",
    "def _get_default_device():\n",
    "    \"\"\"torch.get_default_device() 대체 함수\"\"\"\n",
    "\n",
    "    # gpu가 있으면 cuda 디바이스로 반환\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # apple m1,m2 칩이 있으면 mps 디바이스로 반환\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    # 그 외는 cpu 디바이스로 반환\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617dbce",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "898ce71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "chatnge_ai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_teddynote import logging\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"chatnge_ai\")\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35f0c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#클로드 api 키를 환경 변수에서 불러옴\n",
    "api_key2 = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "#제미나이 api 키를 환경 변수에서 불러옴\n",
    "api_key3 = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0435c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer 임포트 전에 환경 설정\n",
    "\n",
    "# transformers 라이브러리가 온라인 모드로 동작하도록 설정\n",
    "## 모델 다운로드 설정\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "# KLUE/BERT 모델 사용하기 위해 Hugging Face 모델 접근할 수 있도록 설정\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b638caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformers 라이브러리 로드 완료\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel, logging as transformers_logging\n",
    "\n",
    "    transformers_logging.set_verbosity_error()  # 경고 메시지 최소화\n",
    "    print(\"✅ Transformers 라이브러리 로드 완료\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Transformers 라이브러리 임포트 실패: {e}\")\n",
    "    print(\"pip install transformers를 실행해주세요.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e59afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torch에 없는 함수 추가\n",
    "torch.get_default_device = _get_default_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707289",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66c776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 불용어 리스트\n",
    "KOREAN_STOPWORDS = [\n",
    "    \"이\",\n",
    "    \"그\",\n",
    "    \"저\",\n",
    "    \"것\",\n",
    "    \"및\",\n",
    "    \"에\",\n",
    "    \"를\",\n",
    "    \"은\",\n",
    "    \"는\",\n",
    "    \"이런\",\n",
    "    \"저런\",\n",
    "    \"그런\",\n",
    "    \"한\",\n",
    "    \"이르\",\n",
    "    \"또한\",\n",
    "    \"있\",\n",
    "    \"하\",\n",
    "    \"에서\",\n",
    "    \"으로\",\n",
    "    \"으로써\",\n",
    "    \"로써\",\n",
    "    \"로서\",\n",
    "    \"로\",\n",
    "    \"와\",\n",
    "    \"과\",\n",
    "    \"이고\",\n",
    "    \"이며\",\n",
    "    \"이다\",\n",
    "    \"있다\",\n",
    "    \"하다\",\n",
    "    \"되다\",\n",
    "    \"이\",\n",
    "    \"가\",\n",
    "    \"을\",\n",
    "    \"를\",\n",
    "    \"에게\",\n",
    "    \"의\",\n",
    "    \"뿐\",\n",
    "    \"다\",\n",
    "    \"적\",\n",
    "    \"데\",\n",
    "    \"때\",\n",
    "    \"나\",\n",
    "    \"도\",\n",
    "    \"만\",\n",
    "    \"께\",\n",
    "    \"에게서\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf6f6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 텍스트 전처리\n",
    "def preprocess_korean_text(text):\n",
    "    # 만약에 텍스트가 없으면 그냥 빈칸 반환\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # 반복 문자 정규화\n",
    "    text = re.sub(r\"[^가-힣a-zA-Z0-9\\s\\.,!?]\", \" \", text)  # 특수문자 제거\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 공백 정리\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stopwords=KOREAN_STOPWORDS):\n",
    "    \"\"\"주어진 텍스트에서 불용어 제거\"\"\"\n",
    "    # 아무것도 없으면 그냥 반환\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95013df4",
   "metadata": {},
   "source": [
    "## 감정 분류기 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05b816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(torch.nn.Module):\n",
    "    \"\"\"감정 분류기 모델 - BERT 기반의 감정 분류를 위한 신경망 모델\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model, num_classes, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        모델 초기화\n",
    "\n",
    "        Args:\n",
    "            bert_model: 사전 훈련된 BERT 모델 (예: BertModel)\n",
    "            num_classes: 분류할 감정 클래스의 개수\n",
    "            dropout_rate: 드롭아웃 비율 (기본값: 0.3)\n",
    "        \"\"\"\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "\n",
    "        # BERT 모델을 백본으로 사용\n",
    "        self.bert = bert_model\n",
    "        # BERT의 히든 사이즈 (일반적으로 768)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # 과적합 방지를 위한 드롭아웃 레이어\n",
    "        self.dropout1 = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 어텐션 메커니즘: 각 토큰의 중요도를 계산\n",
    "        self.attention = torch.nn.Sequential(\n",
    "            # 히든 사이즈를 256차원으로 축소\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # Tanh 활성화 함수로 비선형성 추가\n",
    "            torch.nn.Tanh(),\n",
    "            # 256차원을 1차원으로 축소하여 어텐션 스코어 생성\n",
    "            torch.nn.Linear(256, 1),\n",
    "            # Softmax로 어텐션 가중치를 정규화 (합이 1이 되도록)\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        # 최종 분류를 위한 분류기\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # 히든 사이즈를 256차원으로 축소\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # ReLU 활성화 함수\n",
    "            torch.nn.ReLU(),\n",
    "            # 배치 정규화로 학습 안정성 향상\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            # 드롭아웃으로 과적합 방지\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            # 최종 감정 클래스 개수만큼 출력\n",
    "            torch.nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            input_ids: 토크나이징된 입력 텍스트의 ID\n",
    "            attention_mask: 패딩 토큰을 무시하기 위한 마스크\n",
    "            token_type_ids: 문장 구분을 위한 토큰 타입 ID\n",
    "\n",
    "        Returns:\n",
    "            logits: 각 감정 클래스에 대한 점수\n",
    "        \"\"\"\n",
    "        # BERT 모델에 입력을 통과시켜 임베딩 생성\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True,  # 딕셔너리 형태로 결과 반환\n",
    "        )\n",
    "\n",
    "        # 모든 토큰의 히든 상태 (배치 크기, 시퀀스 길이, 히든 크기)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        # [CLS] 토큰의 풀링된 표현 (배치 크기, 히든 크기)\n",
    "        pooled_output = outputs.pooler_output\n",
    "\n",
    "        # 어텐션 가중치 계산: 각 토큰의 중요도 결정\n",
    "        attention_weights = self.attention(sequence_output)\n",
    "\n",
    "        # 가중합을 통해 컨텍스트 벡터 생성\n",
    "        # attention_weights와 sequence_output을 곱하고 시퀀스 차원을 따라 합산\n",
    "        context_vector = torch.sum(attention_weights * sequence_output, dim=1)\n",
    "\n",
    "        # 어텐션 기반 컨텍스트 벡터와 BERT의 풀링 출력을 결합\n",
    "        # 두 표현을 더해서 더 풍부한 표현 생성\n",
    "        final_output = context_vector + pooled_output\n",
    "\n",
    "        # 드롭아웃 적용하여 과적합 방지\n",
    "        final_output = self.dropout1(final_output)\n",
    "\n",
    "        # 분류기를 통과시켜 최종 로짓 계산\n",
    "        logits = self.classifier(final_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba10aed",
   "metadata": {},
   "source": [
    "## 계층적 감정 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a7057fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalEmotionClassifier:\n",
    "    def __init__(self, model_dir,confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "\n",
    "        self.model_dir = model_dir  # 모델 경로 설정\n",
    "        self.device = _get_default_device()  # 디바이스 설정\n",
    "        self.max_len = 128  # 최대 길이 설정\n",
    "\n",
    "        # 디버깅용\n",
    "        print(f\"모델 디렉토리: {self.model_dir}\")\n",
    "        print(f\"디바이스: {self.device}\")\n",
    "\n",
    "        # 임계값 설정\n",
    "        self.confidence_threshold = confidence_threshold  # 신뢰도 임계값\n",
    "        self.emotion_threshold = emotion_threshold        # 감정 탐지 임계값\n",
    "        \n",
    "        print(f\"신뢰도 임계값: {self.confidence_threshold}\")\n",
    "        print(f\"감정 탐지 임계값: {self.emotion_threshold}\")\n",
    "\n",
    "        # 변수 초기화\n",
    "        self.tokenizer = None\n",
    "        self.bert_model = None\n",
    "        self.level1_model = None\n",
    "        self.level2_model = None\n",
    "        self.level3_model = None\n",
    "        self.level1_labels = None\n",
    "        self.level2_labels = None\n",
    "        self.level3_labels = None\n",
    "\n",
    "        # 모델 로드\n",
    "        self._load_models()\n",
    "\n",
    "    def _check_files(self):\n",
    "        print(\"1단계 : 파일 확인\")\n",
    "        # 필수 파일들 정의\n",
    "        required_files = [\n",
    "            \"level1_best_model.pt\",\n",
    "            \"level2_best_model.pt\",\n",
    "            \"level3_best_model.pt\",\n",
    "            \"level1_label_encoder.pkl\",\n",
    "            \"level2_label_encoder.pkl\",\n",
    "            \"level3_label_encoder.pkl\",\n",
    "        ]\n",
    "\n",
    "        # 없는 파일 확인 리스트\n",
    "        missing_files = []\n",
    "\n",
    "        for file in required_files:\n",
    "            filepath = os.path.join(self.model_dir, file)\n",
    "            if not os.path.exists(filepath):\n",
    "                missing_files.append(file)\n",
    "            else:\n",
    "                print(f\"✅ {file} 파일이 존재합니다.\")\n",
    "\n",
    "        # 만약에 누락된 파일이 있으면 예외 발생\n",
    "        if missing_files:\n",
    "            raise FileExistsError(f\"파일 누락 목록:{missing_files}\")\n",
    "\n",
    "    # 라벨 인코터 로드\n",
    "    def _load_label_encoders(self):\n",
    "        print(\"2단계: 라벨 인코더 로드\")\n",
    "\n",
    "        encoders = [\n",
    "            (\"level1_label_encoder.pkl\", \"level1_encoder\"),\n",
    "            (\"level2_label_encoder.pkl\", \"level2_encoder\"),\n",
    "            (\"level3_label_encoder.pkl\", \"level3_encoder\"),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name in encoders:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                encoder = pickle.load(f)\n",
    "                setattr(self, attr_name, encoder)\n",
    "            print(f\"{filename} 파일에서 {attr_name} 로드 완료\")\n",
    "\n",
    "    # 3단계 bert 모델 로드\n",
    "    def _load_bert_model(self):\n",
    "\n",
    "        try:\n",
    "            print(\"3단계: BERT 모델 로드\")\n",
    "            # BERT 모델과 토크나이저 로드\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "            self.bert_model = AutoModel.from_pretrained(\"klue/bert-base\")\n",
    "\n",
    "            # 디바이스 이동\n",
    "            self.bert_model = self.bert_model.to(self.device)\n",
    "            print(\"BERT 모델과 토크나이저 로드 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ BERT 모델 로드 실패: {e}\")\n",
    "            raise ImportError(\n",
    "                \"BERT 모델을 로드하는 데 실패했습니다. 'transformers' 라이브러리가 설치되어 있는지 확인하세요.\"\n",
    "            )\n",
    "\n",
    "    def _load_emotion_models(self):\n",
    "        \"\"\"감정 분류 모델들 로드\"\"\"\n",
    "        print(\"😊 감정 분류 모델 로드 중...\")\n",
    "\n",
    "        models = [\n",
    "            (\"level1_best_model.pt\", \"level1_model\", self.level1_encoder),\n",
    "            (\"level2_best_model.pt\", \"level2_model\", self.level2_encoder),\n",
    "            (\"level3_best_model.pt\", \"level3_model\", self.level3_encoder),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name, encoder in models:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "\n",
    "            print(f\"  🔄 {filename} 로드 중...\")\n",
    "\n",
    "            # 모델 초기화\n",
    "            model = EmotionClassifier(\n",
    "                copy.deepcopy(self.bert_model.to(\"cpu\")), len(encoder.classes_)\n",
    "            )\n",
    "\n",
    "            # 가중치 로드\n",
    "            try:\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n",
    "            except TypeError:  # 구버전 PyTorch\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\")\n",
    "\n",
    "            model.load_state_dict(state_dict)\n",
    "\n",
    "            # 디바이스 이동 및 평가 모드\n",
    "            model = model.to(self.device)\n",
    "            model.eval()\n",
    "\n",
    "            setattr(self, attr_name, model)\n",
    "            print(f\"  ✅ {filename} 로드 완료\")\n",
    "\n",
    "    def _load_models(self):\n",
    "        \"\"\"모든 모델 로드\"\"\"\n",
    "        try:\n",
    "            # 1단계 : 파일 존재 확인\n",
    "            self._check_files()\n",
    "\n",
    "            # 2단계 : 라벨 인코더 로드\n",
    "            self._load_label_encoders()\n",
    "\n",
    "            # 3단계\n",
    "            self._load_bert_model()\n",
    "\n",
    "            # 4단계\n",
    "            self._load_emotion_models()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 모델 로드 중 오류 발생: {e}\")\n",
    "            raise\n",
    "\n",
    "    # 단일 모델 분류\n",
    "    def _predict_single(self, model, text):\n",
    "        # 전처리\n",
    "        preprocessed = preprocess_korean_text(text)\n",
    "        preprocessed = remove_stopwords(preprocessed)\n",
    "\n",
    "        # 토큰화\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            preprocessed,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # 디바이스 이동\n",
    "        input_ids = encoding[\"input_ids\"].to(self.device)\n",
    "        attention_mask = encoding[\"attention_mask\"].to(self.device)\n",
    "        token_type_ids = encoding[\"token_type_ids\"].to(self.device)\n",
    "\n",
    "        # 예측\n",
    "        with torch.no_grad():  # 그래디어언트 계산 비활성화 : 메모리 절약 + 속도 향상\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)  # 로짓 출력\n",
    "            probs = torch.nn.functional.softmax(\n",
    "                outputs, dim=1\n",
    "            )  # 확률 변환, 각 클래스별 확률값\n",
    "            _, preds = torch.max(outputs, dim=1)  # 가장 높은 확률을 가진 클래스 선택\n",
    "\n",
    "        return preds.item(), probs[0]\n",
    "\n",
    "    # 계층적 감정 분류\n",
    "    def predict_hierarchical(self, text):\n",
    "        \"\"\"계층적 예측\"\"\"\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"levels\": {},\n",
    "        }\n",
    "\n",
    "        # 1단계\n",
    "        pred1, probs1 = self._predict_single(self.level1_model, text)\n",
    "        label1 = self.level1_encoder.inverse_transform([pred1])[0]\n",
    "\n",
    "        result[\"levels\"][\"level1\"] = {\n",
    "            \"step\": \"1단계: 일반대화 vs 감정\",\n",
    "            \"prediction\": label1,\n",
    "            \"confidence\": float(probs1[pred1]),\n",
    "            \"probabilities\": {\n",
    "                self.level1_encoder.classes_[i]: float(probs1[i])\n",
    "                for i in range(len(self.level1_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label1 == \"일반대화\":\n",
    "            result[\"final\"] = {\n",
    "                \"prediction\": \"일반대화\",\n",
    "                \"confidence\": float(probs1[pred1]),\n",
    "            }\n",
    "            result[\"path\"] = [\"일반대화\"]\n",
    "            return result\n",
    "\n",
    "        # 2단계\n",
    "        pred2, probs2 = self._predict_single(self.level2_model, text)\n",
    "        label2 = self.level2_encoder.inverse_transform([pred2])[0]\n",
    "\n",
    "        result[\"levels\"][\"level2\"] = {\n",
    "            \"step\": \"2단계: 기쁨 vs 기타감정\",\n",
    "            \"prediction\": label2,\n",
    "            \"confidence\": float(probs2[pred2]),\n",
    "            \"probabilities\": {\n",
    "                self.level2_encoder.classes_[i]: float(probs2[i])\n",
    "                for i in range(len(self.level2_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label2 == \"기쁨\":\n",
    "            result[\"final\"] = {\"prediction\": \"기쁨\", \"confidence\": float(probs2[pred2])}\n",
    "            result[\"path\"] = [\"감정\", \"기쁨\"]\n",
    "            return result\n",
    "\n",
    "        # 3단계\n",
    "        pred3, probs3 = self._predict_single(self.level3_model, text)\n",
    "        label3 = self.level3_encoder.inverse_transform([pred3])[0]\n",
    "\n",
    "        result[\"levels\"][\"level3\"] = {\n",
    "            \"step\": \"3단계: 세부 감정 분류\",\n",
    "            \"prediction\": label3,\n",
    "            \"confidence\": float(probs3[pred3]),\n",
    "            \"probabilities\": {\n",
    "                self.level3_encoder.classes_[i]: float(probs3[i])\n",
    "                for i in range(len(self.level3_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        result[\"final\"] = {\"prediction\": label3, \"confidence\": float(probs3[pred3])}\n",
    "        result[\"path\"] = [\"감정\", \"기타감정\", label3]\n",
    "\n",
    "        return result\n",
    "    \n",
    "    #신뢰도 기반 복합 감정 분석\n",
    "    def predict_with_confidence_analysis(self, text, threshold=0.55):\n",
    "        result = self.predict_hierarchical(text)\n",
    "\n",
    "        # 각 단계별 신뢰도 분석\n",
    "        analysis = {\n",
    "            \"original_text\": text,\n",
    "            \"complexity_level\": \"simple\",  # simple, mixed, complex\n",
    "            \"primary_emotion\": result['final']['prediction'],\n",
    "            \"primary_confidence\": result['final']['confidence'],\n",
    "            \"mixed_emotions\": [],\n",
    "            \"uncertainty_indicators\": []\n",
    "        }\n",
    "\n",
    "        #Level 2에서 기쁨과 기타감정 혼동 체크\n",
    "        if 'level2' in result['levels']:\n",
    "            level2_probs = result['levels']['level2']['probabilities']\n",
    "            joy_prob = level2_probs.get('기쁨', 0)\n",
    "            other_prob = level2_probs.get('기타감정', 0)\n",
    "\n",
    "            # 확률 차이가 작으면 혼합 감정으로 판단\n",
    "            prob_diff = abs(joy_prob - other_prob)\n",
    "            \n",
    "            if prob_diff < 0.3:  # 30% 이하 차이면 혼합 감정\n",
    "                analysis[\"complexity_level\"] = \"mixed\"\n",
    "                analysis[\"mixed_emotions\"].append({\n",
    "                    \"emotion\": \"기쁨\",\n",
    "                    \"confidence\": joy_prob,\n",
    "                    \"type\": \"positive\"\n",
    "                })\n",
    "                \n",
    "                # Level 3에서 세부 감정도 추가\n",
    "                if 'level3' in result['levels']:\n",
    "                    level3_result = result['levels']['level3']\n",
    "                    analysis[\"mixed_emotions\"].append({\n",
    "                        \"emotion\": level3_result['prediction'],\n",
    "                        \"confidence\": level3_result['confidence'],\n",
    "                        \"type\": \"negative_or_neutral\"\n",
    "                    })\n",
    "        if threshold is None:\n",
    "            threshold = self.confidence_threshold\n",
    "            \n",
    "        # 전반적 신뢰도가 낮으면 복잡한 감정으로 분류\n",
    "        if result['final']['confidence'] < threshold:\n",
    "            analysis[\"complexity_level\"] = \"complex\"\n",
    "            analysis[\"uncertainty_indicators\"].append(\n",
    "                f\"낮은 신뢰도: {result['final']['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        return analysis\n",
    "                \n",
    "    def predict_multi_emotion_threshold(self, text, threshold=None):\n",
    "        \"\"\"임계값 이상의 모든 감정 반환 (완성된 버전)\"\"\"\n",
    "        # 임계값이 지정되지 않으면 클래스 기본값 사용\n",
    "        if threshold is None:\n",
    "            threshold = self.emotion_threshold\n",
    "            \n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"detected_emotions\": [],\n",
    "            \"emotion_combination\": None\n",
    "        }\n",
    "        \n",
    "        # 모든 단계에서 임계값 이상인 감정들 수집\n",
    "        hierarchical_result = self.predict_hierarchical(text)\n",
    "        \n",
    "        all_emotions = []\n",
    "        \n",
    "        # Level 1 체크\n",
    "        if 'level1' in hierarchical_result['levels']:\n",
    "            for emotion, prob in hierarchical_result['levels']['level1']['probabilities'].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append({\n",
    "                        'emotion': emotion,\n",
    "                        'probability': prob,\n",
    "                        'level': 1,\n",
    "                        'category': 'conversation_type'\n",
    "                    })\n",
    "        \n",
    "        # Level 2 체크 (기쁨 vs 기타감정)\n",
    "        if 'level2' in hierarchical_result['levels']:\n",
    "            for emotion, prob in hierarchical_result['levels']['level2']['probabilities'].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append({\n",
    "                        'emotion': emotion,\n",
    "                        'probability': prob,\n",
    "                        'level': 2,\n",
    "                        'category': 'emotion_polarity'\n",
    "                    })\n",
    "        \n",
    "        # Level 3 체크 (세부 감정)\n",
    "        if 'level3' in hierarchical_result['levels']:\n",
    "            for emotion, prob in hierarchical_result['levels']['level3']['probabilities'].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append({\n",
    "                        'emotion': emotion,\n",
    "                        'probability': prob,\n",
    "                        'level': 3,\n",
    "                        'category': 'specific_emotion'\n",
    "                    })\n",
    "        \n",
    "        result['detected_emotions'] = sorted(all_emotions, key=lambda x: x['probability'], reverse=True)\n",
    "        \n",
    "        # 감정 조합 분석\n",
    "        result['emotion_combination'] = self._analyze_emotion_combination(all_emotions)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _analyze_emotion_combination(self, emotions):\n",
    "        \"\"\"감정 조합 분석\"\"\"\n",
    "        # Level 2에서 기쁨과 기타감정이 모두 임계값 이상인지 체크\n",
    "        level2_emotions = [e for e in emotions if e['level'] == 2]\n",
    "        level3_emotions = [e for e in emotions if e['level'] == 3]\n",
    "        \n",
    "        combination_type = \"single\"\n",
    "        details = {}\n",
    "        \n",
    "        if len(level2_emotions) >= 2:  # 기쁨과 기타감정 둘 다 높은 확률\n",
    "            joy_emotion = next((e for e in level2_emotions if e['emotion'] == '기쁨'), None)\n",
    "            other_emotion = next((e for e in level2_emotions if e['emotion'] == '기타감정'), None)\n",
    "            \n",
    "            if joy_emotion and other_emotion:\n",
    "                combination_type = \"ambivalent\"  # 양가감정\n",
    "                details = {\n",
    "                    \"positive_aspect\": {\n",
    "                        \"emotion\": \"기쁨\",\n",
    "                        \"strength\": joy_emotion['probability']\n",
    "                    },\n",
    "                    \"negative_aspect\": {\n",
    "                        \"emotions\": level3_emotions,\n",
    "                        \"primary\": max(level3_emotions, key=lambda x: x['probability']) if level3_emotions else None\n",
    "                    },\n",
    "                    \"conflict_intensity\": abs(joy_emotion['probability'] - other_emotion['probability'])\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            \"type\": combination_type,\n",
    "            \"details\": details\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccf1d9",
   "metadata": {},
   "source": [
    "## 챗봇 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a362c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import google.generativeai as genai\n",
    "\n",
    "class EmotionChatbot:\n",
    "    def __init__(self, model_dir,llm_provider='openai',confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "        # 감정 분류기 초기화\n",
    "        self.classifier = HierarchicalEmotionClassifier(\n",
    "            model_dir, \n",
    "            confidence_threshold=confidence_threshold,\n",
    "            emotion_threshold=emotion_threshold\n",
    "        )\n",
    "        \n",
    "        # 임계값을 챗봇에서도 저장 (필요시 사용)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.emotion_threshold = emotion_threshold\n",
    "        \n",
    "        try:\n",
    "            if llm_provider == 'openai':\n",
    "            # 챗봇 초기화\n",
    "                self.llm = ChatOpenAI(\n",
    "                    model=\"gpt-4o\", \n",
    "                    temperature=0.4, \n",
    "                    max_tokens=1000, \n",
    "                    api_key=api_key\n",
    "                )\n",
    "            elif llm_provider == 'claude':\n",
    "                \n",
    "                self.llm = ChatAnthropic(\n",
    "                    model=\"claude-sonnet-4-20250514\",\n",
    "                    temperature=0.4,\n",
    "                    max_tokens=1000,\n",
    "                    api_key=api_key2\n",
    "                )\n",
    "            elif llm_provider == 'gemini':\n",
    "                \n",
    "                self.llm = genai.GenerativeModel(\n",
    "                    model=\"gemini-pro\",\n",
    "                    temperature=0.4,\n",
    "                    max_tokens=1000,\n",
    "                    api_key=api_key3\n",
    "                )\n",
    "\n",
    "            # 메모리 초기화\n",
    "            self.memory = ConversationSummaryBufferMemory(\n",
    "                llm=self.llm,\n",
    "                return_messages=True,\n",
    "                max_token_limit=2000,\n",
    "                memory_key=\"chat_history\",\n",
    "            )\n",
    "\n",
    "            # 기본 프롬프트 설정 (YAML 파일이 없을 경우를 대비)\n",
    "            try:\n",
    "                system_prompt = load_prompt(\"prompts/emcprompt3.yaml\", encoding=\"utf-8\")\n",
    "                self.system_prompt_text = system_prompt.template\n",
    "            except:\n",
    "                # 기본 시스템 프롬프트\n",
    "                self.system_prompt_text = \"\"\"\n",
    "당신은 전문적이고 따뜻한 심리상담사입니다. \n",
    "사용자의 감정을 깊이 이해하고 공감하며, 건설적인 대화를 통해 도움을 제공합니다.\n",
    "\n",
    "기본 지침:\n",
    "1. 사용자의 감정에 진심으로 공감하고 이해를 표현하세요\n",
    "2. 판단하지 말고 수용하는 자세를 보이세요  \n",
    "3. 적절한 질문을 통해 사용자 스스로 성찰할 수 있도록 도우세요\n",
    "4. 전문적이면서도 친근하고 따뜻한 톤을 유지하세요\n",
    "5. 사용자의 강점과 자원에 주목하세요\n",
    "\n",
    "감정 정보가 제공되면 이를 참고하여 더욱 정확하고 적절한 공감 반응을 보이세요.\n",
    "\"\"\"\n",
    "\n",
    "            self.chat_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", self.system_prompt_text),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ])\n",
    "\n",
    "            self.chain = self.chat_prompt | self.llm\n",
    "            print(\"✅ 챗봇 초기화 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 챗봇 초기화 중 오류 발생: {e}\")\n",
    "            raise\n",
    "\n",
    "    def classify_emotion(self, text):\n",
    "        \"\"\"기본 감정 분류\"\"\"\n",
    "        return self.classifier.predict_hierarchical(text)\n",
    "\n",
    "    def format_analysis(self, result):\n",
    "        \"\"\"기본 분석 결과 포맷팅\"\"\"\n",
    "        output = f\"\"\"\n",
    "📝 입력: {result['original_text']}\n",
    "🔍 전처리: {result['preprocessed_text']}\n",
    "\n",
    "🎯 최종 결과: {result['final']['prediction']} (신뢰도: {result['final']['confidence']:.4f})\n",
    "📊 예측 경로: {' → '.join(result['path'])}\n",
    "\n",
    "📈 단계별 분석:\n",
    "\"\"\"\n",
    "\n",
    "        for level, data in result[\"levels\"].items():\n",
    "            output += f\"\\n🔸 {data['step']}\\n\"\n",
    "            output += f\"   결과: {data['prediction']} ({data['confidence']:.4f})\\n\"\n",
    "            output += f\"   확률: \"\n",
    "            for emotion, prob in data[\"probabilities\"].items():\n",
    "                output += f\"{emotion}({prob:.3f}) \"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        return output\n",
    "\n",
    "    def generate_response(self, text):\n",
    "        \"\"\"기본 챗봇 응답 생성 (메모리 추가)\"\"\"\n",
    "        try:\n",
    "            # 기본 감정 분류\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            # 감정 분석 포맷팅\n",
    "            emotion_info = f\"감정: {emotion_result['final']['prediction']}, 신뢰도: {emotion_result['final']['confidence']:.2f}, 경로: {' → '.join(emotion_result['path'])}\"\n",
    "\n",
    "            # 메모리에서 대화 기록 가져오기\n",
    "            chat_history = self.memory.chat_memory.messages\n",
    "\n",
    "            # 체인 실행\n",
    "            response = self.chain.invoke({\n",
    "                \"message\": text, \n",
    "                \"emotion_info\": emotion_info,\n",
    "                \"chat_history\": chat_history\n",
    "            })\n",
    "\n",
    "            # 응답 추출\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # 메모리에 대화저장\n",
    "                self.memory.chat_memory.add_user_message(text)\n",
    "                self.memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"응답생성에 실패했습니다\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"응답 생성 중 오류 발생: {e}\")\n",
    "            return \"응답 생성 중 오류가 발생했습니다. 다시 시도해주세요.\"\n",
    "\n",
    "    def generate_empathetic_response(self, text):\n",
    "        \"\"\"복합 감정을 고려한 공감 응답 생성\"\"\"\n",
    "        try:\n",
    "            # 복합 감정 분석\n",
    "            emotion_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "            multi_emotion_result = self.classifier.predict_multi_emotion_threshold(text)\n",
    "            \n",
    "            # 응답 전략 결정\n",
    "            response_strategy = self._determine_response_strategy(emotion_analysis, multi_emotion_result)\n",
    "            \n",
    "            # 프롬프트에 복합 감정 정보 추가\n",
    "            emotion_context = self._format_emotion_context(emotion_analysis, multi_emotion_result, response_strategy)\n",
    "            \n",
    "            # 메모리에서 대화 기록 가져오기\n",
    "            chat_history = self.memory.chat_memory.messages\n",
    "            \n",
    "            # 개선된 프롬프트로 응답 생성\n",
    "            response = self._generate_response_with_complex_emotion_context(\n",
    "                text, emotion_context, chat_history\n",
    "            )\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"공감 응답 생성 중 오류: {e}\")\n",
    "            return \"죄송합니다. 응답 생성 중 문제가 발생했네요. 다시 말씀해 주시겠어요?\"\n",
    "    \n",
    "    def _determine_response_strategy(self, emotion_analysis, multi_emotion_result):\n",
    "        \"\"\"응답 전략 결정\"\"\"\n",
    "        if emotion_analysis['complexity_level'] == 'mixed':\n",
    "            if multi_emotion_result['emotion_combination']['type'] == 'ambivalent':\n",
    "                return \"ambivalent_empathy\"  # 양가감정 공감\n",
    "            else:\n",
    "                return \"mixed_validation\"    # 혼합감정 인정\n",
    "        elif emotion_analysis['complexity_level'] == 'complex':\n",
    "            return \"exploratory_empathy\"     # 탐색적 공감\n",
    "        else:\n",
    "            return \"direct_empathy\"          # 직접적 공감\n",
    "    \n",
    "    def _format_emotion_context(self, emotion_analysis, multi_emotion_result, strategy):\n",
    "        \"\"\"감정 맥락 포맷팅\"\"\"\n",
    "        context = {\n",
    "            \"primary_emotion\": emotion_analysis['primary_emotion'],\n",
    "            \"confidence\": emotion_analysis['primary_confidence'],\n",
    "            \"complexity\": emotion_analysis['complexity_level'],\n",
    "            \"response_strategy\": strategy\n",
    "        }\n",
    "        \n",
    "        # 복합 감정 정보 추가\n",
    "        if emotion_analysis['mixed_emotions']:\n",
    "            context[\"mixed_emotions\"] = emotion_analysis['mixed_emotions']\n",
    "        \n",
    "        # 양가감정 정보 추가\n",
    "        if multi_emotion_result['emotion_combination']['type'] == 'ambivalent':\n",
    "            context[\"ambivalent_details\"] = multi_emotion_result['emotion_combination']['details']\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def _generate_response_with_complex_emotion_context(self, text, emotion_context, chat_history):\n",
    "        \"\"\"복합 감정 맥락을 고려한 응답 생성\"\"\"\n",
    "        \n",
    "        # 응답 전략별 시스템 프롬프트 구성\n",
    "        strategy_prompts = {\n",
    "            \"ambivalent_empathy\": \"\"\"\n",
    "당신은 전문 심리상담사입니다. 사용자가 상반된 감정(기쁨과 다른 부정적 감정)을 동시에 경험하고 있는 것 같습니다.\n",
    "\n",
    "양가감정 공감 지침:\n",
    "1. \"기쁜 동시에 복잡한 감정이 드시는 것 같아요\" 같은 표현으로 양면성을 인정\n",
    "2. 두 감정 모두 자연스럽고 정상적임을 강조\n",
    "3. 감정의 충돌로 인한 혼란감에 공감\n",
    "4. 각각의 감정에 대해 따로 탐색해보도록 안내\n",
    "5. 따뜻하고 이해하는 톤으로 대화하세요\n",
    "\"\"\",\n",
    "            \n",
    "            \"mixed_validation\": \"\"\"\n",
    "당신은 전문 심리상담사입니다. 사용자가 여러 감정이 섞인 복잡한 상태인 것 같습니다.\n",
    "\n",
    "혼합감정 인정 지침:\n",
    "1. \"여러 가지 감정이 함께 느껴지시는군요\" 같은 표현으로 복잡성 인정\n",
    "2. 감정이 단순하지 않을 수 있음을 정상화\n",
    "3. 가장 강하게 느껴지는 감정부터 차근차근 탐색\n",
    "4. 각 감정의 의미와 원인에 대해 궁금증 표현\n",
    "5. 판단하지 않고 수용하는 자세를 보이세요\n",
    "\"\"\",\n",
    "            \n",
    "            \"exploratory_empathy\": \"\"\"\n",
    "당신은 전문 심리상담사입니다. 사용자의 감정 상태가 불분명하거나 복잡해 보입니다.\n",
    "\n",
    "탐색적 공감 지침:\n",
    "1. \"지금 마음이 복잡하신 것 같아요\" 같은 포괄적 공감 표현\n",
    "2. 성급한 감정 레이블링 피하기\n",
    "3. 열린 질문으로 감정 탐색 유도\n",
    "4. 사용자 자신의 감정 인식을 돕는 방향으로 대화 진행\n",
    "5. 안전하고 편안한 분위기 조성\n",
    "\"\"\",\n",
    "            \n",
    "            \"direct_empathy\": \"\"\"\n",
    "당신은 전문 심리상담사입니다. 사용자의 감정이 비교적 명확해 보입니다.\n",
    "\n",
    "직접적 공감 지침:\n",
    "1. 인식된 주요 감정에 대해 직접적이고 구체적인 공감\n",
    "2. 해당 감정을 느끼는 것이 자연스럽다고 안심시키기\n",
    "3. 감정의 원인이나 맥락에 대해 궁금해하기\n",
    "4. 감정을 건강하게 다루는 방법 제안\n",
    "5. 사용자의 강점과 자원에 주목\n",
    "\"\"\"\n",
    "        }\n",
    "        \n",
    "        # 감정 정보 문자열 생성\n",
    "        emotion_info_str = f\"\"\"\n",
    "감정 분석 결과:\n",
    "- 주요 감정: {emotion_context['primary_emotion']} (신뢰도: {emotion_context['confidence']:.2f})\n",
    "- 복잡도: {emotion_context['complexity']}\n",
    "- 응답 전략: {emotion_context['response_strategy']}\n",
    "\"\"\"\n",
    "        \n",
    "        if 'mixed_emotions' in emotion_context:\n",
    "            emotion_info_str += \"\\n혼합 감정들:\\n\"\n",
    "            for emotion in emotion_context['mixed_emotions']:\n",
    "                emotion_info_str += f\"- {emotion['emotion']}: {emotion['confidence']:.2f}\\n\"\n",
    "        \n",
    "        if 'ambivalent_details' in emotion_context:\n",
    "            details = emotion_context['ambivalent_details']\n",
    "            emotion_info_str += f\"\\n양가감정 세부사항:\\n\"\n",
    "            emotion_info_str += f\"- 긍정적 측면: {details['positive_aspect']['emotion']} ({details['positive_aspect']['strength']:.2f})\\n\"\n",
    "            if details['negative_aspect']['primary']:\n",
    "                emotion_info_str += f\"- 부정적 측면: {details['negative_aspect']['primary']['emotion']} ({details['negative_aspect']['primary']['probability']:.2f})\\n\"\n",
    "        \n",
    "        # 전략에 맞는 시스템 프롬프트 선택\n",
    "        system_prompt = strategy_prompts.get(emotion_context['response_strategy'], strategy_prompts['direct_empathy'])\n",
    "        \n",
    "        # 프롬프트 구성\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt + f\"\\n\\n{emotion_info_str}\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{message}\")\n",
    "        ])\n",
    "        \n",
    "        # 체인 실행\n",
    "        chain = chat_prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"message\": text,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        \n",
    "        if hasattr(response, \"content\"):\n",
    "            ai_response = response.content\n",
    "            # 메모리에 대화 저장\n",
    "            self.memory.chat_memory.add_user_message(text)\n",
    "            self.memory.chat_memory.add_ai_message(ai_response)\n",
    "            return ai_response\n",
    "        else:\n",
    "            return \"응답 생성에 실패했습니다.\"\n",
    "\n",
    "    def process_message(self, text, include_ai_response=True):\n",
    "        \"\"\"기본 메시지 전체 처리\"\"\"\n",
    "        # 감정 분석\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "        emotion_analysis = self.format_analysis(emotion_result)\n",
    "\n",
    "        result = {\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"emotion_result\": emotion_result,\n",
    "        }\n",
    "\n",
    "        # AI 응답\n",
    "        if include_ai_response:\n",
    "            ai_response = self.generate_response(text)\n",
    "            result[\"ai_response\"] = ai_response\n",
    "            result[\"full_response\"] = f\"{emotion_analysis}\\n💬 AI 상담:\\n{ai_response}\"\n",
    "        else:\n",
    "            result[\"full_response\"] = emotion_analysis\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def process_complex_emotion_message(self, text):\n",
    "        \"\"\"복합 감정을 고려한 메시지 처리\"\"\"\n",
    "        # 기본 감정 분석\n",
    "        basic_result = self.classify_emotion(text)\n",
    "        \n",
    "        # 복합 감정 분석\n",
    "        confidence_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "        multi_emotion_analysis = self.classifier.predict_multi_emotion_threshold(text)\n",
    "        \n",
    "        # 공감 응답 생성\n",
    "        ai_response = self.generate_empathetic_response(text)\n",
    "        \n",
    "        # 결과 통합\n",
    "        result = {\n",
    "            \"basic_emotion_analysis\": self.format_analysis(basic_result),\n",
    "            \"confidence_analysis\": confidence_analysis,\n",
    "            \"multi_emotion_analysis\": multi_emotion_analysis,\n",
    "            \"ai_response\": ai_response,\n",
    "            \"complexity_insight\": self._generate_complexity_insight(confidence_analysis, multi_emotion_analysis),\n",
    "            \"full_response\": f\"\"\"\n",
    "📊 감정 복잡성 분석:\n",
    "{chr(10).join(self._generate_complexity_insight(confidence_analysis, multi_emotion_analysis))}\n",
    "\n",
    "💬 AI 상담:\n",
    "{ai_response}\n",
    "\"\"\"\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _generate_complexity_insight(self, confidence_analysis, multi_emotion_analysis):\n",
    "        \"\"\"복잡성 인사이트 생성\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        if confidence_analysis['complexity_level'] == 'mixed':\n",
    "            insights.append(\"🔀 혼합된 감정이 감지되었습니다.\")\n",
    "        \n",
    "        if multi_emotion_analysis['emotion_combination']['type'] == 'ambivalent':\n",
    "            insights.append(\"⚖️ 상반된 감정이 동시에 나타나는 양가감정 상태입니다.\")\n",
    "        \n",
    "        if confidence_analysis['primary_confidence'] < 0.6:\n",
    "            insights.append(\"🌊 감정이 복잡하고 미묘한 상태로 보입니다.\")\n",
    "        \n",
    "        if len(multi_emotion_analysis['detected_emotions']) > 3:\n",
    "            insights.append(\"🎭 다양한 감정이 복합적으로 나타나고 있습니다.\")\n",
    "        \n",
    "        return insights if insights else [\"💡 비교적 명확한 감정 상태입니다.\"]\n",
    "\n",
    "    # 메모리 관련 유틸리티 메서드들\n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"현재 대화 요약 가져오기\"\"\"\n",
    "        try:\n",
    "            return self.memory.predict_new_summary(self.memory.chat_memory.messages, \"\")\n",
    "        except Exception as e:\n",
    "            print(f\"대화 요약 생성 중 오류: {e}\")\n",
    "            return \"요약을 생성할 수 없습니다.\"\n",
    "\n",
    "    def get_chat_history(self):\n",
    "        \"\"\"전체 대화 기록 가져오기\"\"\"\n",
    "        return self.memory.chat_memory.messages\n",
    "\n",
    "    def clear_memory(self):\n",
    "        \"\"\"메모리 초기화\"\"\"\n",
    "        self.memory.clear()\n",
    "        print(\"💭 대화 기록이 초기화되었습니다.\")\n",
    "\n",
    "    def get_memory_status(self):\n",
    "        \"\"\"메모리 상태 확인\"\"\"\n",
    "        try:\n",
    "            messages = self.memory.chat_memory.messages\n",
    "            token_count = self.memory.llm.get_num_tokens_from_messages(messages)\n",
    "\n",
    "            return {\n",
    "                \"message_count\": len(messages),\n",
    "                \"token_count\": token_count,\n",
    "                \"max_token_limit\": self.memory.max_token_limit,\n",
    "                \"is_summarizing\": token_count > self.memory.max_token_limit,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"메모리 상태 확인 중 오류: {e}\")\n",
    "            return {\n",
    "                \"message_count\": 0,\n",
    "                \"token_count\": 0,\n",
    "                \"max_token_limit\": self.memory.max_token_limit,\n",
    "                \"is_summarizing\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def set_thresholds(self, confidence_threshold=None, emotion_threshold=None):\n",
    "        \"\"\"임계값 동적 변경\"\"\"\n",
    "        if confidence_threshold is not None:\n",
    "            self.confidence_threshold = confidence_threshold\n",
    "            self.classifier.confidence_threshold = confidence_threshold\n",
    "            print(f\"신뢰도 임계값이 {confidence_threshold}로 변경되었습니다.\")\n",
    "        \n",
    "        if emotion_threshold is not None:\n",
    "            self.emotion_threshold = emotion_threshold\n",
    "            self.classifier.emotion_threshold = emotion_threshold\n",
    "            print(f\"감정 탐지 임계값이 {emotion_threshold}로 변경되었습니다.\")\n",
    "\n",
    "    def get_thresholds(self):\n",
    "        \"\"\"현재 임계값 조회\"\"\"\n",
    "        return {\n",
    "            \"confidence_threshold\": self.confidence_threshold,\n",
    "            \"emotion_threshold\": self.emotion_threshold\n",
    "        }\n",
    "\n",
    "\n",
    "# 챗봇 생성 헬퍼 함수\n",
    "def create_chatbot(model_dir,llm_provider,confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "    \"\"\"챗봇 생성\"\"\"\n",
    "    try:\n",
    "        return EmotionChatbot(\n",
    "            model_dir, \n",
    "            confidence_threshold=confidence_threshold,\n",
    "            emotion_threshold=emotion_threshold\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 챗봇 생성 실패: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91405ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 디렉토리: /Users/hwangeunbi/chatnge_AI/chat/model\n",
      "디바이스: mps\n",
      "신뢰도 임계값: 0.6\n",
      "감정 탐지 임계값: 0.3\n",
      "1단계 : 파일 확인\n",
      "✅ level1_best_model.pt 파일이 존재합니다.\n",
      "✅ level2_best_model.pt 파일이 존재합니다.\n",
      "✅ level3_best_model.pt 파일이 존재합니다.\n",
      "✅ level1_label_encoder.pkl 파일이 존재합니다.\n",
      "✅ level2_label_encoder.pkl 파일이 존재합니다.\n",
      "✅ level3_label_encoder.pkl 파일이 존재합니다.\n",
      "2단계: 라벨 인코더 로드\n",
      "level1_label_encoder.pkl 파일에서 level1_encoder 로드 완료\n",
      "level2_label_encoder.pkl 파일에서 level2_encoder 로드 완료\n",
      "level3_label_encoder.pkl 파일에서 level3_encoder 로드 완료\n",
      "3단계: BERT 모델 로드\n",
      "BERT 모델과 토크나이저 로드 완료\n",
      "😊 감정 분류 모델 로드 중...\n",
      "  🔄 level1_best_model.pt 로드 중...\n",
      "  ✅ level1_best_model.pt 로드 완료\n",
      "  🔄 level2_best_model.pt 로드 중...\n",
      "  ✅ level2_best_model.pt 로드 완료\n",
      "  🔄 level3_best_model.pt 로드 중...\n",
      "  ✅ level3_best_model.pt 로드 완료\n",
      "✅ 챗봇 초기화 완료\n",
      "✅ 챗봇이 성공적으로 생성되었습니다!\n",
      "좋은 일이 있었다니 정말 기쁘네요. 하지만 뭔가 아쉬운 마음이 드는 것 같군요. 그 좋은 일이 어떤 것이었는지, 그리고 무엇이 아쉬웠는지 조금 더 이야기해 줄 수 있을까요? 그런 감정이 드는 이유가 무엇인지 함께 탐색해보면 좋겠어요.\n",
      "\n",
      "📊 감정 복잡성 분석:\n",
      "🌊 감정이 복잡하고 미묘한 상태로 보입니다.\n",
      "\n",
      "💬 AI 상담:\n",
      "기쁜 일이 있으면서도 동시에 걱정이 되는 마음이 드는군요. 이런 복합적인 감정을 느끼는 건 아주 자연스러운 일이에요. 기쁜 일이란 어떤 것이었고, 그와 관련된 어떤 점이 걱정을 불러일으키는지 궁금하네요. 혹시 그 걱정을 조금 덜 수 있는 방법이 있을까요? 함께 고민해보면 좋겠어요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 챗봇 생성\n",
    "    model_dir = \"/Users/hwangeunbi/chatnge_AI/chat/model\" \n",
    "    chatbot = create_chatbot(model_dir, llm_provider=\"gemini\")\n",
    "    \n",
    "    if chatbot:\n",
    "        print(\"✅ 챗봇이 성공적으로 생성되었습니다!\")\n",
    "        \n",
    "        # 기본 사용\n",
    "        result = chatbot.process_message(\"오늘 좋은 일이 있었는데 뭔가 아쉬워\")\n",
    "        print(result['ai_response'])\n",
    "        \n",
    "        # 복합 감정 분석 사용\n",
    "        complex_result = chatbot.process_complex_emotion_message(\"기쁘면서도 걱정돼\")\n",
    "        print(complex_result['full_response'])\n",
    "    else:\n",
    "        print(\"❌ 챗봇 생성에 실패했습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatnge-ai-rActT2Je-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
