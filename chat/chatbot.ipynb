{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3ce73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.get_default_device() í•¨ìˆ˜ê°€ ì—†ë‹¤ê³  ë– ì„œ ëŒ€ì²´ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "\n",
    "def _get_default_device():\n",
    "    \"\"\"torch.get_default_device() ëŒ€ì²´ í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    # gpuê°€ ìˆìœ¼ë©´ cuda ë””ë°”ì´ìŠ¤ë¡œ ë°˜í™˜\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # apple m1,m2 ì¹©ì´ ìˆìœ¼ë©´ mps ë””ë°”ì´ìŠ¤ë¡œ ë°˜í™˜\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    # ê·¸ ì™¸ëŠ” cpu ë””ë°”ì´ìŠ¤ë¡œ ë°˜í™˜\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617dbce",
   "metadata": {},
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "898ce71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "chatnge_ai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_teddynote import logging\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"chatnge_ai\")\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35f0c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#í´ë¡œë“œ api í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "api_key2 = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "#ì œë¯¸ë‚˜ì´ api í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "api_key3 = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0435c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer ì„í¬íŠ¸ ì „ì— í™˜ê²½ ì„¤ì •\n",
    "\n",
    "# transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì˜¨ë¼ì¸ ëª¨ë“œë¡œ ë™ì‘í•˜ë„ë¡ ì„¤ì •\n",
    "## ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì„¤ì •\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "# KLUE/BERT ëª¨ë¸ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Hugging Face ëª¨ë¸ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b638caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel, logging as transformers_logging\n",
    "\n",
    "    transformers_logging.set_verbosity_error()  # ê²½ê³  ë©”ì‹œì§€ ìµœì†Œí™”\n",
    "    print(\"âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"pip install transformersë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e59afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torchì— ì—†ëŠ” í•¨ìˆ˜ ì¶”ê°€\n",
    "torch.get_default_device = _get_default_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707289",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66c776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸\n",
    "KOREAN_STOPWORDS = [\n",
    "    \"ì´\",\n",
    "    \"ê·¸\",\n",
    "    \"ì €\",\n",
    "    \"ê²ƒ\",\n",
    "    \"ë°\",\n",
    "    \"ì—\",\n",
    "    \"ë¥¼\",\n",
    "    \"ì€\",\n",
    "    \"ëŠ”\",\n",
    "    \"ì´ëŸ°\",\n",
    "    \"ì €ëŸ°\",\n",
    "    \"ê·¸ëŸ°\",\n",
    "    \"í•œ\",\n",
    "    \"ì´ë¥´\",\n",
    "    \"ë˜í•œ\",\n",
    "    \"ìˆ\",\n",
    "    \"í•˜\",\n",
    "    \"ì—ì„œ\",\n",
    "    \"ìœ¼ë¡œ\",\n",
    "    \"ìœ¼ë¡œì¨\",\n",
    "    \"ë¡œì¨\",\n",
    "    \"ë¡œì„œ\",\n",
    "    \"ë¡œ\",\n",
    "    \"ì™€\",\n",
    "    \"ê³¼\",\n",
    "    \"ì´ê³ \",\n",
    "    \"ì´ë©°\",\n",
    "    \"ì´ë‹¤\",\n",
    "    \"ìˆë‹¤\",\n",
    "    \"í•˜ë‹¤\",\n",
    "    \"ë˜ë‹¤\",\n",
    "    \"ì´\",\n",
    "    \"ê°€\",\n",
    "    \"ì„\",\n",
    "    \"ë¥¼\",\n",
    "    \"ì—ê²Œ\",\n",
    "    \"ì˜\",\n",
    "    \"ë¿\",\n",
    "    \"ë‹¤\",\n",
    "    \"ì \",\n",
    "    \"ë°\",\n",
    "    \"ë•Œ\",\n",
    "    \"ë‚˜\",\n",
    "    \"ë„\",\n",
    "    \"ë§Œ\",\n",
    "    \"ê»˜\",\n",
    "    \"ì—ê²Œì„œ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf6f6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "def preprocess_korean_text(text):\n",
    "    # ë§Œì•½ì— í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë¹ˆì¹¸ ë°˜í™˜\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # ë°˜ë³µ ë¬¸ì ì •ê·œí™”\n",
    "    text = re.sub(r\"[^ê°€-í£a-zA-Z0-9\\s\\.,!?]\", \" \", text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # ê³µë°± ì •ë¦¬\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stopwords=KOREAN_STOPWORDS):\n",
    "    \"\"\"ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆìš©ì–´ ì œê±°\"\"\"\n",
    "    # ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë°˜í™˜\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95013df4",
   "metadata": {},
   "source": [
    "## ê°ì • ë¶„ë¥˜ê¸° ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05b816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(torch.nn.Module):\n",
    "    \"\"\"ê°ì • ë¶„ë¥˜ê¸° ëª¨ë¸ - BERT ê¸°ë°˜ì˜ ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹ ê²½ë§ ëª¨ë¸\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model, num_classes, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        ëª¨ë¸ ì´ˆê¸°í™”\n",
    "\n",
    "        Args:\n",
    "            bert_model: ì‚¬ì „ í›ˆë ¨ëœ BERT ëª¨ë¸ (ì˜ˆ: BertModel)\n",
    "            num_classes: ë¶„ë¥˜í•  ê°ì • í´ë˜ìŠ¤ì˜ ê°œìˆ˜\n",
    "            dropout_rate: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.3)\n",
    "        \"\"\"\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "\n",
    "        # BERT ëª¨ë¸ì„ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©\n",
    "        self.bert = bert_model\n",
    "        # BERTì˜ íˆë“  ì‚¬ì´ì¦ˆ (ì¼ë°˜ì ìœ¼ë¡œ 768)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´\n",
    "        self.dropout1 = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜: ê° í† í°ì˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°\n",
    "        self.attention = torch.nn.Sequential(\n",
    "            # íˆë“  ì‚¬ì´ì¦ˆë¥¼ 256ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # Tanh í™œì„±í™” í•¨ìˆ˜ë¡œ ë¹„ì„ í˜•ì„± ì¶”ê°€\n",
    "            torch.nn.Tanh(),\n",
    "            # 256ì°¨ì›ì„ 1ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ì—¬ ì–´í…ì…˜ ìŠ¤ì½”ì–´ ìƒì„±\n",
    "            torch.nn.Linear(256, 1),\n",
    "            # Softmaxë¡œ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        # ìµœì¢… ë¶„ë¥˜ë¥¼ ìœ„í•œ ë¶„ë¥˜ê¸°\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # íˆë“  ì‚¬ì´ì¦ˆë¥¼ 256ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # ReLU í™œì„±í™” í•¨ìˆ˜\n",
    "            torch.nn.ReLU(),\n",
    "            # ë°°ì¹˜ ì •ê·œí™”ë¡œ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            # ë“œë¡­ì•„ì›ƒìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            # ìµœì¢… ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜ë§Œí¼ ì¶œë ¥\n",
    "            torch.nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        ìˆœì „íŒŒ ê³¼ì •\n",
    "\n",
    "        Args:\n",
    "            input_ids: í† í¬ë‚˜ì´ì§•ëœ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ID\n",
    "            attention_mask: íŒ¨ë”© í† í°ì„ ë¬´ì‹œí•˜ê¸° ìœ„í•œ ë§ˆìŠ¤í¬\n",
    "            token_type_ids: ë¬¸ì¥ êµ¬ë¶„ì„ ìœ„í•œ í† í° íƒ€ì… ID\n",
    "\n",
    "        Returns:\n",
    "            logits: ê° ê°ì • í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜\n",
    "        \"\"\"\n",
    "        # BERT ëª¨ë¸ì— ì…ë ¥ì„ í†µê³¼ì‹œì¼œ ì„ë² ë”© ìƒì„±\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True,  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°˜í™˜\n",
    "        )\n",
    "\n",
    "        # ëª¨ë“  í† í°ì˜ íˆë“  ìƒíƒœ (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, íˆë“  í¬ê¸°)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        # [CLS] í† í°ì˜ í’€ë§ëœ í‘œí˜„ (ë°°ì¹˜ í¬ê¸°, íˆë“  í¬ê¸°)\n",
    "        pooled_output = outputs.pooler_output\n",
    "\n",
    "        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°: ê° í† í°ì˜ ì¤‘ìš”ë„ ê²°ì •\n",
    "        attention_weights = self.attention(sequence_output)\n",
    "\n",
    "        # ê°€ì¤‘í•©ì„ í†µí•´ ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ìƒì„±\n",
    "        # attention_weightsì™€ sequence_outputì„ ê³±í•˜ê³  ì‹œí€€ìŠ¤ ì°¨ì›ì„ ë”°ë¼ í•©ì‚°\n",
    "        context_vector = torch.sum(attention_weights * sequence_output, dim=1)\n",
    "\n",
    "        # ì–´í…ì…˜ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ì™€ BERTì˜ í’€ë§ ì¶œë ¥ì„ ê²°í•©\n",
    "        # ë‘ í‘œí˜„ì„ ë”í•´ì„œ ë” í’ë¶€í•œ í‘œí˜„ ìƒì„±\n",
    "        final_output = context_vector + pooled_output\n",
    "\n",
    "        # ë“œë¡­ì•„ì›ƒ ì ìš©í•˜ì—¬ ê³¼ì í•© ë°©ì§€\n",
    "        final_output = self.dropout1(final_output)\n",
    "\n",
    "        # ë¶„ë¥˜ê¸°ë¥¼ í†µê³¼ì‹œì¼œ ìµœì¢… ë¡œì§“ ê³„ì‚°\n",
    "        logits = self.classifier(final_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba10aed",
   "metadata": {},
   "source": [
    "## ê³„ì¸µì  ê°ì • ë¶„ë¥˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a7057fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalEmotionClassifier:\n",
    "    def __init__(self, model_dir,confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "\n",
    "        self.model_dir = model_dir  # ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "        self.device = _get_default_device()  # ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "        self.max_len = 128  # ìµœëŒ€ ê¸¸ì´ ì„¤ì •\n",
    "\n",
    "        # ë””ë²„ê¹…ìš©\n",
    "        print(f\"ëª¨ë¸ ë””ë ‰í† ë¦¬: {self.model_dir}\")\n",
    "        print(f\"ë””ë°”ì´ìŠ¤: {self.device}\")\n",
    "\n",
    "        # ì„ê³„ê°’ ì„¤ì •\n",
    "        self.confidence_threshold = confidence_threshold  # ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    "        self.emotion_threshold = emotion_threshold        # ê°ì • íƒì§€ ì„ê³„ê°’\n",
    "        \n",
    "        print(f\"ì‹ ë¢°ë„ ì„ê³„ê°’: {self.confidence_threshold}\")\n",
    "        print(f\"ê°ì • íƒì§€ ì„ê³„ê°’: {self.emotion_threshold}\")\n",
    "\n",
    "        # ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "        self.tokenizer = None\n",
    "        self.bert_model = None\n",
    "        self.level1_model = None\n",
    "        self.level2_model = None\n",
    "        self.level3_model = None\n",
    "        self.level1_labels = None\n",
    "        self.level2_labels = None\n",
    "        self.level3_labels = None\n",
    "\n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        self._load_models()\n",
    "\n",
    "    def _check_files(self):\n",
    "        print(\"1ë‹¨ê³„ : íŒŒì¼ í™•ì¸\")\n",
    "        # í•„ìˆ˜ íŒŒì¼ë“¤ ì •ì˜\n",
    "        required_files = [\n",
    "            \"level1_best_model.pt\",\n",
    "            \"level2_best_model.pt\",\n",
    "            \"level3_best_model.pt\",\n",
    "            \"level1_label_encoder.pkl\",\n",
    "            \"level2_label_encoder.pkl\",\n",
    "            \"level3_label_encoder.pkl\",\n",
    "        ]\n",
    "\n",
    "        # ì—†ëŠ” íŒŒì¼ í™•ì¸ ë¦¬ìŠ¤íŠ¸\n",
    "        missing_files = []\n",
    "\n",
    "        for file in required_files:\n",
    "            filepath = os.path.join(self.model_dir, file)\n",
    "            if not os.path.exists(filepath):\n",
    "                missing_files.append(file)\n",
    "            else:\n",
    "                print(f\"âœ… {file} íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        # ë§Œì•½ì— ëˆ„ë½ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ\n",
    "        if missing_files:\n",
    "            raise FileExistsError(f\"íŒŒì¼ ëˆ„ë½ ëª©ë¡:{missing_files}\")\n",
    "\n",
    "    # ë¼ë²¨ ì¸ì½”í„° ë¡œë“œ\n",
    "    def _load_label_encoders(self):\n",
    "        print(\"2ë‹¨ê³„: ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ\")\n",
    "\n",
    "        encoders = [\n",
    "            (\"level1_label_encoder.pkl\", \"level1_encoder\"),\n",
    "            (\"level2_label_encoder.pkl\", \"level2_encoder\"),\n",
    "            (\"level3_label_encoder.pkl\", \"level3_encoder\"),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name in encoders:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                encoder = pickle.load(f)\n",
    "                setattr(self, attr_name, encoder)\n",
    "            print(f\"{filename} íŒŒì¼ì—ì„œ {attr_name} ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "    # 3ë‹¨ê³„ bert ëª¨ë¸ ë¡œë“œ\n",
    "    def _load_bert_model(self):\n",
    "\n",
    "        try:\n",
    "            print(\"3ë‹¨ê³„: BERT ëª¨ë¸ ë¡œë“œ\")\n",
    "            # BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "            self.bert_model = AutoModel.from_pretrained(\"klue/bert-base\")\n",
    "\n",
    "            # ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "            self.bert_model = self.bert_model.to(self.device)\n",
    "            print(\"BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            raise ImportError(\n",
    "                \"BERT ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. 'transformers' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\"\n",
    "            )\n",
    "\n",
    "    def _load_emotion_models(self):\n",
    "        \"\"\"ê°ì • ë¶„ë¥˜ ëª¨ë¸ë“¤ ë¡œë“œ\"\"\"\n",
    "        print(\"ğŸ˜Š ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "        models = [\n",
    "            (\"level1_best_model.pt\", \"level1_model\", self.level1_encoder),\n",
    "            (\"level2_best_model.pt\", \"level2_model\", self.level2_encoder),\n",
    "            (\"level3_best_model.pt\", \"level3_model\", self.level3_encoder),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name, encoder in models:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "\n",
    "            print(f\"  ğŸ”„ {filename} ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "            # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "            model = EmotionClassifier(\n",
    "                copy.deepcopy(self.bert_model.to(\"cpu\")), len(encoder.classes_)\n",
    "            )\n",
    "\n",
    "            # ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "            try:\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n",
    "            except TypeError:  # êµ¬ë²„ì „ PyTorch\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\")\n",
    "\n",
    "            model.load_state_dict(state_dict)\n",
    "\n",
    "            # ë””ë°”ì´ìŠ¤ ì´ë™ ë° í‰ê°€ ëª¨ë“œ\n",
    "            model = model.to(self.device)\n",
    "            model.eval()\n",
    "\n",
    "            setattr(self, attr_name, model)\n",
    "            print(f\"  âœ… {filename} ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "    def _load_models(self):\n",
    "        \"\"\"ëª¨ë“  ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            # 1ë‹¨ê³„ : íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "            self._check_files()\n",
    "\n",
    "            # 2ë‹¨ê³„ : ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ\n",
    "            self._load_label_encoders()\n",
    "\n",
    "            # 3ë‹¨ê³„\n",
    "            self._load_bert_model()\n",
    "\n",
    "            # 4ë‹¨ê³„\n",
    "            self._load_emotion_models()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            raise\n",
    "\n",
    "    # ë‹¨ì¼ ëª¨ë¸ ë¶„ë¥˜\n",
    "    def _predict_single(self, model, text):\n",
    "        # ì „ì²˜ë¦¬\n",
    "        preprocessed = preprocess_korean_text(text)\n",
    "        preprocessed = remove_stopwords(preprocessed)\n",
    "\n",
    "        # í† í°í™”\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            preprocessed,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "        input_ids = encoding[\"input_ids\"].to(self.device)\n",
    "        attention_mask = encoding[\"attention_mask\"].to(self.device)\n",
    "        token_type_ids = encoding[\"token_type_ids\"].to(self.device)\n",
    "\n",
    "        # ì˜ˆì¸¡\n",
    "        with torch.no_grad():  # ê·¸ë˜ë””ì–´ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” : ë©”ëª¨ë¦¬ ì ˆì•½ + ì†ë„ í–¥ìƒ\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)  # ë¡œì§“ ì¶œë ¥\n",
    "            probs = torch.nn.functional.softmax(\n",
    "                outputs, dim=1\n",
    "            )  # í™•ë¥  ë³€í™˜, ê° í´ë˜ìŠ¤ë³„ í™•ë¥ ê°’\n",
    "            _, preds = torch.max(outputs, dim=1)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ ì„ íƒ\n",
    "\n",
    "        return preds.item(), probs[0]\n",
    "\n",
    "    # ê³„ì¸µì  ê°ì • ë¶„ë¥˜\n",
    "    def predict_hierarchical(self, text):\n",
    "        \"\"\"ê³„ì¸µì  ì˜ˆì¸¡\"\"\"\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"levels\": {},\n",
    "        }\n",
    "\n",
    "        # 1ë‹¨ê³„\n",
    "        pred1, probs1 = self._predict_single(self.level1_model, text)\n",
    "        label1 = self.level1_encoder.inverse_transform([pred1])[0]\n",
    "\n",
    "        result[\"levels\"][\"level1\"] = {\n",
    "            \"step\": \"1ë‹¨ê³„: ì¼ë°˜ëŒ€í™” vs ê°ì •\",\n",
    "            \"prediction\": label1,\n",
    "            \"confidence\": float(probs1[pred1]),\n",
    "            \"probabilities\": {\n",
    "                self.level1_encoder.classes_[i]: float(probs1[i])\n",
    "                for i in range(len(self.level1_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label1 == \"ì¼ë°˜ëŒ€í™”\":\n",
    "            result[\"final\"] = {\n",
    "                \"prediction\": \"ì¼ë°˜ëŒ€í™”\",\n",
    "                \"confidence\": float(probs1[pred1]),\n",
    "            }\n",
    "            result[\"path\"] = [\"ì¼ë°˜ëŒ€í™”\"]\n",
    "            return result\n",
    "\n",
    "        # 2ë‹¨ê³„\n",
    "        pred2, probs2 = self._predict_single(self.level2_model, text)\n",
    "        label2 = self.level2_encoder.inverse_transform([pred2])[0]\n",
    "\n",
    "        result[\"levels\"][\"level2\"] = {\n",
    "            \"step\": \"2ë‹¨ê³„: ê¸°ì¨ vs ê¸°íƒ€ê°ì •\",\n",
    "            \"prediction\": label2,\n",
    "            \"confidence\": float(probs2[pred2]),\n",
    "            \"probabilities\": {\n",
    "                self.level2_encoder.classes_[i]: float(probs2[i])\n",
    "                for i in range(len(self.level2_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label2 == \"ê¸°ì¨\":\n",
    "            result[\"final\"] = {\"prediction\": \"ê¸°ì¨\", \"confidence\": float(probs2[pred2])}\n",
    "            result[\"path\"] = [\"ê°ì •\", \"ê¸°ì¨\"]\n",
    "            return result\n",
    "\n",
    "        # 3ë‹¨ê³„\n",
    "        pred3, probs3 = self._predict_single(self.level3_model, text)\n",
    "        label3 = self.level3_encoder.inverse_transform([pred3])[0]\n",
    "\n",
    "        result[\"levels\"][\"level3\"] = {\n",
    "            \"step\": \"3ë‹¨ê³„: ì„¸ë¶€ ê°ì • ë¶„ë¥˜\",\n",
    "            \"prediction\": label3,\n",
    "            \"confidence\": float(probs3[pred3]),\n",
    "            \"probabilities\": {\n",
    "                self.level3_encoder.classes_[i]: float(probs3[i])\n",
    "                for i in range(len(self.level3_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        result[\"final\"] = {\"prediction\": label3, \"confidence\": float(probs3[pred3])}\n",
    "        result[\"path\"] = [\"ê°ì •\", \"ê¸°íƒ€ê°ì •\", label3]\n",
    "\n",
    "        return result\n",
    "    \n",
    "    #ì‹ ë¢°ë„ ê¸°ë°˜ ë³µí•© ê°ì • ë¶„ì„\n",
    "    def predict_with_confidence_analysis(self, text, threshold=0.55):\n",
    "        result = self.predict_hierarchical(text)\n",
    "\n",
    "        # ê° ë‹¨ê³„ë³„ ì‹ ë¢°ë„ ë¶„ì„\n",
    "        analysis = {\n",
    "            \"original_text\": text,\n",
    "            \"complexity_level\": \"simple\",  # simple, mixed, complex\n",
    "            \"primary_emotion\": result['final']['prediction'],\n",
    "            \"primary_confidence\": result['final']['confidence'],\n",
    "            \"mixed_emotions\": [],\n",
    "            \"uncertainty_indicators\": []\n",
    "        }\n",
    "\n",
    "        #Level 2ì—ì„œ ê¸°ì¨ê³¼ ê¸°íƒ€ê°ì • í˜¼ë™ ì²´í¬\n",
    "        if 'level2' in result['levels']:\n",
    "            level2_probs = result['levels']['level2']['probabilities']\n",
    "            joy_prob = level2_probs.get('ê¸°ì¨', 0)\n",
    "            other_prob = level2_probs.get('ê¸°íƒ€ê°ì •', 0)\n",
    "\n",
    "            # í™•ë¥  ì°¨ì´ê°€ ì‘ìœ¼ë©´ í˜¼í•© ê°ì •ìœ¼ë¡œ íŒë‹¨\n",
    "            prob_diff = abs(joy_prob - other_prob)\n",
    "            \n",
    "            if prob_diff < 0.3:  # 30% ì´í•˜ ì°¨ì´ë©´ í˜¼í•© ê°ì •\n",
    "                analysis[\"complexity_level\"] = \"mixed\"\n",
    "                analysis[\"mixed_emotions\"].append({\n",
    "                    \"emotion\": \"ê¸°ì¨\",\n",
    "                    \"confidence\": joy_prob,\n",
    "                    \"type\": \"positive\"\n",
    "                })\n",
    "                \n",
    "                # Level 3ì—ì„œ ì„¸ë¶€ ê°ì •ë„ ì¶”ê°€\n",
    "                if 'level3' in result['levels']:\n",
    "                    level3_result = result['levels']['level3']\n",
    "                    analysis[\"mixed_emotions\"].append({\n",
    "                        \"emotion\": level3_result['prediction'],\n",
    "                        \"confidence\": level3_result['confidence'],\n",
    "                        \"type\": \"negative_or_neutral\"\n",
    "                    })\n",
    "        if threshold is None:\n",
    "            threshold = self.confidence_threshold\n",
    "            \n",
    "        # ì „ë°˜ì  ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ë³µì¡í•œ ê°ì •ìœ¼ë¡œ ë¶„ë¥˜\n",
    "        if result['final']['confidence'] < threshold:\n",
    "            analysis[\"complexity_level\"] = \"complex\"\n",
    "            analysis[\"uncertainty_indicators\"].append(\n",
    "                f\"ë‚®ì€ ì‹ ë¢°ë„: {result['final']['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        return analysis\n",
    "                \n",
    "    def predict_multi_emotion_threshold(self, text, threshold=None):\n",
    "        \"\"\"ì„ê³„ê°’ ì´ìƒì˜ ëª¨ë“  ê°ì • ë°˜í™˜ (ì™„ì„±ëœ ë²„ì „)\"\"\"\n",
    "        # ì„ê³„ê°’ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ í´ë˜ìŠ¤ ê¸°ë³¸ê°’ ì‚¬ìš©\n",
    "        if threshold is None:\n",
    "            threshold = self.emotion_threshold\n",
    "            \n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"detected_emotions\": [],\n",
    "            \"emotion_combination\": None\n",
    "        }\n",
    "        \n",
    "        # ëª¨ë“  ë‹¨ê³„ì—ì„œ ì„ê³„ê°’ ì´ìƒì¸ ê°ì •ë“¤ ìˆ˜ì§‘\n",
    "        hierarchical_result = self.predict_hierarchical(text)\n",
    "        \n",
    "        all_emotions = []\n",
    "        \n",
    "        # Level 1 ì²´í¬\n",
    "        if 'level1' in hierarchical_result['levels']:\n",
    "            for emotion, prob in hierarchical_result['levels']['level1']['probabilities'].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append({\n",
    "                        'emotion': emotion,\n",
    "                        'probability': prob,\n",
    "                        'level': 1,\n",
    "                        'category': 'conversation_type'\n",
    "                    })\n",
    "        \n",
    "        # Level 2 ì²´í¬ (ê¸°ì¨ vs ê¸°íƒ€ê°ì •)\n",
    "        if 'level2' in hierarchical_result['levels']:\n",
    "            for emotion, prob in hierarchical_result['levels']['level2']['probabilities'].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append({\n",
    "                        'emotion': emotion,\n",
    "                        'probability': prob,\n",
    "                        'level': 2,\n",
    "                        'category': 'emotion_polarity'\n",
    "                    })\n",
    "        \n",
    "        # Level 3 ì²´í¬ (ì„¸ë¶€ ê°ì •)\n",
    "        if 'level3' in hierarchical_result['levels']:\n",
    "            for emotion, prob in hierarchical_result['levels']['level3']['probabilities'].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append({\n",
    "                        'emotion': emotion,\n",
    "                        'probability': prob,\n",
    "                        'level': 3,\n",
    "                        'category': 'specific_emotion'\n",
    "                    })\n",
    "        \n",
    "        result['detected_emotions'] = sorted(all_emotions, key=lambda x: x['probability'], reverse=True)\n",
    "        \n",
    "        # ê°ì • ì¡°í•© ë¶„ì„\n",
    "        result['emotion_combination'] = self._analyze_emotion_combination(all_emotions)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _analyze_emotion_combination(self, emotions):\n",
    "        \"\"\"ê°ì • ì¡°í•© ë¶„ì„\"\"\"\n",
    "        # Level 2ì—ì„œ ê¸°ì¨ê³¼ ê¸°íƒ€ê°ì •ì´ ëª¨ë‘ ì„ê³„ê°’ ì´ìƒì¸ì§€ ì²´í¬\n",
    "        level2_emotions = [e for e in emotions if e['level'] == 2]\n",
    "        level3_emotions = [e for e in emotions if e['level'] == 3]\n",
    "        \n",
    "        combination_type = \"single\"\n",
    "        details = {}\n",
    "        \n",
    "        if len(level2_emotions) >= 2:  # ê¸°ì¨ê³¼ ê¸°íƒ€ê°ì • ë‘˜ ë‹¤ ë†’ì€ í™•ë¥ \n",
    "            joy_emotion = next((e for e in level2_emotions if e['emotion'] == 'ê¸°ì¨'), None)\n",
    "            other_emotion = next((e for e in level2_emotions if e['emotion'] == 'ê¸°íƒ€ê°ì •'), None)\n",
    "            \n",
    "            if joy_emotion and other_emotion:\n",
    "                combination_type = \"ambivalent\"  # ì–‘ê°€ê°ì •\n",
    "                details = {\n",
    "                    \"positive_aspect\": {\n",
    "                        \"emotion\": \"ê¸°ì¨\",\n",
    "                        \"strength\": joy_emotion['probability']\n",
    "                    },\n",
    "                    \"negative_aspect\": {\n",
    "                        \"emotions\": level3_emotions,\n",
    "                        \"primary\": max(level3_emotions, key=lambda x: x['probability']) if level3_emotions else None\n",
    "                    },\n",
    "                    \"conflict_intensity\": abs(joy_emotion['probability'] - other_emotion['probability'])\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            \"type\": combination_type,\n",
    "            \"details\": details\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccf1d9",
   "metadata": {},
   "source": [
    "## ì±—ë´‡ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a362c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import google.generativeai as genai\n",
    "\n",
    "class EmotionChatbot:\n",
    "    def __init__(self, model_dir,llm_provider='openai',confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "        # ê°ì • ë¶„ë¥˜ê¸° ì´ˆê¸°í™”\n",
    "        self.classifier = HierarchicalEmotionClassifier(\n",
    "            model_dir, \n",
    "            confidence_threshold=confidence_threshold,\n",
    "            emotion_threshold=emotion_threshold\n",
    "        )\n",
    "        \n",
    "        # ì„ê³„ê°’ì„ ì±—ë´‡ì—ì„œë„ ì €ì¥ (í•„ìš”ì‹œ ì‚¬ìš©)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.emotion_threshold = emotion_threshold\n",
    "        \n",
    "        try:\n",
    "            if llm_provider == 'openai':\n",
    "            # ì±—ë´‡ ì´ˆê¸°í™”\n",
    "                self.llm = ChatOpenAI(\n",
    "                    model=\"gpt-4o\", \n",
    "                    temperature=0.4, \n",
    "                    max_tokens=1000, \n",
    "                    api_key=api_key\n",
    "                )\n",
    "            elif llm_provider == 'claude':\n",
    "                \n",
    "                self.llm = ChatAnthropic(\n",
    "                    model=\"claude-sonnet-4-20250514\",\n",
    "                    temperature=0.4,\n",
    "                    max_tokens=1000,\n",
    "                    api_key=api_key2\n",
    "                )\n",
    "            elif llm_provider == 'gemini':\n",
    "                \n",
    "                self.llm = genai.GenerativeModel(\n",
    "                    model=\"gemini-pro\",\n",
    "                    temperature=0.4,\n",
    "                    max_tokens=1000,\n",
    "                    api_key=api_key3\n",
    "                )\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "            self.memory = ConversationSummaryBufferMemory(\n",
    "                llm=self.llm,\n",
    "                return_messages=True,\n",
    "                max_token_limit=2000,\n",
    "                memory_key=\"chat_history\",\n",
    "            )\n",
    "\n",
    "            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì • (YAML íŒŒì¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„)\n",
    "            try:\n",
    "                system_prompt = load_prompt(\"prompts/emcprompt3.yaml\", encoding=\"utf-8\")\n",
    "                self.system_prompt_text = system_prompt.template\n",
    "            except:\n",
    "                # ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "                self.system_prompt_text = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ë”°ëœ»í•œ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. \n",
    "ì‚¬ìš©ìì˜ ê°ì •ì„ ê¹Šì´ ì´í•´í•˜ê³  ê³µê°í•˜ë©°, ê±´ì„¤ì ì¸ ëŒ€í™”ë¥¼ í†µí•´ ë„ì›€ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ë³¸ ì§€ì¹¨:\n",
    "1. ì‚¬ìš©ìì˜ ê°ì •ì— ì§„ì‹¬ìœ¼ë¡œ ê³µê°í•˜ê³  ì´í•´ë¥¼ í‘œí˜„í•˜ì„¸ìš”\n",
    "2. íŒë‹¨í•˜ì§€ ë§ê³  ìˆ˜ìš©í•˜ëŠ” ìì„¸ë¥¼ ë³´ì´ì„¸ìš”  \n",
    "3. ì ì ˆí•œ ì§ˆë¬¸ì„ í†µí•´ ì‚¬ìš©ì ìŠ¤ìŠ¤ë¡œ ì„±ì°°í•  ìˆ˜ ìˆë„ë¡ ë„ìš°ì„¸ìš”\n",
    "4. ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”\n",
    "5. ì‚¬ìš©ìì˜ ê°•ì ê³¼ ìì›ì— ì£¼ëª©í•˜ì„¸ìš”\n",
    "\n",
    "ê°ì • ì •ë³´ê°€ ì œê³µë˜ë©´ ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ë”ìš± ì •í™•í•˜ê³  ì ì ˆí•œ ê³µê° ë°˜ì‘ì„ ë³´ì´ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "            self.chat_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", self.system_prompt_text),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ])\n",
    "\n",
    "            self.chain = self.chat_prompt | self.llm\n",
    "            print(\"âœ… ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            raise\n",
    "\n",
    "    def classify_emotion(self, text):\n",
    "        \"\"\"ê¸°ë³¸ ê°ì • ë¶„ë¥˜\"\"\"\n",
    "        return self.classifier.predict_hierarchical(text)\n",
    "\n",
    "    def format_analysis(self, result):\n",
    "        \"\"\"ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…\"\"\"\n",
    "        output = f\"\"\"\n",
    "ğŸ“ ì…ë ¥: {result['original_text']}\n",
    "ğŸ” ì „ì²˜ë¦¬: {result['preprocessed_text']}\n",
    "\n",
    "ğŸ¯ ìµœì¢… ê²°ê³¼: {result['final']['prediction']} (ì‹ ë¢°ë„: {result['final']['confidence']:.4f})\n",
    "ğŸ“Š ì˜ˆì¸¡ ê²½ë¡œ: {' â†’ '.join(result['path'])}\n",
    "\n",
    "ğŸ“ˆ ë‹¨ê³„ë³„ ë¶„ì„:\n",
    "\"\"\"\n",
    "\n",
    "        for level, data in result[\"levels\"].items():\n",
    "            output += f\"\\nğŸ”¸ {data['step']}\\n\"\n",
    "            output += f\"   ê²°ê³¼: {data['prediction']} ({data['confidence']:.4f})\\n\"\n",
    "            output += f\"   í™•ë¥ : \"\n",
    "            for emotion, prob in data[\"probabilities\"].items():\n",
    "                output += f\"{emotion}({prob:.3f}) \"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        return output\n",
    "\n",
    "    def generate_response(self, text):\n",
    "        \"\"\"ê¸°ë³¸ ì±—ë´‡ ì‘ë‹µ ìƒì„± (ë©”ëª¨ë¦¬ ì¶”ê°€)\"\"\"\n",
    "        try:\n",
    "            # ê¸°ë³¸ ê°ì • ë¶„ë¥˜\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            # ê°ì • ë¶„ì„ í¬ë§·íŒ…\n",
    "            emotion_info = f\"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}, ê²½ë¡œ: {' â†’ '.join(emotion_result['path'])}\"\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "            chat_history = self.memory.chat_memory.messages\n",
    "\n",
    "            # ì²´ì¸ ì‹¤í–‰\n",
    "            response = self.chain.invoke({\n",
    "                \"message\": text, \n",
    "                \"emotion_info\": emotion_info,\n",
    "                \"chat_history\": chat_history\n",
    "            })\n",
    "\n",
    "            # ì‘ë‹µ ì¶”ì¶œ\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # ë©”ëª¨ë¦¬ì— ëŒ€í™”ì €ì¥\n",
    "                self.memory.chat_memory.add_user_message(text)\n",
    "                self.memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"ì‘ë‹µìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return \"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    def generate_empathetic_response(self, text):\n",
    "        \"\"\"ë³µí•© ê°ì •ì„ ê³ ë ¤í•œ ê³µê° ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            # ë³µí•© ê°ì • ë¶„ì„\n",
    "            emotion_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "            multi_emotion_result = self.classifier.predict_multi_emotion_threshold(text)\n",
    "            \n",
    "            # ì‘ë‹µ ì „ëµ ê²°ì •\n",
    "            response_strategy = self._determine_response_strategy(emotion_analysis, multi_emotion_result)\n",
    "            \n",
    "            # í”„ë¡¬í”„íŠ¸ì— ë³µí•© ê°ì • ì •ë³´ ì¶”ê°€\n",
    "            emotion_context = self._format_emotion_context(emotion_analysis, multi_emotion_result, response_strategy)\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "            chat_history = self.memory.chat_memory.messages\n",
    "            \n",
    "            # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±\n",
    "            response = self._generate_response_with_complex_emotion_context(\n",
    "                text, emotion_context, chat_history\n",
    "            )\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ê³µê° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return \"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆë„¤ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    \n",
    "    def _determine_response_strategy(self, emotion_analysis, multi_emotion_result):\n",
    "        \"\"\"ì‘ë‹µ ì „ëµ ê²°ì •\"\"\"\n",
    "        if emotion_analysis['complexity_level'] == 'mixed':\n",
    "            if multi_emotion_result['emotion_combination']['type'] == 'ambivalent':\n",
    "                return \"ambivalent_empathy\"  # ì–‘ê°€ê°ì • ê³µê°\n",
    "            else:\n",
    "                return \"mixed_validation\"    # í˜¼í•©ê°ì • ì¸ì •\n",
    "        elif emotion_analysis['complexity_level'] == 'complex':\n",
    "            return \"exploratory_empathy\"     # íƒìƒ‰ì  ê³µê°\n",
    "        else:\n",
    "            return \"direct_empathy\"          # ì§ì ‘ì  ê³µê°\n",
    "    \n",
    "    def _format_emotion_context(self, emotion_analysis, multi_emotion_result, strategy):\n",
    "        \"\"\"ê°ì • ë§¥ë½ í¬ë§·íŒ…\"\"\"\n",
    "        context = {\n",
    "            \"primary_emotion\": emotion_analysis['primary_emotion'],\n",
    "            \"confidence\": emotion_analysis['primary_confidence'],\n",
    "            \"complexity\": emotion_analysis['complexity_level'],\n",
    "            \"response_strategy\": strategy\n",
    "        }\n",
    "        \n",
    "        # ë³µí•© ê°ì • ì •ë³´ ì¶”ê°€\n",
    "        if emotion_analysis['mixed_emotions']:\n",
    "            context[\"mixed_emotions\"] = emotion_analysis['mixed_emotions']\n",
    "        \n",
    "        # ì–‘ê°€ê°ì • ì •ë³´ ì¶”ê°€\n",
    "        if multi_emotion_result['emotion_combination']['type'] == 'ambivalent':\n",
    "            context[\"ambivalent_details\"] = multi_emotion_result['emotion_combination']['details']\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def _generate_response_with_complex_emotion_context(self, text, emotion_context, chat_history):\n",
    "        \"\"\"ë³µí•© ê°ì • ë§¥ë½ì„ ê³ ë ¤í•œ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        \n",
    "        # ì‘ë‹µ ì „ëµë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "        strategy_prompts = {\n",
    "            \"ambivalent_empathy\": \"\"\"\n",
    "ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ìƒë°˜ëœ ê°ì •(ê¸°ì¨ê³¼ ë‹¤ë¥¸ ë¶€ì •ì  ê°ì •)ì„ ë™ì‹œì— ê²½í—˜í•˜ê³  ìˆëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì–‘ê°€ê°ì • ê³µê° ì§€ì¹¨:\n",
    "1. \"ê¸°ìœ ë™ì‹œì— ë³µì¡í•œ ê°ì •ì´ ë“œì‹œëŠ” ê²ƒ ê°™ì•„ìš”\" ê°™ì€ í‘œí˜„ìœ¼ë¡œ ì–‘ë©´ì„±ì„ ì¸ì •\n",
    "2. ë‘ ê°ì • ëª¨ë‘ ìì—°ìŠ¤ëŸ½ê³  ì •ìƒì ì„ì„ ê°•ì¡°\n",
    "3. ê°ì •ì˜ ì¶©ëŒë¡œ ì¸í•œ í˜¼ë€ê°ì— ê³µê°\n",
    "4. ê°ê°ì˜ ê°ì •ì— ëŒ€í•´ ë”°ë¡œ íƒìƒ‰í•´ë³´ë„ë¡ ì•ˆë‚´\n",
    "5. ë”°ëœ»í•˜ê³  ì´í•´í•˜ëŠ” í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”\n",
    "\"\"\",\n",
    "            \n",
    "            \"mixed_validation\": \"\"\"\n",
    "ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì—¬ëŸ¬ ê°ì •ì´ ì„ì¸ ë³µì¡í•œ ìƒíƒœì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "í˜¼í•©ê°ì • ì¸ì • ì§€ì¹¨:\n",
    "1. \"ì—¬ëŸ¬ ê°€ì§€ ê°ì •ì´ í•¨ê»˜ ëŠê»´ì§€ì‹œëŠ”êµ°ìš”\" ê°™ì€ í‘œí˜„ìœ¼ë¡œ ë³µì¡ì„± ì¸ì •\n",
    "2. ê°ì •ì´ ë‹¨ìˆœí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒì„ ì •ìƒí™”\n",
    "3. ê°€ì¥ ê°•í•˜ê²Œ ëŠê»´ì§€ëŠ” ê°ì •ë¶€í„° ì°¨ê·¼ì°¨ê·¼ íƒìƒ‰\n",
    "4. ê° ê°ì •ì˜ ì˜ë¯¸ì™€ ì›ì¸ì— ëŒ€í•´ ê¶ê¸ˆì¦ í‘œí˜„\n",
    "5. íŒë‹¨í•˜ì§€ ì•Šê³  ìˆ˜ìš©í•˜ëŠ” ìì„¸ë¥¼ ë³´ì´ì„¸ìš”\n",
    "\"\"\",\n",
    "            \n",
    "            \"exploratory_empathy\": \"\"\"\n",
    "ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœê°€ ë¶ˆë¶„ëª…í•˜ê±°ë‚˜ ë³µì¡í•´ ë³´ì…ë‹ˆë‹¤.\n",
    "\n",
    "íƒìƒ‰ì  ê³µê° ì§€ì¹¨:\n",
    "1. \"ì§€ê¸ˆ ë§ˆìŒì´ ë³µì¡í•˜ì‹  ê²ƒ ê°™ì•„ìš”\" ê°™ì€ í¬ê´„ì  ê³µê° í‘œí˜„\n",
    "2. ì„±ê¸‰í•œ ê°ì • ë ˆì´ë¸”ë§ í”¼í•˜ê¸°\n",
    "3. ì—´ë¦° ì§ˆë¬¸ìœ¼ë¡œ ê°ì • íƒìƒ‰ ìœ ë„\n",
    "4. ì‚¬ìš©ì ìì‹ ì˜ ê°ì • ì¸ì‹ì„ ë•ëŠ” ë°©í–¥ìœ¼ë¡œ ëŒ€í™” ì§„í–‰\n",
    "5. ì•ˆì „í•˜ê³  í¸ì•ˆí•œ ë¶„ìœ„ê¸° ì¡°ì„±\n",
    "\"\"\",\n",
    "            \n",
    "            \"direct_empathy\": \"\"\"\n",
    "ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê°ì •ì´ ë¹„êµì  ëª…í™•í•´ ë³´ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì§ì ‘ì  ê³µê° ì§€ì¹¨:\n",
    "1. ì¸ì‹ëœ ì£¼ìš” ê°ì •ì— ëŒ€í•´ ì§ì ‘ì ì´ê³  êµ¬ì²´ì ì¸ ê³µê°\n",
    "2. í•´ë‹¹ ê°ì •ì„ ëŠë¼ëŠ” ê²ƒì´ ìì—°ìŠ¤ëŸ½ë‹¤ê³  ì•ˆì‹¬ì‹œí‚¤ê¸°\n",
    "3. ê°ì •ì˜ ì›ì¸ì´ë‚˜ ë§¥ë½ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ê¸°\n",
    "4. ê°ì •ì„ ê±´ê°•í•˜ê²Œ ë‹¤ë£¨ëŠ” ë°©ë²• ì œì•ˆ\n",
    "5. ì‚¬ìš©ìì˜ ê°•ì ê³¼ ìì›ì— ì£¼ëª©\n",
    "\"\"\"\n",
    "        }\n",
    "        \n",
    "        # ê°ì • ì •ë³´ ë¬¸ìì—´ ìƒì„±\n",
    "        emotion_info_str = f\"\"\"\n",
    "ê°ì • ë¶„ì„ ê²°ê³¼:\n",
    "- ì£¼ìš” ê°ì •: {emotion_context['primary_emotion']} (ì‹ ë¢°ë„: {emotion_context['confidence']:.2f})\n",
    "- ë³µì¡ë„: {emotion_context['complexity']}\n",
    "- ì‘ë‹µ ì „ëµ: {emotion_context['response_strategy']}\n",
    "\"\"\"\n",
    "        \n",
    "        if 'mixed_emotions' in emotion_context:\n",
    "            emotion_info_str += \"\\ní˜¼í•© ê°ì •ë“¤:\\n\"\n",
    "            for emotion in emotion_context['mixed_emotions']:\n",
    "                emotion_info_str += f\"- {emotion['emotion']}: {emotion['confidence']:.2f}\\n\"\n",
    "        \n",
    "        if 'ambivalent_details' in emotion_context:\n",
    "            details = emotion_context['ambivalent_details']\n",
    "            emotion_info_str += f\"\\nì–‘ê°€ê°ì • ì„¸ë¶€ì‚¬í•­:\\n\"\n",
    "            emotion_info_str += f\"- ê¸ì •ì  ì¸¡ë©´: {details['positive_aspect']['emotion']} ({details['positive_aspect']['strength']:.2f})\\n\"\n",
    "            if details['negative_aspect']['primary']:\n",
    "                emotion_info_str += f\"- ë¶€ì •ì  ì¸¡ë©´: {details['negative_aspect']['primary']['emotion']} ({details['negative_aspect']['primary']['probability']:.2f})\\n\"\n",
    "        \n",
    "        # ì „ëµì— ë§ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ\n",
    "        system_prompt = strategy_prompts.get(emotion_context['response_strategy'], strategy_prompts['direct_empathy'])\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt + f\"\\n\\n{emotion_info_str}\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{message}\")\n",
    "        ])\n",
    "        \n",
    "        # ì²´ì¸ ì‹¤í–‰\n",
    "        chain = chat_prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"message\": text,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        \n",
    "        if hasattr(response, \"content\"):\n",
    "            ai_response = response.content\n",
    "            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥\n",
    "            self.memory.chat_memory.add_user_message(text)\n",
    "            self.memory.chat_memory.add_ai_message(ai_response)\n",
    "            return ai_response\n",
    "        else:\n",
    "            return \"ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    def process_message(self, text, include_ai_response=True):\n",
    "        \"\"\"ê¸°ë³¸ ë©”ì‹œì§€ ì „ì²´ ì²˜ë¦¬\"\"\"\n",
    "        # ê°ì • ë¶„ì„\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "        emotion_analysis = self.format_analysis(emotion_result)\n",
    "\n",
    "        result = {\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"emotion_result\": emotion_result,\n",
    "        }\n",
    "\n",
    "        # AI ì‘ë‹µ\n",
    "        if include_ai_response:\n",
    "            ai_response = self.generate_response(text)\n",
    "            result[\"ai_response\"] = ai_response\n",
    "            result[\"full_response\"] = f\"{emotion_analysis}\\nğŸ’¬ AI ìƒë‹´:\\n{ai_response}\"\n",
    "        else:\n",
    "            result[\"full_response\"] = emotion_analysis\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def process_complex_emotion_message(self, text):\n",
    "        \"\"\"ë³µí•© ê°ì •ì„ ê³ ë ¤í•œ ë©”ì‹œì§€ ì²˜ë¦¬\"\"\"\n",
    "        # ê¸°ë³¸ ê°ì • ë¶„ì„\n",
    "        basic_result = self.classify_emotion(text)\n",
    "        \n",
    "        # ë³µí•© ê°ì • ë¶„ì„\n",
    "        confidence_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "        multi_emotion_analysis = self.classifier.predict_multi_emotion_threshold(text)\n",
    "        \n",
    "        # ê³µê° ì‘ë‹µ ìƒì„±\n",
    "        ai_response = self.generate_empathetic_response(text)\n",
    "        \n",
    "        # ê²°ê³¼ í†µí•©\n",
    "        result = {\n",
    "            \"basic_emotion_analysis\": self.format_analysis(basic_result),\n",
    "            \"confidence_analysis\": confidence_analysis,\n",
    "            \"multi_emotion_analysis\": multi_emotion_analysis,\n",
    "            \"ai_response\": ai_response,\n",
    "            \"complexity_insight\": self._generate_complexity_insight(confidence_analysis, multi_emotion_analysis),\n",
    "            \"full_response\": f\"\"\"\n",
    "ğŸ“Š ê°ì • ë³µì¡ì„± ë¶„ì„:\n",
    "{chr(10).join(self._generate_complexity_insight(confidence_analysis, multi_emotion_analysis))}\n",
    "\n",
    "ğŸ’¬ AI ìƒë‹´:\n",
    "{ai_response}\n",
    "\"\"\"\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _generate_complexity_insight(self, confidence_analysis, multi_emotion_analysis):\n",
    "        \"\"\"ë³µì¡ì„± ì¸ì‚¬ì´íŠ¸ ìƒì„±\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        if confidence_analysis['complexity_level'] == 'mixed':\n",
    "            insights.append(\"ğŸ”€ í˜¼í•©ëœ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        if multi_emotion_analysis['emotion_combination']['type'] == 'ambivalent':\n",
    "            insights.append(\"âš–ï¸ ìƒë°˜ëœ ê°ì •ì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ëŠ” ì–‘ê°€ê°ì • ìƒíƒœì…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        if confidence_analysis['primary_confidence'] < 0.6:\n",
    "            insights.append(\"ğŸŒŠ ê°ì •ì´ ë³µì¡í•˜ê³  ë¯¸ë¬˜í•œ ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        if len(multi_emotion_analysis['detected_emotions']) > 3:\n",
    "            insights.append(\"ğŸ­ ë‹¤ì–‘í•œ ê°ì •ì´ ë³µí•©ì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        return insights if insights else [\"ğŸ’¡ ë¹„êµì  ëª…í™•í•œ ê°ì • ìƒíƒœì…ë‹ˆë‹¤.\"]\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤\n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"í˜„ì¬ ëŒ€í™” ìš”ì•½ ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        try:\n",
    "            return self.memory.predict_new_summary(self.memory.chat_memory.messages, \"\")\n",
    "        except Exception as e:\n",
    "            print(f\"ëŒ€í™” ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return \"ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    def get_chat_history(self):\n",
    "        \"\"\"ì „ì²´ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        return self.memory.chat_memory.messages\n",
    "\n",
    "    def clear_memory(self):\n",
    "        \"\"\"ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\"\"\"\n",
    "        self.memory.clear()\n",
    "        print(\"ğŸ’­ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    def get_memory_status(self):\n",
    "        \"\"\"ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\"\"\"\n",
    "        try:\n",
    "            messages = self.memory.chat_memory.messages\n",
    "            token_count = self.memory.llm.get_num_tokens_from_messages(messages)\n",
    "\n",
    "            return {\n",
    "                \"message_count\": len(messages),\n",
    "                \"token_count\": token_count,\n",
    "                \"max_token_limit\": self.memory.max_token_limit,\n",
    "                \"is_summarizing\": token_count > self.memory.max_token_limit,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return {\n",
    "                \"message_count\": 0,\n",
    "                \"token_count\": 0,\n",
    "                \"max_token_limit\": self.memory.max_token_limit,\n",
    "                \"is_summarizing\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def set_thresholds(self, confidence_threshold=None, emotion_threshold=None):\n",
    "        \"\"\"ì„ê³„ê°’ ë™ì  ë³€ê²½\"\"\"\n",
    "        if confidence_threshold is not None:\n",
    "            self.confidence_threshold = confidence_threshold\n",
    "            self.classifier.confidence_threshold = confidence_threshold\n",
    "            print(f\"ì‹ ë¢°ë„ ì„ê³„ê°’ì´ {confidence_threshold}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        if emotion_threshold is not None:\n",
    "            self.emotion_threshold = emotion_threshold\n",
    "            self.classifier.emotion_threshold = emotion_threshold\n",
    "            print(f\"ê°ì • íƒì§€ ì„ê³„ê°’ì´ {emotion_threshold}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    def get_thresholds(self):\n",
    "        \"\"\"í˜„ì¬ ì„ê³„ê°’ ì¡°íšŒ\"\"\"\n",
    "        return {\n",
    "            \"confidence_threshold\": self.confidence_threshold,\n",
    "            \"emotion_threshold\": self.emotion_threshold\n",
    "        }\n",
    "\n",
    "\n",
    "# ì±—ë´‡ ìƒì„± í—¬í¼ í•¨ìˆ˜\n",
    "def create_chatbot(model_dir,llm_provider,confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "    \"\"\"ì±—ë´‡ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        return EmotionChatbot(\n",
    "            model_dir, \n",
    "            confidence_threshold=confidence_threshold,\n",
    "            emotion_threshold=emotion_threshold\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì±—ë´‡ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91405ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ë””ë ‰í† ë¦¬: /Users/hwangeunbi/chatnge_AI/chat/model\n",
      "ë””ë°”ì´ìŠ¤: mps\n",
      "ì‹ ë¢°ë„ ì„ê³„ê°’: 0.6\n",
      "ê°ì • íƒì§€ ì„ê³„ê°’: 0.3\n",
      "1ë‹¨ê³„ : íŒŒì¼ í™•ì¸\n",
      "âœ… level1_best_model.pt íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level2_best_model.pt íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level3_best_model.pt íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level1_label_encoder.pkl íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level2_label_encoder.pkl íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level3_label_encoder.pkl íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "2ë‹¨ê³„: ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ\n",
      "level1_label_encoder.pkl íŒŒì¼ì—ì„œ level1_encoder ë¡œë“œ ì™„ë£Œ\n",
      "level2_label_encoder.pkl íŒŒì¼ì—ì„œ level2_encoder ë¡œë“œ ì™„ë£Œ\n",
      "level3_label_encoder.pkl íŒŒì¼ì—ì„œ level3_encoder ë¡œë“œ ì™„ë£Œ\n",
      "3ë‹¨ê³„: BERT ëª¨ë¸ ë¡œë“œ\n",
      "BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ˜Š ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì¤‘...\n",
      "  ğŸ”„ level1_best_model.pt ë¡œë“œ ì¤‘...\n",
      "  âœ… level1_best_model.pt ë¡œë“œ ì™„ë£Œ\n",
      "  ğŸ”„ level2_best_model.pt ë¡œë“œ ì¤‘...\n",
      "  âœ… level2_best_model.pt ë¡œë“œ ì™„ë£Œ\n",
      "  ğŸ”„ level3_best_model.pt ë¡œë“œ ì¤‘...\n",
      "  âœ… level3_best_model.pt ë¡œë“œ ì™„ë£Œ\n",
      "âœ… ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "âœ… ì±—ë´‡ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ì¢‹ì€ ì¼ì´ ìˆì—ˆë‹¤ë‹ˆ ì •ë§ ê¸°ì˜ë„¤ìš”. í•˜ì§€ë§Œ ë­”ê°€ ì•„ì‰¬ìš´ ë§ˆìŒì´ ë“œëŠ” ê²ƒ ê°™êµ°ìš”. ê·¸ ì¢‹ì€ ì¼ì´ ì–´ë–¤ ê²ƒì´ì—ˆëŠ”ì§€, ê·¸ë¦¬ê³  ë¬´ì—‡ì´ ì•„ì‰¬ì› ëŠ”ì§€ ì¡°ê¸ˆ ë” ì´ì•¼ê¸°í•´ ì¤„ ìˆ˜ ìˆì„ê¹Œìš”? ê·¸ëŸ° ê°ì •ì´ ë“œëŠ” ì´ìœ ê°€ ë¬´ì—‡ì¸ì§€ í•¨ê»˜ íƒìƒ‰í•´ë³´ë©´ ì¢‹ê² ì–´ìš”.\n",
      "\n",
      "ğŸ“Š ê°ì • ë³µì¡ì„± ë¶„ì„:\n",
      "ğŸŒŠ ê°ì •ì´ ë³µì¡í•˜ê³  ë¯¸ë¬˜í•œ ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ’¬ AI ìƒë‹´:\n",
      "ê¸°ìœ ì¼ì´ ìˆìœ¼ë©´ì„œë„ ë™ì‹œì— ê±±ì •ì´ ë˜ëŠ” ë§ˆìŒì´ ë“œëŠ”êµ°ìš”. ì´ëŸ° ë³µí•©ì ì¸ ê°ì •ì„ ëŠë¼ëŠ” ê±´ ì•„ì£¼ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ì´ì—ìš”. ê¸°ìœ ì¼ì´ë€ ì–´ë–¤ ê²ƒì´ì—ˆê³ , ê·¸ì™€ ê´€ë ¨ëœ ì–´ë–¤ ì ì´ ê±±ì •ì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. í˜¹ì‹œ ê·¸ ê±±ì •ì„ ì¡°ê¸ˆ ëœ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆì„ê¹Œìš”? í•¨ê»˜ ê³ ë¯¼í•´ë³´ë©´ ì¢‹ê² ì–´ìš”.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # ì±—ë´‡ ìƒì„±\n",
    "    model_dir = \"/Users/hwangeunbi/chatnge_AI/chat/model\" \n",
    "    chatbot = create_chatbot(model_dir, llm_provider=\"gemini\")\n",
    "    \n",
    "    if chatbot:\n",
    "        print(\"âœ… ì±—ë´‡ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # ê¸°ë³¸ ì‚¬ìš©\n",
    "        result = chatbot.process_message(\"ì˜¤ëŠ˜ ì¢‹ì€ ì¼ì´ ìˆì—ˆëŠ”ë° ë­”ê°€ ì•„ì‰¬ì›Œ\")\n",
    "        print(result['ai_response'])\n",
    "        \n",
    "        # ë³µí•© ê°ì • ë¶„ì„ ì‚¬ìš©\n",
    "        complex_result = chatbot.process_complex_emotion_message(\"ê¸°ì˜ë©´ì„œë„ ê±±ì •ë¼\")\n",
    "        print(complex_result['full_response'])\n",
    "    else:\n",
    "        print(\"âŒ ì±—ë´‡ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatnge-ai-rActT2Je-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
