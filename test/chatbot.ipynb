{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ce73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.get_default_device() í•¨ìˆ˜ê°€ ì—†ë‹¤ê³  ë– ì„œ ëŒ€ì²´ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "\n",
    "def _get_default_device():\n",
    "    \"\"\"torch.get_default_device() ëŒ€ì²´ í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    # gpuê°€ ìˆìœ¼ë©´ cuda ë””ë°”ì´ìŠ¤ë¡œ ë°˜í™˜\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # apple m1,m2 ì¹©ì´ ìˆìœ¼ë©´ mps ë””ë°”ì´ìŠ¤ë¡œ ë°˜í™˜\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    # ê·¸ ì™¸ëŠ” cpu ë””ë°”ì´ìŠ¤ë¡œ ë°˜í™˜\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617dbce",
   "metadata": {},
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898ce71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "chatnge_ai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_teddynote import logging\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from langchain_core.prompts import load_prompt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# í´ë¡œë“œ api í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# ì œë¯¸ë‚˜ì´ api í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "api_key3 = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"chatnge_ai\")\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b0fe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0435c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer ì„í¬íŠ¸ ì „ì— í™˜ê²½ ì„¤ì •\n",
    "\n",
    "# transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì˜¨ë¼ì¸ ëª¨ë“œë¡œ ë™ì‘í•˜ë„ë¡ ì„¤ì •\n",
    "## ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì„¤ì •\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "# KLUE/BERT ëª¨ë¸ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Hugging Face ëª¨ë¸ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b638caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel, logging as transformers_logging\n",
    "\n",
    "    transformers_logging.set_verbosity_error()  # ê²½ê³  ë©”ì‹œì§€ ìµœì†Œí™”\n",
    "    print(\"âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"pip install transformersë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torchì— ì—†ëŠ” í•¨ìˆ˜ ì¶”ê°€\n",
    "torch.get_default_device = _get_default_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707289",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸\n",
    "KOREAN_STOPWORDS = [\n",
    "    \"ì´\",\n",
    "    \"ê·¸\",\n",
    "    \"ì €\",\n",
    "    \"ê²ƒ\",\n",
    "    \"ë°\",\n",
    "    \"ì—\",\n",
    "    \"ë¥¼\",\n",
    "    \"ì€\",\n",
    "    \"ëŠ”\",\n",
    "    \"ì´ëŸ°\",\n",
    "    \"ì €ëŸ°\",\n",
    "    \"ê·¸ëŸ°\",\n",
    "    \"í•œ\",\n",
    "    \"ì´ë¥´\",\n",
    "    \"ë˜í•œ\",\n",
    "    \"ìˆ\",\n",
    "    \"í•˜\",\n",
    "    \"ì—ì„œ\",\n",
    "    \"ìœ¼ë¡œ\",\n",
    "    \"ìœ¼ë¡œì¨\",\n",
    "    \"ë¡œì¨\",\n",
    "    \"ë¡œì„œ\",\n",
    "    \"ë¡œ\",\n",
    "    \"ì™€\",\n",
    "    \"ê³¼\",\n",
    "    \"ì´ê³ \",\n",
    "    \"ì´ë©°\",\n",
    "    \"ì´ë‹¤\",\n",
    "    \"ìˆë‹¤\",\n",
    "    \"í•˜ë‹¤\",\n",
    "    \"ë˜ë‹¤\",\n",
    "    \"ì´\",\n",
    "    \"ê°€\",\n",
    "    \"ì„\",\n",
    "    \"ë¥¼\",\n",
    "    \"ì—ê²Œ\",\n",
    "    \"ì˜\",\n",
    "    \"ë¿\",\n",
    "    \"ë‹¤\",\n",
    "    \"ì \",\n",
    "    \"ë°\",\n",
    "    \"ë•Œ\",\n",
    "    \"ë‚˜\",\n",
    "    \"ë„\",\n",
    "    \"ë§Œ\",\n",
    "    \"ê»˜\",\n",
    "    \"ì—ê²Œì„œ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6f6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "def preprocess_korean_text(text):\n",
    "    # ë§Œì•½ì— í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë¹ˆì¹¸ ë°˜í™˜\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # ë°˜ë³µ ë¬¸ì ì •ê·œí™”\n",
    "    text = re.sub(r\"[^ê°€-í£a-zA-Z0-9\\s\\.,!?]\", \" \", text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # ê³µë°± ì •ë¦¬\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stopwords=KOREAN_STOPWORDS):\n",
    "    \"\"\"ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆìš©ì–´ ì œê±°\"\"\"\n",
    "    # ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë°˜í™˜\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95013df4",
   "metadata": {},
   "source": [
    "## ê°ì • ë¶„ë¥˜ê¸° ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(torch.nn.Module):\n",
    "    \"\"\"ê°ì • ë¶„ë¥˜ê¸° ëª¨ë¸ - BERT ê¸°ë°˜ì˜ ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹ ê²½ë§ ëª¨ë¸\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model, num_classes, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        ëª¨ë¸ ì´ˆê¸°í™”\n",
    "\n",
    "        Args:\n",
    "            bert_model: ì‚¬ì „ í›ˆë ¨ëœ BERT ëª¨ë¸ (ì˜ˆ: BertModel)\n",
    "            num_classes: ë¶„ë¥˜í•  ê°ì • í´ë˜ìŠ¤ì˜ ê°œìˆ˜\n",
    "            dropout_rate: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.3)\n",
    "        \"\"\"\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "\n",
    "        # BERT ëª¨ë¸ì„ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©\n",
    "        self.bert = bert_model\n",
    "        # BERTì˜ íˆë“  ì‚¬ì´ì¦ˆ (ì¼ë°˜ì ìœ¼ë¡œ 768)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´\n",
    "        self.dropout1 = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜: ê° í† í°ì˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°\n",
    "        self.attention = torch.nn.Sequential(\n",
    "            # íˆë“  ì‚¬ì´ì¦ˆë¥¼ 256ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # Tanh í™œì„±í™” í•¨ìˆ˜ë¡œ ë¹„ì„ í˜•ì„± ì¶”ê°€\n",
    "            torch.nn.Tanh(),\n",
    "            # 256ì°¨ì›ì„ 1ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ì—¬ ì–´í…ì…˜ ìŠ¤ì½”ì–´ ìƒì„±\n",
    "            torch.nn.Linear(256, 1),\n",
    "            # Softmaxë¡œ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        # ìµœì¢… ë¶„ë¥˜ë¥¼ ìœ„í•œ ë¶„ë¥˜ê¸°\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # íˆë“  ì‚¬ì´ì¦ˆë¥¼ 256ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # ReLU í™œì„±í™” í•¨ìˆ˜\n",
    "            torch.nn.ReLU(),\n",
    "            # ë°°ì¹˜ ì •ê·œí™”ë¡œ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            # ë“œë¡­ì•„ì›ƒìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            # ìµœì¢… ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜ë§Œí¼ ì¶œë ¥\n",
    "            torch.nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        ìˆœì „íŒŒ ê³¼ì •\n",
    "\n",
    "        Args:\n",
    "            input_ids: í† í¬ë‚˜ì´ì§•ëœ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ID\n",
    "            attention_mask: íŒ¨ë”© í† í°ì„ ë¬´ì‹œí•˜ê¸° ìœ„í•œ ë§ˆìŠ¤í¬\n",
    "            token_type_ids: ë¬¸ì¥ êµ¬ë¶„ì„ ìœ„í•œ í† í° íƒ€ì… ID\n",
    "\n",
    "        Returns:\n",
    "            logits: ê° ê°ì • í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜\n",
    "        \"\"\"\n",
    "        # BERT ëª¨ë¸ì— ì…ë ¥ì„ í†µê³¼ì‹œì¼œ ì„ë² ë”© ìƒì„±\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True,  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°˜í™˜\n",
    "        )\n",
    "\n",
    "        # ëª¨ë“  í† í°ì˜ íˆë“  ìƒíƒœ (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, íˆë“  í¬ê¸°)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        # [CLS] í† í°ì˜ í’€ë§ëœ í‘œí˜„ (ë°°ì¹˜ í¬ê¸°, íˆë“  í¬ê¸°)\n",
    "        pooled_output = outputs.pooler_output\n",
    "\n",
    "        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°: ê° í† í°ì˜ ì¤‘ìš”ë„ ê²°ì •\n",
    "        attention_weights = self.attention(sequence_output)\n",
    "\n",
    "        # ê°€ì¤‘í•©ì„ í†µí•´ ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ìƒì„±\n",
    "        # attention_weightsì™€ sequence_outputì„ ê³±í•˜ê³  ì‹œí€€ìŠ¤ ì°¨ì›ì„ ë”°ë¼ í•©ì‚°\n",
    "        context_vector = torch.sum(attention_weights * sequence_output, dim=1)\n",
    "\n",
    "        # ì–´í…ì…˜ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ì™€ BERTì˜ í’€ë§ ì¶œë ¥ì„ ê²°í•©\n",
    "        # ë‘ í‘œí˜„ì„ ë”í•´ì„œ ë” í’ë¶€í•œ í‘œí˜„ ìƒì„±\n",
    "        final_output = context_vector + pooled_output\n",
    "\n",
    "        # ë“œë¡­ì•„ì›ƒ ì ìš©í•˜ì—¬ ê³¼ì í•© ë°©ì§€\n",
    "        final_output = self.dropout1(final_output)\n",
    "\n",
    "        # ë¶„ë¥˜ê¸°ë¥¼ í†µê³¼ì‹œì¼œ ìµœì¢… ë¡œì§“ ê³„ì‚°\n",
    "        logits = self.classifier(final_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba10aed",
   "metadata": {},
   "source": [
    "## ê³„ì¸µì  ê°ì • ë¶„ë¥˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7057fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalEmotionClassifier:\n",
    "    def __init__(self, model_dir, confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "\n",
    "        self.model_dir = model_dir  # ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "        self.device = _get_default_device()  # ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "        self.max_len = 128  # ìµœëŒ€ ê¸¸ì´ ì„¤ì •ã…\n",
    "\n",
    "        # ë””ë²„ê¹…ìš©\n",
    "        print(f\"ëª¨ë¸ ë””ë ‰í† ë¦¬: {self.model_dir}\")\n",
    "        print(f\"ë””ë°”ì´ìŠ¤: {self.device}\")\n",
    "\n",
    "        # ì„ê³„ê°’ ì„¤ì •\n",
    "        self.confidence_threshold = confidence_threshold  # ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    "        self.emotion_threshold = emotion_threshold  # ê°ì • íƒì§€ ì„ê³„ê°’\n",
    "\n",
    "        print(f\"ì‹ ë¢°ë„ ì„ê³„ê°’: {self.confidence_threshold}\")\n",
    "        print(f\"ê°ì • íƒì§€ ì„ê³„ê°’: {self.emotion_threshold}\")\n",
    "\n",
    "        # ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "        self.tokenizer = None\n",
    "        self.bert_model = None\n",
    "        self.level1_model = None\n",
    "        self.level2_model = None\n",
    "        self.level3_model = None\n",
    "        self.level1_labels = None\n",
    "        self.level2_labels = None\n",
    "        self.level3_labels = None\n",
    "\n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        self._load_models()\n",
    "\n",
    "    def _check_files(self):\n",
    "        print(\"1ë‹¨ê³„ : íŒŒì¼ í™•ì¸\")\n",
    "        # í•„ìˆ˜ íŒŒì¼ë“¤ ì •ì˜\n",
    "        required_files = [\n",
    "            \"level1_best_model.pt\",\n",
    "            \"level2_best_model.pt\",\n",
    "            \"level3_best_model.pt\",\n",
    "            \"level1_label_encoder.pkl\",\n",
    "            \"level2_label_encoder.pkl\",\n",
    "            \"level3_label_encoder.pkl\",\n",
    "        ]\n",
    "\n",
    "        # ì—†ëŠ” íŒŒì¼ í™•ì¸ ë¦¬ìŠ¤íŠ¸\n",
    "        missing_files = []\n",
    "\n",
    "        for file in required_files:\n",
    "            filepath = os.path.join(self.model_dir, file)\n",
    "            if not os.path.exists(filepath):\n",
    "                missing_files.append(file)\n",
    "            else:\n",
    "                print(f\"âœ… {file} íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        # ë§Œì•½ì— ëˆ„ë½ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ\n",
    "        if missing_files:\n",
    "            raise FileExistsError(f\"íŒŒì¼ ëˆ„ë½ ëª©ë¡:{missing_files}\")\n",
    "\n",
    "    # ë¼ë²¨ ì¸ì½”í„° ë¡œë“œ\n",
    "    def _load_label_encoders(self):\n",
    "        print(\"2ë‹¨ê³„: ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ\")\n",
    "\n",
    "        encoders = [\n",
    "            (\"level1_label_encoder.pkl\", \"level1_encoder\"),\n",
    "            (\"level2_label_encoder.pkl\", \"level2_encoder\"),\n",
    "            (\"level3_label_encoder.pkl\", \"level3_encoder\"),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name in encoders:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                encoder = pickle.load(f)\n",
    "                setattr(self, attr_name, encoder)\n",
    "            print(f\"{filename} íŒŒì¼ì—ì„œ {attr_name} ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "    # 3ë‹¨ê³„ bert ëª¨ë¸ ë¡œë“œ\n",
    "    def _load_bert_model(self):\n",
    "\n",
    "        try:\n",
    "            print(\"3ë‹¨ê³„: BERT ëª¨ë¸ ë¡œë“œ\")\n",
    "            # BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "            self.bert_model = AutoModel.from_pretrained(\"klue/bert-base\")\n",
    "\n",
    "            # ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "            self.bert_model = self.bert_model.to(self.device)\n",
    "            print(\"BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            raise ImportError(\n",
    "                \"BERT ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. 'transformers' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\"\n",
    "            )\n",
    "\n",
    "    def _load_emotion_models(self):\n",
    "        \"\"\"ê°ì • ë¶„ë¥˜ ëª¨ë¸ë“¤ ë¡œë“œ\"\"\"\n",
    "        print(\"ğŸ˜Š ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "        models = [\n",
    "            (\"level1_best_model.pt\", \"level1_model\", self.level1_encoder),\n",
    "            (\"level2_best_model.pt\", \"level2_model\", self.level2_encoder),\n",
    "            (\"level3_best_model.pt\", \"level3_model\", self.level3_encoder),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name, encoder in models:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "\n",
    "            print(f\"  ğŸ”„ {filename} ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "            # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "            model = EmotionClassifier(\n",
    "                copy.deepcopy(self.bert_model.to(\"cpu\")), len(encoder.classes_)\n",
    "            )\n",
    "\n",
    "            # ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "            try:\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n",
    "            except TypeError:  # êµ¬ë²„ì „ PyTorch\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\")\n",
    "\n",
    "            model.load_state_dict(state_dict)\n",
    "\n",
    "            # ë””ë°”ì´ìŠ¤ ì´ë™ ë° í‰ê°€ ëª¨ë“œ\n",
    "            model = model.to(self.device)\n",
    "            model.eval()\n",
    "\n",
    "            setattr(self, attr_name, model)\n",
    "            print(f\"  âœ… {filename} ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "    def _load_models(self):\n",
    "        \"\"\"ëª¨ë“  ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            # 1ë‹¨ê³„ : íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "            self._check_files()\n",
    "\n",
    "            # 2ë‹¨ê³„ : ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ\n",
    "            self._load_label_encoders()\n",
    "\n",
    "            # 3ë‹¨ê³„\n",
    "            self._load_bert_model()\n",
    "\n",
    "            # 4ë‹¨ê³„\n",
    "            self._load_emotion_models()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            raise\n",
    "\n",
    "    # ë‹¨ì¼ ëª¨ë¸ ë¶„ë¥˜\n",
    "    def _predict_single(self, model, text):\n",
    "        # ì „ì²˜ë¦¬\n",
    "        preprocessed = preprocess_korean_text(text)\n",
    "        preprocessed = remove_stopwords(preprocessed)\n",
    "\n",
    "        # í† í°í™”\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            preprocessed,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "        input_ids = encoding[\"input_ids\"].to(self.device)\n",
    "        attention_mask = encoding[\"attention_mask\"].to(self.device)\n",
    "        token_type_ids = encoding[\"token_type_ids\"].to(self.device)\n",
    "\n",
    "        # ì˜ˆì¸¡\n",
    "        with torch.no_grad():  # ê·¸ë˜ë””ì–´ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” : ë©”ëª¨ë¦¬ ì ˆì•½ + ì†ë„ í–¥ìƒ\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)  # ë¡œì§“ ì¶œë ¥\n",
    "            probs = torch.nn.functional.softmax(\n",
    "                outputs, dim=1\n",
    "            )  # í™•ë¥  ë³€í™˜, ê° í´ë˜ìŠ¤ë³„ í™•ë¥ ê°’\n",
    "            _, preds = torch.max(outputs, dim=1)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ ì„ íƒ\n",
    "\n",
    "        return preds.item(), probs[0]\n",
    "\n",
    "    # ê³„ì¸µì  ê°ì • ë¶„ë¥˜\n",
    "    def predict_hierarchical(self, text):\n",
    "        \"\"\"ê³„ì¸µì  ì˜ˆì¸¡\"\"\"\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"levels\": {},\n",
    "        }\n",
    "\n",
    "        # 1ë‹¨ê³„\n",
    "        pred1, probs1 = self._predict_single(self.level1_model, text)\n",
    "        label1 = self.level1_encoder.inverse_transform([pred1])[0]\n",
    "\n",
    "        result[\"levels\"][\"level1\"] = {\n",
    "            \"step\": \"1ë‹¨ê³„: ì¼ë°˜ëŒ€í™” vs ê°ì •\",\n",
    "            \"prediction\": label1,\n",
    "            \"confidence\": float(probs1[pred1]),\n",
    "            \"probabilities\": {\n",
    "                self.level1_encoder.classes_[i]: float(probs1[i])\n",
    "                for i in range(len(self.level1_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label1 == \"ì¼ë°˜ëŒ€í™”\":\n",
    "            result[\"final\"] = {\n",
    "                \"prediction\": \"ì¼ë°˜ëŒ€í™”\",\n",
    "                \"confidence\": float(probs1[pred1]),\n",
    "            }\n",
    "            result[\"path\"] = [\"ì¼ë°˜ëŒ€í™”\"]\n",
    "            return result\n",
    "\n",
    "        # 2ë‹¨ê³„\n",
    "        pred2, probs2 = self._predict_single(self.level2_model, text)\n",
    "        label2 = self.level2_encoder.inverse_transform([pred2])[0]\n",
    "\n",
    "        result[\"levels\"][\"level2\"] = {\n",
    "            \"step\": \"2ë‹¨ê³„: ê¸°ì¨ vs ê¸°íƒ€ê°ì •\",\n",
    "            \"prediction\": label2,\n",
    "            \"confidence\": float(probs2[pred2]),\n",
    "            \"probabilities\": {\n",
    "                self.level2_encoder.classes_[i]: float(probs2[i])\n",
    "                for i in range(len(self.level2_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label2 == \"ê¸°ì¨\":\n",
    "            result[\"final\"] = {\"prediction\": \"ê¸°ì¨\", \"confidence\": float(probs2[pred2])}\n",
    "            result[\"path\"] = [\"ê°ì •\", \"ê¸°ì¨\"]\n",
    "            return result\n",
    "\n",
    "        # 3ë‹¨ê³„\n",
    "        pred3, probs3 = self._predict_single(self.level3_model, text)\n",
    "        label3 = self.level3_encoder.inverse_transform([pred3])[0]\n",
    "\n",
    "        result[\"levels\"][\"level3\"] = {\n",
    "            \"step\": \"3ë‹¨ê³„: ì„¸ë¶€ ê°ì • ë¶„ë¥˜\",\n",
    "            \"prediction\": label3,\n",
    "            \"confidence\": float(probs3[pred3]),\n",
    "            \"probabilities\": {\n",
    "                self.level3_encoder.classes_[i]: float(probs3[i])\n",
    "                for i in range(len(self.level3_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        result[\"final\"] = {\"prediction\": label3, \"confidence\": float(probs3[pred3])}\n",
    "        result[\"path\"] = [\"ê°ì •\", \"ê¸°íƒ€ê°ì •\", label3]\n",
    "\n",
    "        return result\n",
    "\n",
    "    # ì‹ ë¢°ë„ ê¸°ë°˜ ë³µí•© ê°ì • ë¶„ì„\n",
    "    def predict_with_confidence_analysis(self, text, threshold=0.55):\n",
    "        result = self.predict_hierarchical(text)\n",
    "\n",
    "        # ê° ë‹¨ê³„ë³„ ì‹ ë¢°ë„ ë¶„ì„\n",
    "        analysis = {\n",
    "            \"original_text\": text,\n",
    "            \"complexity_level\": \"simple\",  # simple, mixed, complex\n",
    "            \"primary_emotion\": result[\"final\"][\"prediction\"],\n",
    "            \"primary_confidence\": result[\"final\"][\"confidence\"],\n",
    "            \"mixed_emotions\": [],\n",
    "            \"uncertainty_indicators\": [],\n",
    "        }\n",
    "\n",
    "        # Level 2ì—ì„œ ê¸°ì¨ê³¼ ê¸°íƒ€ê°ì • í˜¼ë™ ì²´í¬\n",
    "        if \"level2\" in result[\"levels\"]:\n",
    "            level2_probs = result[\"levels\"][\"level2\"][\"probabilities\"]\n",
    "            joy_prob = level2_probs.get(\"ê¸°ì¨\", 0)\n",
    "            other_prob = level2_probs.get(\"ê¸°íƒ€ê°ì •\", 0)\n",
    "\n",
    "            # í™•ë¥  ì°¨ì´ê°€ ì‘ìœ¼ë©´ í˜¼í•© ê°ì •ìœ¼ë¡œ íŒë‹¨\n",
    "            prob_diff = abs(joy_prob - other_prob)\n",
    "\n",
    "            if prob_diff < 0.3:  # 30% ì´í•˜ ì°¨ì´ë©´ í˜¼í•© ê°ì •\n",
    "                analysis[\"complexity_level\"] = \"mixed\"\n",
    "                analysis[\"mixed_emotions\"].append(\n",
    "                    {\"emotion\": \"ê¸°ì¨\", \"confidence\": joy_prob, \"type\": \"positive\"}\n",
    "                )\n",
    "\n",
    "                # Level 3ì—ì„œ ì„¸ë¶€ ê°ì •ë„ ì¶”ê°€\n",
    "                if \"level3\" in result[\"levels\"]:\n",
    "                    level3_result = result[\"levels\"][\"level3\"]\n",
    "                    analysis[\"mixed_emotions\"].append(\n",
    "                        {\n",
    "                            \"emotion\": level3_result[\"prediction\"],\n",
    "                            \"confidence\": level3_result[\"confidence\"],\n",
    "                            \"type\": \"negative_or_neutral\",\n",
    "                        }\n",
    "                    )\n",
    "        if threshold is None:\n",
    "            threshold = self.confidence_threshold\n",
    "\n",
    "        # ì „ë°˜ì  ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ë³µì¡í•œ ê°ì •ìœ¼ë¡œ ë¶„ë¥˜\n",
    "        if result[\"final\"][\"confidence\"] < threshold:\n",
    "            analysis[\"complexity_level\"] = \"complex\"\n",
    "            analysis[\"uncertainty_indicators\"].append(\n",
    "                f\"ë‚®ì€ ì‹ ë¢°ë„: {result['final']['confidence']:.3f}\"\n",
    "            )\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def predict_multi_emotion_threshold(self, text, threshold=None):\n",
    "        \"\"\"ì„ê³„ê°’ ì´ìƒì˜ ëª¨ë“  ê°ì • ë°˜í™˜ (ì™„ì„±ëœ ë²„ì „)\"\"\"\n",
    "        # ì„ê³„ê°’ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ í´ë˜ìŠ¤ ê¸°ë³¸ê°’ ì‚¬ìš©\n",
    "        if threshold is None:\n",
    "            threshold = self.emotion_threshold\n",
    "\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"detected_emotions\": [],\n",
    "            \"emotion_combination\": None,\n",
    "        }\n",
    "\n",
    "        # ëª¨ë“  ë‹¨ê³„ì—ì„œ ì„ê³„ê°’ ì´ìƒì¸ ê°ì •ë“¤ ìˆ˜ì§‘\n",
    "        hierarchical_result = self.predict_hierarchical(text)\n",
    "\n",
    "        all_emotions = []\n",
    "\n",
    "        # Level 1 ì²´í¬\n",
    "        if \"level1\" in hierarchical_result[\"levels\"]:\n",
    "            for emotion, prob in hierarchical_result[\"levels\"][\"level1\"][\n",
    "                \"probabilities\"\n",
    "            ].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append(\n",
    "                        {\n",
    "                            \"emotion\": emotion,\n",
    "                            \"probability\": prob,\n",
    "                            \"level\": 1,\n",
    "                            \"category\": \"conversation_type\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Level 2 ì²´í¬ (ê¸°ì¨ vs ê¸°íƒ€ê°ì •)\n",
    "        if \"level2\" in hierarchical_result[\"levels\"]:\n",
    "            for emotion, prob in hierarchical_result[\"levels\"][\"level2\"][\n",
    "                \"probabilities\"\n",
    "            ].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append(\n",
    "                        {\n",
    "                            \"emotion\": emotion,\n",
    "                            \"probability\": prob,\n",
    "                            \"level\": 2,\n",
    "                            \"category\": \"emotion_polarity\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Level 3 ì²´í¬ (ì„¸ë¶€ ê°ì •)\n",
    "        if \"level3\" in hierarchical_result[\"levels\"]:\n",
    "            for emotion, prob in hierarchical_result[\"levels\"][\"level3\"][\n",
    "                \"probabilities\"\n",
    "            ].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append(\n",
    "                        {\n",
    "                            \"emotion\": emotion,\n",
    "                            \"probability\": prob,\n",
    "                            \"level\": 3,\n",
    "                            \"category\": \"specific_emotion\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        result[\"detected_emotions\"] = sorted(\n",
    "            all_emotions, key=lambda x: x[\"probability\"], reverse=True\n",
    "        )\n",
    "\n",
    "        # ê°ì • ì¡°í•© ë¶„ì„\n",
    "        result[\"emotion_combination\"] = self._analyze_emotion_combination(all_emotions)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _analyze_emotion_combination(self, emotions):\n",
    "        \"\"\"ê°ì • ì¡°í•© ë¶„ì„\"\"\"\n",
    "        # Level 2ì—ì„œ ê¸°ì¨ê³¼ ê¸°íƒ€ê°ì •ì´ ëª¨ë‘ ì„ê³„ê°’ ì´ìƒì¸ì§€ ì²´í¬\n",
    "        level2_emotions = [e for e in emotions if e[\"level\"] == 2]\n",
    "        level3_emotions = [e for e in emotions if e[\"level\"] == 3]\n",
    "\n",
    "        combination_type = \"single\"\n",
    "        details = {}\n",
    "\n",
    "        if len(level2_emotions) >= 2:  # ê¸°ì¨ê³¼ ê¸°íƒ€ê°ì • ë‘˜ ë‹¤ ë†’ì€ í™•ë¥ \n",
    "            joy_emotion = next(\n",
    "                (e for e in level2_emotions if e[\"emotion\"] == \"ê¸°ì¨\"), None\n",
    "            )\n",
    "            other_emotion = next(\n",
    "                (e for e in level2_emotions if e[\"emotion\"] == \"ê¸°íƒ€ê°ì •\"), None\n",
    "            )\n",
    "\n",
    "            if joy_emotion and other_emotion:\n",
    "                combination_type = \"ambivalent\"  # ì–‘ê°€ê°ì •\n",
    "                details = {\n",
    "                    \"positive_aspect\": {\n",
    "                        \"emotion\": \"ê¸°ì¨\",\n",
    "                        \"strength\": joy_emotion[\"probability\"],\n",
    "                    },\n",
    "                    \"negative_aspect\": {\n",
    "                        \"emotions\": level3_emotions,\n",
    "                        \"primary\": (\n",
    "                            max(level3_emotions, key=lambda x: x[\"probability\"])\n",
    "                            if level3_emotions\n",
    "                            else None\n",
    "                        ),\n",
    "                    },\n",
    "                    \"conflict_intensity\": abs(\n",
    "                        joy_emotion[\"probability\"] - other_emotion[\"probability\"]\n",
    "                    ),\n",
    "                }\n",
    "\n",
    "        return {\"type\": combination_type, \"details\": details}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccf1d9",
   "metadata": {},
   "source": [
    "## ì±—ë´‡ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a362c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "class EmotionChatbot:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_dir,\n",
    "        confidence_threshold=0.6,\n",
    "        emotion_threshold=0.3,\n",
    "        centers_csv_path=None,  # ì¶”ê°€ : CSV íŒŒì¼ ê²½ë¡œ\n",
    "        enable_safety_features=True,  # ì•ˆì „ ê¸°ëŠ¥ í™œì„±í™” ì˜µì…˜\n",
    "    ):\n",
    "        # ê°ì • ë¶„ë¥˜ê¸° ì´ˆê¸°í™”\n",
    "        self.classifier = HierarchicalEmotionClassifier(\n",
    "            model_dir,\n",
    "            confidence_threshold=confidence_threshold,\n",
    "            emotion_threshold=emotion_threshold,\n",
    "        )\n",
    "\n",
    "        # ì„ê³„ê°’ì„ ì±—ë´‡ì—ì„œë„ ì €ì¥ (í•„ìš”ì‹œ ì‚¬ìš©)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.emotion_threshold = emotion_threshold\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ ë¡œë“œ\n",
    "        self.prompts = self._load_prompts()\n",
    "\n",
    "        # ë‹¤ì¤‘ llm ì´ˆê¸°í™”\n",
    "        self.llms = self._initialize_all_llms()\n",
    "        self.shared_memory = None  # ê³µìœ  ë©”ëª¨ë¦¬ ë³€ìˆ˜ ì¶”ê°€\n",
    "\n",
    "        # ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ì™€ ì²´ì¸ ì„¤ì •\n",
    "        self._setup_model_chains()\n",
    "\n",
    "        # llm ì„ ì •ì„ ìœ„í•´ ì—¬ëŸ¬ API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "            api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "            api_key2 = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "            if llm_provider == \"openai\":\n",
    "                if not api_key:\n",
    "                    raise ValueError(\"OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "                self.llm = ChatOpenAI(\n",
    "                    model=\"gpt-4o\", temperature=0.4, max_tokens=1000, api_key=api_key\n",
    "                )\n",
    "\n",
    "            elif llm_provider == \"claude\":\n",
    "                if not api_key2:\n",
    "                    raise ValueError(\n",
    "                        \"ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "                    )\n",
    "\n",
    "                self.llm = ChatAnthropic(\n",
    "                    model=\"claude-opus-4-20250514\",\n",
    "                    temperature=0.4,\n",
    "                    max_tokens=1000,\n",
    "                    api_key=api_key2,\n",
    "                )\n",
    "\n",
    "            elif llm_provider == \"gemini\":\n",
    "                try:\n",
    "                    if not api_key3:\n",
    "                        raise ValueError(\"GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "                    \n",
    "                    print(f\"Gemini API key ì¡´ì¬: {bool(api_key3)}\")\n",
    "                    print(\"ChatGoogleGenerativeAI ì´ˆê¸°í™” ì‹œë„...\")\n",
    "                    \n",
    "                    self.llm = ChatGoogleGenerativeAI(\n",
    "                        model=\"gemini-1.5-pro-latest\",\n",
    "                        temperature=0.4,\n",
    "                        api_key=api_key3,\n",
    "                        \n",
    "\n",
    "                    )\n",
    "                    print(\"ChatGoogleGenerativeAI ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        \n",
    "                except Exception as gemini_error:\n",
    "                    print(f\"Gemini ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {gemini_error}\")\n",
    "                    raise\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "            self.shared_memory = ConversationSummaryBufferMemory(\n",
    "                llm=self.llm,\n",
    "                return_messages=True,\n",
    "                max_token_limit=2000,\n",
    "                memory_key=\"chat_history\",\n",
    "            )\n",
    "\n",
    "            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "            self.system_prompt_text = self.prompts.get(\"basic_system\")\n",
    "            if not self.system_prompt_text:\n",
    "                raise ValueError(\n",
    "                    \"basic_system í”„ë¡¬í”„íŠ¸ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. prompts/basic_system.yaml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "                )\n",
    "\n",
    "            self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_prompt_text),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.chain = self.chat_prompt | self.llm\n",
    "            print(\"âœ… ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            raise\n",
    "        \"\"\"\n",
    "\n",
    "        # ì•ˆì „ ê¸°ëŠ¥ ì¶”ê°€ ë¶€ë¶„\n",
    "        if enable_safety_features:\n",
    "            # ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€ê¸° ì¶”ê°€\n",
    "            self.risk_detector = RiskKeywordDetector()\n",
    "\n",
    "            # CSV íŒŒì¼ì—ì„œ ì„¼í„° ì •ë³´ ë¡œë“œ\n",
    "            if centers_csv_path and os.path.exists(centers_csv_path):\n",
    "                self.center_matcher = LocationBasedCenterMatcher(centers_csv_path)\n",
    "            else:\n",
    "                # ê¸°ë³¸ ì„¼í„° ì‚¬ìš©\n",
    "                self.center_matcher = LocationBasedCenterMatcher()\n",
    "            # ìœ„ì¹˜ ì²˜ë¦¬ í•¸ë“¤ëŸ¬\n",
    "            self.location_handler = LocationHandler(self.center_matcher)\n",
    "\n",
    "            # ì²­ì†Œë…„ ì–¸ì–´ ì²˜ë¦¬ê¸°\n",
    "            self.youth_processor = YouthLanguageProcessor()\n",
    "\n",
    "            # ìœ„í—˜ ìƒí™© ë¡œê·¸\n",
    "            self.risk_log = []\n",
    "\n",
    "            print(\"âœ… ì²­ì†Œë…„ ì•ˆì „ ê¸°ëŠ¥ í™œì„±í™”ë¨\")\n",
    "\n",
    "        else:\n",
    "            # ì•ˆì „ ê¸°ëŠ¥ ë¹„í™œì„±í™”\n",
    "            self.risk_detector = None\n",
    "            self.center_matcher = None\n",
    "            self.location_handler = None\n",
    "            self.youth_processor = None\n",
    "            self.risk_log = []\n",
    "\n",
    "            print(\"âš ï¸ ì²­ì†Œë…„ ì•ˆì „ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨\")\n",
    "\n",
    "    def _load_prompts(self):\n",
    "        \"\"\"YAML íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë¡œë“œ\"\"\"\n",
    "        prompts = {}\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤ ë¦¬ìŠ¤íŠ¸ (ë³µí•© ê°ì • í”„ë¡¬í”„íŠ¸ë§Œ)\n",
    "        prompt_files = {\n",
    "            \"basic_system\": \"prompts/basic_system.yaml\",\n",
    "            \"ambivalent_empathy\": \"prompts/ambivalent_empathy.yaml\",\n",
    "            \"mixed_validation\": \"prompts/mixed_validation.yaml\",\n",
    "            \"exploratory_empathy\": \"prompts/exploratory_empathy.yaml\",\n",
    "            \"direct_empathy\": \"prompts/direct_empathy.yaml\",\n",
    "            \"general_conversation\": \"prompts/general_conversation.yaml\",\n",
    "        }\n",
    "\n",
    "        for prompt_name, file_path in prompt_files.items():\n",
    "            try:\n",
    "                if os.path.exists(file_path):\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        data = yaml.safe_load(f)\n",
    "                        # YAML íŒŒì¼ì—ì„œ 'template' í‚¤ë¥¼ ì°¾ì•„ì„œ ì‚¬ìš©\n",
    "                        if isinstance(data, dict) and \"template\" in data:\n",
    "                            prompts[prompt_name] = data[\"template\"]\n",
    "                        elif isinstance(data, str):\n",
    "                            prompts[prompt_name] = data\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"âš ï¸ {file_path}ì—ì„œ ì˜¬ë°”ë¥¸ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "                            )\n",
    "                else:\n",
    "                    print(f\"âš ï¸ {file_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {file_path} ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "        return prompts\n",
    "\n",
    "    def _initialize_all_llms(self):\n",
    "        # ëª¨ë“  LLM í•œë²ˆì— ì´ˆê¸°í™”\n",
    "        llms = {}\n",
    "\n",
    "        try:\n",
    "            if openai_key:\n",
    "                # ì¼ë°˜ ëŒ€í™”ìš©\n",
    "                llms[\"gpt35\"] = ChatOpenAI(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    temperature=0.6,\n",
    "                    max_tokens=800,\n",
    "                    api_key=openai_key,\n",
    "                )\n",
    "            print(\"ğŸŒŸì¼ë°˜ëŒ€í™”ìš© GPT3.5 ì´ˆê¸°í™”ì™„ë£Œ\")\n",
    "\n",
    "            if openai_key:\n",
    "                # ê°ì • ëŒ€í™”ìš©\n",
    "                llms[\"gpt4o\"] = ChatOpenAI(\n",
    "                    model=\"gpt-4o\", temperature=0.3, max_tokens=1200, api_key=openai_key\n",
    "                )\n",
    "            print(\"ğŸŒŸê°ì •ëŒ€í™”ìš© GPT4 ì´ˆê¸°í™”ì™„ë£Œ\")\n",
    "\n",
    "            if anthropic_key:\n",
    "                # ìœ„í—˜ í‚¤ì›Œë“œ íƒì§€\n",
    "                llms[\"claude\"] = ChatAnthropic(\n",
    "                    model=\"claude-opus-4-20250514\",\n",
    "                    temperature=0.3,\n",
    "                    max_tokens=1200,\n",
    "                    api_key=anthropic_key,\n",
    "                )\n",
    "            print(\"ğŸŒŸìœ„í—˜ëŒ€í™”ìš© Cluade ì´ˆê¸°í™”ì™„ë£Œ\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ¥º LLM ì´ˆê¸°í™” ì˜¤ë¥˜{e}\")\n",
    "            raise\n",
    "        return llms\n",
    "\n",
    "    def _choose_model(self, text):\n",
    "        # í…ìŠ¤íŠ¸ ë¶„ì„í›„ ì ì ˆí•œ ëª¨ë¸ ì„ íƒ\n",
    "\n",
    "        # 1. ê°ì • ë¶„ì„\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "\n",
    "        # 2. ìœ„í—˜ë„ ë¶„ì„ (ì•ˆì „ ê¸°ëŠ¥ì´ ìˆì„ ë•Œë§Œ)\n",
    "        risk_analysis = None\n",
    "        if hasattr(self, \"risk_detector\") and self.risk_detector:\n",
    "            risk_analysis = self.risk_detector.detect_risk(text)\n",
    "\n",
    "        # 3. ëª¨ë¸ ì„ íƒ ë¡œì§\n",
    "        # ìœ„í—˜ìƒí™©ì´ë©´ Claude ìš°ì„ \n",
    "        if risk_analysis and risk_analysis[\"requires_intervention\"]:\n",
    "            if \"claude\" in self.llms:\n",
    "                return \"claude\", emotion_result, risk_analysis\n",
    "            elif \"gpt4o\" in self.llms:  # Claude ì—†ìœ¼ë©´ GPT-4oë¡œ í´ë°±\n",
    "                return \"gpt4o\", emotion_result, risk_analysis\n",
    "\n",
    "        # ì¼ë°˜ëŒ€í™”ë©´ GPT-3.5\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        confidence = emotion_result[\"final\"][\"confidence\"]\n",
    "\n",
    "        if emotion == \"ì¼ë°˜ëŒ€í™”\" and confidence > 0.7:\n",
    "            if \"gpt35\" in self.llms:\n",
    "                return \"gpt35\", emotion_result, risk_analysis\n",
    "\n",
    "        # ê°ì •ê´€ë ¨ì´ë©´ GPT-4o\n",
    "        if \"gpt4o\" in self.llms:\n",
    "            return \"gpt4o\", emotion_result, risk_analysis\n",
    "\n",
    "        # í´ë°±: ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸\n",
    "        available_model = list(self.llms.keys())[0]\n",
    "        return available_model, emotion_result, risk_analysis\n",
    "\n",
    "    def generate_smart_response(self, text):\n",
    "        \"\"\"ìƒí™©ì— ë§ëŠ” ëª¨ë¸ë¡œ ìŠ¤ë§ˆíŠ¸ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "\n",
    "        try:\n",
    "            # 1. ëª¨ë¸ ì„ íƒ\n",
    "            selected_model, emotion_result, risk_analysis = self._choose_model(text)\n",
    "\n",
    "            print(f\"ğŸ¤– ì„ íƒëœ ëª¨ë¸: {selected_model}\")\n",
    "\n",
    "            # 2. í•´ë‹¹ ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±\n",
    "            response = self._generate_with_selected_model(\n",
    "                text, selected_model, emotion_result, risk_analysis\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"ai_response\": response,\n",
    "                \"model_used\": selected_model,\n",
    "                \"emotion_analysis\": emotion_result,\n",
    "                \"risk_analysis\": risk_analysis,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "            # ì˜¤ë¥˜ì‹œ ê¸°ë³¸ ëª¨ë¸ë¡œ í´ë°±\n",
    "            fallback_model = list(self.llms.keys())[0]\n",
    "            fallback_response = (\n",
    "                f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"ai_response\": fallback_response,\n",
    "                \"model_used\": fallback_model + \" (fallback)\",\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "\n",
    "    def _generate_with_selected_model(\n",
    "        self, text, model_name, emotion_result, risk_analysis\n",
    "    ):\n",
    "        \"\"\"ì„ íƒëœ ëª¨ë¸ë¡œ ì‹¤ì œ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "\n",
    "        # ê³µìœ  ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "        chat_history = self.shared_memory.chat_memory.messages\n",
    "        llm = self.llms[model_name]\n",
    "\n",
    "        # ğŸ”§ emotion_info ì¤€ë¹„ (ëª¨ë“  ê²½ìš°ì— ì‚¬ìš©)\n",
    "        emotion_info = f\"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}\"\n",
    "\n",
    "        # ìœ„í—˜ìƒí™©ì´ê³  Claudeë©´ íŠ¹ë³„ ì²˜ë¦¬\n",
    "        if (\n",
    "            risk_analysis\n",
    "            and risk_analysis[\"requires_intervention\"]\n",
    "            and model_name == \"claude\"\n",
    "        ):\n",
    "            response = self._generate_crisis_response_safe(\n",
    "                text, risk_analysis, [], emotion_result\n",
    "            )\n",
    "\n",
    "        elif emotion_result[\"final\"][\"prediction\"] == \"ì¼ë°˜ëŒ€í™”\":\n",
    "            # ğŸ”§ ì¼ë°˜ëŒ€í™”: emotion_info ì „ë‹¬ ì¶”ê°€\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        self.prompts.get(\n",
    "                            \"general_conversation\", \"ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì¹œêµ¬ì…ë‹ˆë‹¤.\"\n",
    "                        ),\n",
    "                    ),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            chain = prompt | llm\n",
    "            llm_response = chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,  # ğŸ”§ ì¶”ê°€\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            response = (\n",
    "                llm_response.content\n",
    "                if hasattr(llm_response, \"content\")\n",
    "                else str(llm_response)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # ê°ì •ê´€ë ¨: ê¸°ì¡´ ë¡œì§ ì‚¬ìš©í•˜ë˜ emotion_info ì „ë‹¬\n",
    "            response = self._generate_emotion_response_with_model(\n",
    "                text, emotion_result, chat_history, llm\n",
    "            )\n",
    "\n",
    "        # ê³µìœ  ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥\n",
    "        self.shared_memory.chat_memory.add_user_message(text)\n",
    "        self.shared_memory.chat_memory.add_ai_message(response)\n",
    "\n",
    "        return response\n",
    "\n",
    "    def _generate_emotion_response_with_model(\n",
    "        self, text, emotion_result, chat_history, llm\n",
    "    ):\n",
    "        \"\"\"ê°ì • ì‘ë‹µ ìƒì„± (ê¸°ì¡´ ë¡œì§ í™œìš©)\"\"\"\n",
    "\n",
    "        # ê¸°ë³¸ ê°ì • í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "        system_prompt = self.prompts.get(\n",
    "            \"basic_system\", \"ë‹¹ì‹ ì€ ê³µê°ì ì¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\"\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm\n",
    "\n",
    "        # ğŸ”§ ê°ì • ì •ë³´ ì¤€ë¹„\n",
    "        emotion_info = f\"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}\"\n",
    "\n",
    "        llm_response = chain.invoke(\n",
    "            {\n",
    "                \"message\": text,\n",
    "                \"emotion_info\": emotion_info,  # ğŸ”§ ì¶”ê°€\n",
    "                \"chat_history\": chat_history,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            llm_response.content\n",
    "            if hasattr(llm_response, \"content\")\n",
    "            else str(llm_response)\n",
    "        )\n",
    "\n",
    "    def _setup_model_chains(self):\n",
    "        \"\"\"ê³µìœ ë©”ëª¨ë¦¬ ì„¤ì •\"\"\"\n",
    "\n",
    "        # ëŒ€í‘œ ëª¨ë¸ ì„ íƒ\n",
    "        if \"gpt4o\" in self.llms:\n",
    "            primary_llm = self.llms[\"gpt4o\"]\n",
    "        elif \"claude\" in self.llms:\n",
    "            primary_llm = self.llms[\"claude\"]\n",
    "        else:\n",
    "            primary_llm = list(self.llms.values())[0]\n",
    "\n",
    "        self.llm = primary_llm\n",
    "\n",
    "        # ê³µìœ ë©”ëª¨ë¦¬ ìƒì„±\n",
    "        self.shared_memory = ConversationSummaryBufferMemory(\n",
    "            llm=primary_llm,\n",
    "            return_messages=True,\n",
    "            max_token_limit=2000,\n",
    "            memory_key=\"chat_history\",\n",
    "        )\n",
    "\n",
    "        print(\"ê³µìœ  ë©”ëª¨ë¦¬ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "        self.system_prompt_text = self.prompts.get(\"basic_system\")\n",
    "\n",
    "        self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_prompt_text),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.chain = self.chat_prompt | self.llm\n",
    "\n",
    "        print(\"ê³µìœ  ë©”ëª¨ë¦¬ ë° ê¸°ë³¸ ì²´ì¸ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "    def classify_emotion(self, text):\n",
    "        \"\"\"ê¸°ë³¸ ê°ì • ë¶„ë¥˜\"\"\"\n",
    "        return self.classifier.predict_hierarchical(text)\n",
    "\n",
    "    def format_analysis(self, result):\n",
    "        \"\"\"ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…\"\"\"\n",
    "        output = f\"\"\"\n",
    "ğŸ“ ì…ë ¥: {result['original_text']}\n",
    "ğŸ” ì „ì²˜ë¦¬: {result['preprocessed_text']}\n",
    "\n",
    "ğŸ¯ ìµœì¢… ê²°ê³¼: {result['final']['prediction']} (ì‹ ë¢°ë„: {result['final']['confidence']:.4f})\n",
    "ğŸ“Š ì˜ˆì¸¡ ê²½ë¡œ: {' â†’ '.join(result['path'])}\n",
    "\n",
    "ğŸ“ˆ ë‹¨ê³„ë³„ ë¶„ì„:\n",
    "\"\"\"\n",
    "\n",
    "        for level, data in result[\"levels\"].items():\n",
    "            output += f\"\\nğŸ”¸ {data['step']}\\n\"\n",
    "            output += f\"   ê²°ê³¼: {data['prediction']} ({data['confidence']:.4f})\\n\"\n",
    "            output += f\"   í™•ë¥ : \"\n",
    "            for emotion, prob in data[\"probabilities\"].items():\n",
    "                output += f\"{emotion}({prob:.3f}) \"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        return output\n",
    "\n",
    "    def generate_response(self, text):\n",
    "        \"\"\"ê¸°ë³¸ ì±—ë´‡ ì‘ë‹µ ìƒì„± (ë©”ëª¨ë¦¬ ì¶”ê°€)\"\"\"\n",
    "        try:\n",
    "            # ê¸°ë³¸ ê°ì • ë¶„ë¥˜\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            # ê°ì • ë¶„ì„ í¬ë§·íŒ…\n",
    "            emotion_info = f\"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}, ê²½ë¡œ: {' â†’ '.join(emotion_result['path'])}\"\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "            chat_history = self.shared_memory.chat_memory.messages\n",
    "\n",
    "            # ì²´ì¸ ì‹¤í–‰\n",
    "            response = self.chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # ì‘ë‹µ ì¶”ì¶œ\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # ë©”ëª¨ë¦¬ì— ëŒ€í™”ì €ì¥\n",
    "                self.shared_memory.chat_memory.add_user_message(text)\n",
    "                self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"ì‘ë‹µìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return \"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    def generate_response_with_emotion_detection(self, text):\n",
    "        \"\"\" \"ê°ì • ë¶„ë¥˜ì— ë”°ë¼ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            chat_history = self.shared_memory.chat_memory.messages\n",
    "\n",
    "            # ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸\n",
    "            finally_prediction = emotion_result[\"final\"][\"prediction\"]\n",
    "\n",
    "            if finally_prediction == \"ì¼ë°˜ëŒ€í™”\":\n",
    "                # ì¼ë°˜ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "                response = self.generate_general_conversation_response(\n",
    "                    text, emotion_result, chat_history\n",
    "                )\n",
    "            else:\n",
    "                # ê°ì •ì´ë¼ë©´\n",
    "                response = self.generate_emotion_response(\n",
    "                    text, emotion_result, chat_history\n",
    "                )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"ê°ì • ë¶„ë¥˜ ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return \"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆë„¤ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "\n",
    "    # ì¼ë°˜ëŒ€í™” ìƒì„±\n",
    "    def generate_general_conversation_response(\n",
    "        self, text, emotion_result, chat_history\n",
    "    ):\n",
    "        \"\"\"ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            # ğŸ”§ ê°ì • ì •ë³´ ì¤€ë¹„\n",
    "            emotion_info = f\"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}\"\n",
    "\n",
    "            # ğŸ”§ ì¼ë°˜ëŒ€í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "            if \"gpt35\" in self.llms:\n",
    "                llm = self.llms[\"gpt35\"]\n",
    "            else:\n",
    "                llm = list(self.llms.values())[0]  # í´ë°±\n",
    "\n",
    "            general_chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        self.prompts.get(\n",
    "                            \"general_conversation\", \"ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì¹œêµ¬ì…ë‹ˆë‹¤.\"\n",
    "                        ),\n",
    "                    ),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # ì²´ì¸ ì‹¤í–‰\n",
    "            chain = general_chat_prompt | llm\n",
    "            response = chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,  # ğŸ”§ ì¶”ê°€\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # ğŸ”§ shared_memoryì— ëŒ€í™” ì €ì¥\n",
    "                self.shared_memory.chat_memory.add_user_message(text)\n",
    "                self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return \"ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆë„¤ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "\n",
    "    def generate_empathetic_response(self, text):\n",
    "        \"\"\"ë³µí•© ê°ì •ì„ ê³ ë ¤í•œ ê³µê° ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            # ë³µí•© ê°ì • ë¶„ì„\n",
    "            emotion_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "            multi_emotion_result = self.classifier.predict_multi_emotion_threshold(text)\n",
    "\n",
    "            # ì‘ë‹µ ì „ëµ ê²°ì •\n",
    "            response_strategy = self._determine_response_strategy(\n",
    "                emotion_analysis, multi_emotion_result\n",
    "            )\n",
    "\n",
    "            # í”„ë¡¬í”„íŠ¸ì— ë³µí•© ê°ì • ì •ë³´ ì¶”ê°€\n",
    "            emotion_context = self._format_emotion_context(\n",
    "                emotion_analysis, multi_emotion_result, response_strategy\n",
    "            )\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "            chat_history = self.shared_memory.chat_memory.messages\n",
    "\n",
    "            # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±\n",
    "            response = self._generate_response_with_complex_emotion_context(\n",
    "                text, emotion_context, chat_history\n",
    "            )\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ê³µê° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return \"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆë„¤ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "\n",
    "    def _determine_response_strategy(self, emotion_analysis, multi_emotion_result):\n",
    "        \"\"\"ì‘ë‹µ ì „ëµ ê²°ì •\"\"\"\n",
    "        if emotion_analysis[\"complexity_level\"] == \"mixed\":\n",
    "            if multi_emotion_result[\"emotion_combination\"][\"type\"] == \"ambivalent\":\n",
    "                return \"ambivalent_empathy\"  # ì–‘ê°€ê°ì • ê³µê°\n",
    "            else:\n",
    "                return \"mixed_validation\"  # í˜¼í•©ê°ì • ì¸ì •\n",
    "        elif emotion_analysis[\"complexity_level\"] == \"complex\":\n",
    "            return \"exploratory_empathy\"  # íƒìƒ‰ì  ê³µê°\n",
    "        else:\n",
    "            return \"direct_empathy\"  # ì§ì ‘ì  ê³µê°\n",
    "\n",
    "    def _format_emotion_context(self, emotion_analysis, multi_emotion_result, strategy):\n",
    "        \"\"\"ê°ì • ë§¥ë½ í¬ë§·íŒ…\"\"\"\n",
    "        context = {\n",
    "            \"primary_emotion\": emotion_analysis[\"primary_emotion\"],\n",
    "            \"confidence\": emotion_analysis[\"primary_confidence\"],\n",
    "            \"complexity\": emotion_analysis[\"complexity_level\"],\n",
    "            \"response_strategy\": strategy,\n",
    "        }\n",
    "\n",
    "        # ë³µí•© ê°ì • ì •ë³´ ì¶”ê°€\n",
    "        if emotion_analysis[\"mixed_emotions\"]:\n",
    "            context[\"mixed_emotions\"] = emotion_analysis[\"mixed_emotions\"]\n",
    "\n",
    "        # ì–‘ê°€ê°ì • ì •ë³´ ì¶”ê°€\n",
    "        if multi_emotion_result[\"emotion_combination\"][\"type\"] == \"ambivalent\":\n",
    "            context[\"ambivalent_details\"] = multi_emotion_result[\"emotion_combination\"][\n",
    "                \"details\"\n",
    "            ]\n",
    "\n",
    "        return context\n",
    "\n",
    "    def _generate_response_with_complex_emotion_context(\n",
    "        self, text, emotion_context, chat_history\n",
    "    ):\n",
    "        \"\"\"ë³µí•© ê°ì • ë§¥ë½ì„ ê³ ë ¤í•œ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "\n",
    "        # í•„ìˆ˜ í”„ë¡¬í”„íŠ¸ë“¤ì´ ëª¨ë‘ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "        required_prompts = [\n",
    "            \"ambivalent_empathy\",\n",
    "            \"mixed_validation\",\n",
    "            \"exploratory_empathy\",\n",
    "            \"direct_empathy\",\n",
    "        ]\n",
    "        missing_prompts = [\n",
    "            p for p in required_prompts if p not in self.prompts or not self.prompts[p]\n",
    "        ]\n",
    "\n",
    "        if missing_prompts:\n",
    "            raise ValueError(f\"í•„ìˆ˜ í”„ë¡¬í”„íŠ¸ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_prompts}\")\n",
    "\n",
    "        # YAMLì—ì„œ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "        strategy_prompts = {}\n",
    "        for strategy in required_prompts:\n",
    "            strategy_prompts[strategy] = self.prompts[strategy]\n",
    "\n",
    "        # ê°ì • ì •ë³´ ë¬¸ìì—´ ìƒì„±\n",
    "        emotion_info_str = f\"\"\"\n",
    "ê°ì • ë¶„ì„ ê²°ê³¼:\n",
    "- ì£¼ìš” ê°ì •: {emotion_context['primary_emotion']} (ì‹ ë¢°ë„: {emotion_context['confidence']:.2f})\n",
    "- ë³µì¡ë„: {emotion_context['complexity']}\n",
    "- ì‘ë‹µ ì „ëµ: {emotion_context['response_strategy']}\n",
    "\"\"\"\n",
    "\n",
    "        if \"mixed_emotions\" in emotion_context:\n",
    "            emotion_info_str += \"\\ní˜¼í•© ê°ì •ë“¤:\\n\"\n",
    "            for emotion in emotion_context[\"mixed_emotions\"]:\n",
    "                emotion_info_str += (\n",
    "                    f\"- {emotion['emotion']}: {emotion['confidence']:.2f}\\n\"\n",
    "                )\n",
    "\n",
    "        if \"ambivalent_details\" in emotion_context:\n",
    "            details = emotion_context[\"ambivalent_details\"]\n",
    "            emotion_info_str += f\"\\nì–‘ê°€ê°ì • ì„¸ë¶€ì‚¬í•­:\\n\"\n",
    "            emotion_info_str += f\"- ê¸ì •ì  ì¸¡ë©´: {details['positive_aspect']['emotion']} ({details['positive_aspect']['strength']:.2f})\\n\"\n",
    "            if details[\"negative_aspect\"][\"primary\"]:\n",
    "                emotion_info_str += f\"- ë¶€ì •ì  ì¸¡ë©´: {details['negative_aspect']['primary']['emotion']} ({details['negative_aspect']['primary']['probability']:.2f})\\n\"\n",
    "\n",
    "        # ì „ëµì— ë§ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ\n",
    "        system_prompt = strategy_prompts.get(\n",
    "            emotion_context[\"response_strategy\"], strategy_prompts[\"direct_empathy\"]\n",
    "        )\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "        chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ì²´ì¸ ì‹¤í–‰\n",
    "        chain = chat_prompt | self.llm\n",
    "        response = chain.invoke(\n",
    "            {\n",
    "                \"message\": text,\n",
    "                \"chat_history\": chat_history,\n",
    "                \"emotion_info\": emotion_info_str,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if hasattr(response, \"content\"):\n",
    "            ai_response = response.content\n",
    "            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥\n",
    "            self.shared_memory.chat_memory.add_user_message(text)\n",
    "            self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "            return ai_response\n",
    "        else:\n",
    "            return \"ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    def reload_prompts(self):\n",
    "        \"\"\"í”„ë¡¬í”„íŠ¸ ì¬ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            self.prompts = self._load_prompts()\n",
    "            self.system_prompt_text = self.prompts.get(\"basic_system\")\n",
    "            if not self.system_prompt_text:\n",
    "                print(\"âš ï¸ basic_system í”„ë¡¬í”„íŠ¸ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "                self.system_prompt_text = \"ë‹¹ì‹ ì€ ê³µê°ì ì¸ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "            # ğŸ”§ ê¸°ë³¸ ì²´ì¸ ì¬ìƒì„± (self.llm ì‚¬ìš©)\n",
    "            self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_prompt_text),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "            self.chain = self.chat_prompt | self.llm  # self.llm ì‚¬ìš©\n",
    "\n",
    "            print(\"âœ… í”„ë¡¬í”„íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í”„ë¡¬í”„íŠ¸ ì¬ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def process_message(self, text, include_ai_response=True):\n",
    "        \"\"\"ê¸°ë³¸ ë©”ì‹œì§€ ì „ì²´ ì²˜ë¦¬\"\"\"\n",
    "        # ê°ì • ë¶„ì„\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "        emotion_analysis = self.format_analysis(emotion_result)\n",
    "\n",
    "        result = {\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"emotion_result\": emotion_result,\n",
    "        }\n",
    "\n",
    "        # AI ì‘ë‹µ\n",
    "        if include_ai_response:\n",
    "            ai_response = self.generate_response(text)\n",
    "            result[\"ai_response\"] = ai_response\n",
    "            result[\"full_response\"] = f\"{emotion_analysis}\\nğŸ’¬ AI ìƒë‹´:\\n{ai_response}\"\n",
    "        else:\n",
    "            result[\"full_response\"] = emotion_analysis\n",
    "\n",
    "        return result\n",
    "\n",
    "    def process_complex_emotion_message(self, text):\n",
    "        \"\"\"ë³µí•© ê°ì •ì„ ê³ ë ¤í•œ ë©”ì‹œì§€ ì²˜ë¦¬\"\"\"\n",
    "        # ê¸°ë³¸ ê°ì • ë¶„ì„\n",
    "        basic_result = self.classify_emotion(text)\n",
    "\n",
    "        # ë³µí•© ê°ì • ë¶„ì„\n",
    "        confidence_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "        multi_emotion_analysis = self.classifier.predict_multi_emotion_threshold(text)\n",
    "\n",
    "        # ê³µê° ì‘ë‹µ ìƒì„±\n",
    "        ai_response = self.generate_empathetic_response(text)\n",
    "\n",
    "        # ê²°ê³¼ í†µí•©\n",
    "        result = {\n",
    "            \"basic_emotion_analysis\": self.format_analysis(basic_result),\n",
    "            \"confidence_analysis\": confidence_analysis,\n",
    "            \"multi_emotion_analysis\": multi_emotion_analysis,\n",
    "            \"ai_response\": ai_response,\n",
    "            \"complexity_insight\": self._generate_complexity_insight(\n",
    "                confidence_analysis, multi_emotion_analysis\n",
    "            ),\n",
    "            \"full_response\": f\"\"\"\n",
    "ğŸ“Š ê°ì • ë³µì¡ì„± ë¶„ì„:\n",
    "{chr(10).join(self._generate_complexity_insight(confidence_analysis, multi_emotion_analysis))}\n",
    "\n",
    "ğŸ’¬ AI ìƒë‹´:\n",
    "{ai_response}\n",
    "\"\"\",\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _generate_complexity_insight(self, confidence_analysis, multi_emotion_analysis):\n",
    "        \"\"\"ë³µì¡ì„± ì¸ì‚¬ì´íŠ¸ ìƒì„±\"\"\"\n",
    "        insights = []\n",
    "\n",
    "        if confidence_analysis[\"complexity_level\"] == \"mixed\":\n",
    "            insights.append(\"ğŸ”€ í˜¼í•©ëœ ê°ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        if multi_emotion_analysis[\"emotion_combination\"][\"type\"] == \"ambivalent\":\n",
    "            insights.append(\"âš–ï¸ ìƒë°˜ëœ ê°ì •ì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ëŠ” ì–‘ê°€ê°ì • ìƒíƒœì…ë‹ˆë‹¤.\")\n",
    "\n",
    "        if confidence_analysis[\"primary_confidence\"] < 0.6:\n",
    "            insights.append(\"ğŸŒŠ ê°ì •ì´ ë³µì¡í•˜ê³  ë¯¸ë¬˜í•œ ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "        if len(multi_emotion_analysis[\"detected_emotions\"]) > 3:\n",
    "            insights.append(\"ğŸ­ ë‹¤ì–‘í•œ ê°ì •ì´ ë³µí•©ì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        return insights if insights else [\"ğŸ’¡ ë¹„êµì  ëª…í™•í•œ ê°ì • ìƒíƒœì…ë‹ˆë‹¤.\"]\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤\n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"í˜„ì¬ ëŒ€í™” ìš”ì•½ ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        try:\n",
    "            return self.shared_memory.predict_new_summary(\n",
    "                self.shared_memory.chat_memory.messages, \"\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"ëŒ€í™” ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return \"ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    def get_chat_history(self):\n",
    "        \"\"\"ì „ì²´ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        if hasattr(self, \"shared_memory\") and self.shared_memory:\n",
    "            return self.shared_memory.chat_memory.messages\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def clear_memory(self):\n",
    "        \"\"\"ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\"\"\"\n",
    "        if hasattr(self, \"shared_memory\") and self.shared_memory:\n",
    "            self.shared_memory.clear()\n",
    "            print(\"ğŸ’­ ê³µìœ  ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"âš ï¸ ì´ˆê¸°í™”í•  ë©”ëª¨ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    def get_memory_status(self):\n",
    "        \"\"\"ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\"\"\"\n",
    "        try:\n",
    "            messages = self.shared_memory.chat_memory.messages\n",
    "            token_count = self.shared_memory.llm.get_num_tokens_from_messages(messages)\n",
    "\n",
    "            return {\n",
    "                \"message_count\": len(messages),\n",
    "                \"token_count\": token_count,\n",
    "                \"max_token_limit\": self.shared_memory.max_token_limit,\n",
    "                \"is_summarizing\": token_count > self.shared_memory.max_token_limit,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return {\n",
    "                \"message_count\": 0,\n",
    "                \"token_count\": 0,\n",
    "                \"max_token_limit\": 2000,\n",
    "                \"is_summarizing\": False,\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "\n",
    "    def set_thresholds(self, confidence_threshold=None, emotion_threshold=None):\n",
    "        \"\"\"ì„ê³„ê°’ ë™ì  ë³€ê²½\"\"\"\n",
    "        if confidence_threshold is not None:\n",
    "            self.confidence_threshold = confidence_threshold\n",
    "            self.classifier.confidence_threshold = confidence_threshold\n",
    "            print(f\"ì‹ ë¢°ë„ ì„ê³„ê°’ì´ {confidence_threshold}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        if emotion_threshold is not None:\n",
    "            self.emotion_threshold = emotion_threshold\n",
    "            self.classifier.emotion_threshold = emotion_threshold\n",
    "            print(f\"ê°ì • íƒì§€ ì„ê³„ê°’ì´ {emotion_threshold}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    def get_thresholds(self):\n",
    "        \"\"\"í˜„ì¬ ì„ê³„ê°’ ì¡°íšŒ\"\"\"\n",
    "        return {\n",
    "            \"confidence_threshold\": self.confidence_threshold,\n",
    "            \"emotion_threshold\": self.emotion_threshold,\n",
    "        }\n",
    "\n",
    "    def generate_emotion_response(self, text, emotion_result, chat_history):\n",
    "        \"\"\"ê°ì • ê´€ë ¨ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„± (ê¸°ì¡´ ë¡œì§)\"\"\"\n",
    "        try:\n",
    "            # ê°ì • ë¶„ì„ í¬ë§·íŒ…\n",
    "            emotion_info = f\"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}, ê²½ë¡œ: {' â†’ '.join(emotion_result['path'])}\"\n",
    "\n",
    "            # ê¸°ë³¸ ê°ì • í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "            response = self.chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥\n",
    "                self.shared_memory.chat_memory.add_user_message(text)\n",
    "                self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ê°ì • ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return \"ì£„ì†¡í•©ë‹ˆë‹¤. ê°ì • ë¶„ì„ ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    def process_message_with_detection(self, text, include_ai_response=True):\n",
    "        \"\"\"ì¼ë°˜ëŒ€í™”/ê°ì • êµ¬ë¶„í•˜ì—¬ ë©”ì‹œì§€ ì²˜ë¦¬\"\"\"\n",
    "        # ê°ì • ë¶„ì„\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "        emotion_analysis = self.format_analysis(emotion_result)\n",
    "\n",
    "        result = {\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"emotion_result\": emotion_result,\n",
    "            \"conversation_type\": emotion_result[\"final\"][\n",
    "                \"prediction\"\n",
    "            ],  # ì¼ë°˜ëŒ€í™” vs ê°ì •\n",
    "        }\n",
    "\n",
    "        # AI ì‘ë‹µ\n",
    "        if include_ai_response:\n",
    "            ai_response = self.generate_response_with_emotion_detection(text)\n",
    "            result[\"ai_response\"] = ai_response\n",
    "            result[\"full_response\"] = (\n",
    "                f\"{emotion_analysis}\\n\\nğŸ’¬ AI ì‘ë‹µ:\\n{ai_response}\"\n",
    "            )\n",
    "        else:\n",
    "            result[\"full_response\"] = emotion_analysis\n",
    "\n",
    "        return result\n",
    "\n",
    "        # ë©”ì„œë“œ ì¶”ê°€\n",
    "\n",
    "    def process_youth_message(\n",
    "        self,\n",
    "        text: str,\n",
    "        user_id: str = \"default\",\n",
    "        latitude: float = None,\n",
    "        longitude: float = None,\n",
    "    ) -> Dict:\n",
    "        # ì•ˆì „ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ì²˜ë¦¬\n",
    "        if not hasattr(self, \"risk_detector\") or self.risk_detector is None:\n",
    "            return self.process_message(text, include_ai_response=True)\n",
    "\n",
    "        try:\n",
    "            # 1. ê¸°ë³¸ ê°ì • ë¶„ì„:\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            # 2. ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€\n",
    "            risk_analysis = self.risk_detector.detect_risk(text)\n",
    "\n",
    "            # 3. ìœ„í—˜ ì •ë³´ ì²˜ë¦¬\n",
    "            location_result = self.location_handler.process_user_location(\n",
    "                user_id=user_id,\n",
    "                latitude=latitude,\n",
    "                longitude=longitude,\n",
    "                location_text=text,\n",
    "            )\n",
    "\n",
    "            # 4. ì²­ì†Œë…„ ì–¸ì–´ ë¶„ì„\n",
    "            youth_analysis = self.youth_processor.process_youth_message(text)\n",
    "\n",
    "            # 5. ê°ì •-ìœ„í—˜ë„ ì¼ê´€ì„± ì²´í¬ ì¶”ê°€\n",
    "            consistency_check = self._check_emotion_risk_consistency(\n",
    "                emotion_result, risk_analysis\n",
    "            )\n",
    "\n",
    "            # 6. ìµœì¢… ìœ„í—˜ë„ ì¡°ì •\n",
    "            final_risk_analysis = self._adjust_final_risk_level(\n",
    "                risk_analysis, emotion_result, consistency_check\n",
    "            )\n",
    "\n",
    "            # 7. ê·¼ì²˜ ì„¼í„° ì°¾ê¸° (ì¡°ì •ëœ ìœ„í—˜ë„ ê¸°ì¤€)\n",
    "            nearby_centers = []\n",
    "            if (\n",
    "                final_risk_analysis[\"requires_intervention\"]\n",
    "                and location_result[\"coordinates\"]\n",
    "            ):\n",
    "                nearby_centers = self.center_matcher.find_nearest_centers(\n",
    "                    location_result[\"coordinates\"], max_distance=50.0, limit=3\n",
    "                )\n",
    "\n",
    "            # 8. ì‘ë‹µ ìƒì„± (ì¡°ì •ëœ ìœ„í—˜ë„ì— ë”°ë¼ ë‹¤ë¥¸ ì „ëµ)\n",
    "            if final_risk_analysis[\"requires_intervention\"]:\n",
    "                ai_response = self._generate_crisis_response_safe(\n",
    "                    text, final_risk_analysis, nearby_centers, emotion_result\n",
    "                )\n",
    "                # ìœ„í—˜ ìƒí™© ë¡œê¹…\n",
    "                self._log_risk_situation_safe(\n",
    "                    text, final_risk_analysis, location_result, user_id\n",
    "                )\n",
    "            else:\n",
    "                ai_response = self._generate_safe_response(\n",
    "                    text, emotion_result, youth_analysis\n",
    "                )\n",
    "\n",
    "            # 9. ê²°ê³¼ í†µí•©\n",
    "            result = {\n",
    "                \"original_text\": text,\n",
    "                \"user_id\": user_id,\n",
    "                \"emotion_analysis\": emotion_result,\n",
    "                \"risk_analysis\": risk_analysis,\n",
    "                \"final_risk_analysis\": final_risk_analysis,\n",
    "                \"consistency_check\": consistency_check,\n",
    "                \"youth_analysis\": youth_analysis,\n",
    "                \"location_info\": location_result,\n",
    "                \"nearby_centers\": nearby_centers,\n",
    "                \"ai_response\": ai_response,\n",
    "                \"requires_immediate_help\": final_risk_analysis[\"requires_intervention\"],\n",
    "                \"timestamp\": datetime.now(),\n",
    "            }\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:  # ğŸ†• ì´ ë¶€ë¶„ ì¶”ê°€!\n",
    "            print(f\"âŒ ì²­ì†Œë…„ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì²˜ë¦¬ë¡œ í´ë°±\n",
    "            return self.process_message(text, include_ai_response=True)\n",
    "\n",
    "    def _generate_crisis_response_safe(\n",
    "        self,\n",
    "        text: str,\n",
    "        risk_analysis: Dict,\n",
    "        nearby_centers: List[Dict],\n",
    "        emotion_result: Dict,\n",
    "    ) -> str:\n",
    "        \"\"\"ğŸ†• ìœ„ê¸° ìƒí™© ì•ˆì „ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "\n",
    "        # ê¸°ë³¸ ê³µê° ë©”ì‹œì§€\n",
    "        crisis_message = f\"ğŸ’™ {risk_analysis.get('risk_message', 'ë§ì´ í˜ë“œì‹œêµ°ìš”. í˜¼ìê°€ ì•„ë‹ˆì—ìš”.')}\\n\\n\"\n",
    "\n",
    "        # ê·¼ì²˜ ì„¼í„° ì •ë³´ ì¶”ê°€\n",
    "        if nearby_centers:\n",
    "            crisis_message += \"ğŸ¥ **ê°€ê¹Œìš´ ë„ì›€ë°›ì„ ê³³:**\\n\"\n",
    "            for i, center in enumerate(nearby_centers[:2], 1):\n",
    "                crisis_message += f\"{i}. {center['name']}\\n\"\n",
    "                crisis_message += f\"   ğŸ“ {center['phone']}\\n\"\n",
    "                if \"distance\" in center:\n",
    "                    crisis_message += f\"   ğŸš— ê±°ë¦¬: {center['distance']}km\\n\"\n",
    "                crisis_message += \"\\n\"\n",
    "\n",
    "        # ì‘ê¸‰ ì—°ë½ì²˜\n",
    "        crisis_message += \"\"\"ğŸš¨ **ì¦‰ì‹œ ë„ì›€ì´ í•„ìš”í•˜ë‹¤ë©´:**\n",
    "â€¢ ì‘ê¸‰ìƒí™©: 112\n",
    "â€¢ ì²­ì†Œë…„ì „í™”: 1388 (24ì‹œê°„)\n",
    "â€¢ ìì‚´ì˜ˆë°©ìƒë‹´: 1393\n",
    "â€¢ ìœ„ê¸°ìƒë‹´: 1577-0199\n",
    "\n",
    "í˜¼ìê°€ ì•„ë‹ˆë¼ëŠ” ê±¸ ê¸°ì–µí•´ì£¼ì„¸ìš”. ğŸ’™\"\"\"\n",
    "\n",
    "        return crisis_message\n",
    "\n",
    "    def _generate_safe_response(\n",
    "        self, text: str, emotion_result: Dict, youth_analysis: Dict\n",
    "    ) -> str:\n",
    "        \"\"\"ê°œì„ ëœ ì¼ë°˜ ìƒí™© ì•ˆì „ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "\n",
    "        # ê°ì • ê²°ê³¼ í™•ì¸\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        confidence = emotion_result[\"final\"][\"confidence\"]\n",
    "\n",
    "        # ê¸ì •ì  ê°ì •ì¼ ë•Œ\n",
    "        if emotion in [\"ê¸°ì¨\", \"ì¼ë°˜ëŒ€í™”\"] and confidence > 0.6:\n",
    "            if youth_analysis.get(\"language_style\") == \"youth_casual\":\n",
    "                response_start = \"ì˜¤ëŠ˜ ê¸°ë¶„ ì¢‹ìœ¼ì‹œë‹¤ë‹ˆ ì™„ì „ ì¢‹ë„¤ìš”! ğŸ˜Š \"\n",
    "            else:\n",
    "                response_start = \"ê¸°ë¶„ì´ ì¢‹ìœ¼ì‹œë‹¤ë‹ˆ ì •ë§ ë‹¤í–‰ì´ì—ìš”! ğŸ˜Š \"\n",
    "        else:\n",
    "            # ê¸°ì¡´ ë¡œì§\n",
    "            if youth_analysis.get(\"language_style\") == \"youth_casual\":\n",
    "                response_start = \"ê·¸ëŸ° ë§ˆìŒ ì™„ì „ ì´í•´í•´ğŸ’™ \"\n",
    "            else:\n",
    "                response_start = \"í˜ë“  ë§ˆìŒì„ ë§ì”€í•´ì£¼ì…¨êµ°ìš”. \"\n",
    "\n",
    "        # ê¸°ì¡´ generate_response í˜¸ì¶œí•˜ë˜ ì•ì— ì¹œí™”ì  ë©”ì‹œì§€ ì¶”ê°€\n",
    "        base_response = self.generate_response(text)\n",
    "\n",
    "        return response_start + base_response\n",
    "\n",
    "    def _log_risk_situation_safe(\n",
    "        self, text: str, risk_analysis: Dict, location_result: Dict, user_id: str\n",
    "    ):\n",
    "        \"\"\"ğŸ†• ìœ„í—˜ ìƒí™© ì•ˆì „ ë¡œê¹…\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"user_id\": user_id,\n",
    "            \"risk_level\": risk_analysis[\"risk_level\"],\n",
    "            \"detected_keywords\": [\n",
    "                r[\"keyword\"] for r in risk_analysis.get(\"detected_risks\", [])\n",
    "            ],\n",
    "            \"has_location\": location_result.get(\"coordinates\") is not None,\n",
    "            \"intervention_provided\": True,\n",
    "        }\n",
    "\n",
    "        self.risk_log.append(log_entry)\n",
    "\n",
    "        # ë¡œê·¸ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì •ë¦¬ (ìµœê·¼ 50ê°œë§Œ ìœ ì§€)\n",
    "        if len(self.risk_log) > 100:\n",
    "            self.risk_log = self.risk_log[-50:]\n",
    "\n",
    "    def _check_emotion_risk_consistency(\n",
    "        self, emotion_result: Dict, risk_analysis: Dict\n",
    "    ) -> Dict:\n",
    "        \"\"\"ê°ì •ê³¼ ìœ„í—˜ë„ì˜ ì¼ê´€ì„± ì²´í¬\"\"\"\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        risk_level = risk_analysis[\"risk_level\"]\n",
    "        has_positive_context = risk_analysis.get(\"has_positive_context\", False)\n",
    "\n",
    "        # ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°\n",
    "        consistency_score = 1.0\n",
    "        warnings = []\n",
    "\n",
    "        # ê¸ì •ì  ê°ì • + ë†’ì€ ìœ„í—˜ë„ = ë¹„ì¼ê´€ì \n",
    "        if emotion in [\"ê¸°ì¨\", \"ì¼ë°˜ëŒ€í™”\"] and risk_level in [\"high\", \"critical\"]:\n",
    "            if not has_positive_context:\n",
    "                consistency_score -= 0.5\n",
    "                warnings.append(\"ê¸ì •ì  ê°ì •ê³¼ ë†’ì€ ìœ„í—˜ë„ ë¶ˆì¼ì¹˜\")\n",
    "\n",
    "        return {\n",
    "            \"consistency_score\": max(0.0, min(1.0, consistency_score)),\n",
    "            \"warnings\": warnings,\n",
    "        }\n",
    "\n",
    "    def _adjust_final_risk_level(\n",
    "        self, risk_analysis: Dict, emotion_result: Dict, consistency: Dict\n",
    "    ) -> Dict:\n",
    "        \"\"\"ìµœì¢… ìœ„í—˜ë„ ì¡°ì •\"\"\"\n",
    "        base_risk = risk_analysis[\"risk_level\"]\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        confidence = emotion_result[\"final\"][\"confidence\"]\n",
    "\n",
    "        # ì¼ê´€ì„±ì´ ë‚®ìœ¼ë©´ ìœ„í—˜ë„ ì¬í‰ê°€\n",
    "        if consistency[\"consistency_score\"] < 0.5:\n",
    "            # ê¸ì •ì  ê°ì •ì´ í™•ì‹¤í•˜ë©´ ìœ„í—˜ë„ ë‚®ì¶¤\n",
    "            if emotion in [\"ê¸°ì¨\", \"ì¼ë°˜ëŒ€í™”\"] and confidence > 0.7:\n",
    "                if base_risk == \"high\":\n",
    "                    base_risk = \"medium\"\n",
    "                elif base_risk == \"medium\":\n",
    "                    base_risk = \"low\"\n",
    "\n",
    "        return {\n",
    "            \"risk_level\": base_risk,\n",
    "            \"requires_intervention\": base_risk in [\"critical\", \"high\"],\n",
    "            \"adjustment_reason\": f\"ê°ì • ì¼ê´€ì„± ê³ ë ¤\",\n",
    "            \"original_risk\": risk_analysis[\"risk_level\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804155b",
   "metadata": {},
   "source": [
    "# í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8f9f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SupportCenter:\n",
    "    \"\"\"ì§€ì›ì„¼í„° ì •ë³´\"\"\"\n",
    "\n",
    "    region: str\n",
    "    name: str\n",
    "    address: str\n",
    "    phone: str\n",
    "    website: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    center_type: str\n",
    "\n",
    "\n",
    "class RiskKeywordDetector:\n",
    "    \"\"\"ê°œì„ ëœ ìœ„í—˜ í‚¤ì›Œë“œ ê°ì§€ê¸°\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # ìœ„í—˜ í‚¤ì›Œë“œë¥¼ ë” ì •í™•í•˜ê²Œ ì •ì˜\n",
    "        self.risk_patterns = {\n",
    "            \"critical\": {\n",
    "                \"patterns\": [\n",
    "                    r\"ì£½ê³ \\s*ì‹¶\",\n",
    "                    r\"ìì‚´\",\n",
    "                    r\"ìí•´\",\n",
    "                    r\"ì‚¬ë¼ì§€ê³ \\s*ì‹¶\",\n",
    "                    r\"ì£½ì–´ì•¼ì§€\",\n",
    "                    r\"ì£½ì„ë˜\",\n",
    "                    r\"ì£½ì—ˆìœ¼ë©´\",\n",
    "                ],\n",
    "                \"exclusions\": [],\n",
    "            },\n",
    "            \"high\": {\n",
    "                \"patterns\": [\n",
    "                    r\"ê°€ì¶œí•˜ê³ \\s*ì‹¶\",\n",
    "                    r\"ì§‘ì—\\s*ì•ˆ\\s*ê°€ê³ \\s*ì‹¶\",\n",
    "                    r\"ë•Œë¦¬ê³ \\s*ì‹¶\",\n",
    "                    r\"ë¶€ëª¨\\s*ë•Œë¦¬\",\n",
    "                    r\"ì„ ìƒë‹˜\\s*ë•Œë¦¬\",\n",
    "                ],\n",
    "                \"exclusions\": [r\"ê¸°ë¶„\\s*ì¢‹\", r\"í–‰ë³µ\", r\"ì¦ê±°\"],\n",
    "            },\n",
    "            \"medium\": {\n",
    "                \"patterns\": [\n",
    "                    r\"ë„ˆë¬´\\s*ìš°ìš¸\",\n",
    "                    r\"ì‹¬í•œ\\s*ë¶ˆì•ˆ\",\n",
    "                    r\"ë§ì´\\s*í˜ë“¤\",\n",
    "                    r\"ê·¹ì‹¬í•œ\\s*ìŠ¤íŠ¸ë ˆìŠ¤\",\n",
    "                    r\"ê²¬ë”œ\\s*ìˆ˜\\s*ì—†\",\n",
    "                ],\n",
    "                \"exclusions\": [r\"ê¸°ë¶„\\s*ì¢‹\", r\"ê´œì°®\", r\"ì¢‹ì•„\", r\"í–‰ë³µ\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # ê¸ì •ì  ë§¥ë½ í‚¤ì›Œë“œ\n",
    "        self.positive_context = [\n",
    "            r\"ê¸°ë¶„\\s*ì¢‹\",\n",
    "            r\"í–‰ë³µ\",\n",
    "            r\"ì¦ê±°\",\n",
    "            r\"ê´œì°®\",\n",
    "            r\"ì¢‹ì•„\",\n",
    "            r\"ì¬ë°Œ\",\n",
    "            r\"ì‹ ë‚˜\",\n",
    "            r\"ì›ƒ\",\n",
    "            r\"ë°\",\n",
    "            r\"í¬ë§\",\n",
    "        ]\n",
    "\n",
    "    def detect_risk(self, text: str) -> dict:\n",
    "        \"\"\"ê°œì„ ëœ ìœ„í—˜ë„ ê°ì§€\"\"\"\n",
    "        text_processed = text.lower().strip()\n",
    "        detected_risks = []\n",
    "        max_risk_level = \"low\"\n",
    "\n",
    "        # 1. ê¸ì •ì  ë§¥ë½ ì²´í¬\n",
    "        has_positive_context = self._check_positive_context(text_processed)\n",
    "\n",
    "        # 2. ê° ìœ„í—˜ ë ˆë²¨ë³„ë¡œ íŒ¨í„´ ë§¤ì¹­\n",
    "        for level, patterns_data in self.risk_patterns.items():\n",
    "            patterns = patterns_data[\"patterns\"]\n",
    "            exclusions = patterns_data[\"exclusions\"]\n",
    "\n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, text_processed)\n",
    "                if matches:\n",
    "                    # ì œì™¸ íŒ¨í„´ ì²´í¬\n",
    "                    is_excluded = False\n",
    "                    for exclusion in exclusions:\n",
    "                        if re.search(exclusion, text_processed):\n",
    "                            is_excluded = True\n",
    "                            break\n",
    "\n",
    "                    # ê¸ì •ì  ë§¥ë½ì´ ìˆìœ¼ë©´ ìœ„í—˜ë„ ë‚®ì¶¤\n",
    "                    if has_positive_context and level in [\"medium\", \"high\"]:\n",
    "                        is_excluded = True\n",
    "\n",
    "                    if not is_excluded:\n",
    "                        detected_risks.append(\n",
    "                            {\"keyword\": matches[0], \"category\": level}\n",
    "                        )\n",
    "\n",
    "                        if self._is_higher_risk(level, max_risk_level):\n",
    "                            max_risk_level = level\n",
    "\n",
    "        # 3. ìµœì¢… ìœ„í—˜ë„ ì¡°ì •\n",
    "        final_risk_level = self._finalize_risk_level(\n",
    "            max_risk_level, has_positive_context\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"risk_level\": final_risk_level,\n",
    "            \"detected_risks\": detected_risks,\n",
    "            \"requires_intervention\": final_risk_level in [\"critical\", \"high\"],\n",
    "            \"has_positive_context\": has_positive_context,\n",
    "            \"risk_message\": self._get_risk_message(final_risk_level),\n",
    "            \"timestamp\": datetime.now(),\n",
    "        }\n",
    "\n",
    "    def _check_positive_context(self, text: str) -> bool:\n",
    "        \"\"\"ê¸ì •ì  ë§¥ë½ ì²´í¬\"\"\"\n",
    "        for pattern in self.positive_context:\n",
    "            if re.search(pattern, text):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _is_higher_risk(self, level1: str, level2: str) -> bool:\n",
    "        \"\"\"ìœ„í—˜ë„ ë¹„êµ\"\"\"\n",
    "        risk_order = {\"low\": 0, \"medium\": 1, \"high\": 2, \"critical\": 3}\n",
    "        return risk_order.get(level1, 0) > risk_order.get(level2, 0)\n",
    "\n",
    "    def _finalize_risk_level(self, max_risk: str, has_positive: bool) -> str:\n",
    "        \"\"\"ìµœì¢… ìœ„í—˜ë„ ê²°ì •\"\"\"\n",
    "        # ê¸ì •ì  ë§¥ë½ì´ ìˆìœ¼ë©´ ìœ„í—˜ë„ ë‚®ì¶¤\n",
    "        if has_positive and max_risk in [\"medium\", \"high\"]:\n",
    "            return \"low\"\n",
    "\n",
    "        # criticalì€ í•­ìƒ ìœ ì§€ (ìƒëª…ê³¼ ì§ê²°)\n",
    "        if max_risk == \"critical\":\n",
    "            return \"critical\"\n",
    "\n",
    "        return max_risk\n",
    "\n",
    "    def _get_risk_message(self, risk_level: str) -> str:\n",
    "        \"\"\"ìœ„í—˜ë„ë³„ ë©”ì‹œì§€\"\"\"\n",
    "        messages = {\n",
    "            \"critical\": \"ì •ë§ í˜ë“  ìƒí™©ì´ì‹œêµ°ìš”. í˜¼ì ê²¬ë””ì§€ ë§ˆì‹œê³  ì¦‰ì‹œ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”.\",\n",
    "            \"high\": \"ì–´ë ¤ìš´ ìƒí™©ì— ê³„ì‹œëŠ” ê²ƒ ê°™ì•„ìš”. ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ì•„ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\",\n",
    "            \"medium\": \"ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ìˆìœ¼ì‹œêµ°ìš”. ë§ˆìŒì„ ëŒë³¼ í•„ìš”ê°€ ìˆì„ ê²ƒ ê°™ì•„ìš”.\",\n",
    "            \"low\": \"ê´œì°®ìœ¼ì‹œë‹¤ë‹ˆ ë‹¤í–‰ì´ì—ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!\",\n",
    "        }\n",
    "        return messages.get(risk_level, \"ì•ˆë…•í•˜ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "class LocationBasedCenterMatcher:\n",
    "    \"\"\"ìœ„ì¹˜ ê¸°ë°˜ ì„¼í„° ë§¤ì¹­ (ê°„ë‹¨ ë²„ì „)\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str = None):\n",
    "        if csv_path and os.path.exists(csv_path):\n",
    "            self.centers = self._load_from_csv(csv_path)\n",
    "        else:\n",
    "            self.centers = self._load_default_centers()\n",
    "\n",
    "        # ì£¼ìš” ë„ì‹œ ì¢Œí‘œ\n",
    "        self.city_coords = {\n",
    "            \"ê°•ë¦‰\": (37.7519, 128.8761),\n",
    "            \"ì›ì£¼\": (37.3422, 127.9202),\n",
    "            \"ì¶˜ì²œ\": (37.8813, 127.7298),\n",
    "            \"ì°½ì›\": (35.2281, 128.6811),\n",
    "            \"ê¹€í•´\": (35.2281, 128.8890),\n",
    "            \"ì§„ì£¼\": (35.1742, 128.0959),\n",
    "        }\n",
    "\n",
    "    def _load_from_csv(self, csv_path: str):\n",
    "        \"\"\"CSVì—ì„œ ì„¼í„° ì •ë³´ ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "            centers = []\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                if pd.notna(row.get(\"ì„¼í„°ëª…\")) and pd.notna(row.get(\"ì „í™”ë²ˆí˜¸\")):\n",
    "                    center = SupportCenter(\n",
    "                        region=str(row.get(\"ì‹œë„ëª…\", \"N/A\")),\n",
    "                        name=str(row.get(\"ì„¼í„°ëª…\")),\n",
    "                        address=str(row.get(\"ì†Œì¬ì§€\", \"N/A\")),\n",
    "                        phone=str(row.get(\"ì „í™”ë²ˆí˜¸\")),\n",
    "                        website=str(row.get(\"í™ˆí˜ì´ì§€\", \"\")),\n",
    "                        latitude=float(row.get(\"ìœ„ë„\", 0.0)),\n",
    "                        longitude=float(row.get(\"ê²½ë„\", 0.0)),\n",
    "                        center_type=str(row.get(\"ìœ í˜•\", \"ì§€ì›ì„¼í„°\")),\n",
    "                    )\n",
    "                    if center.latitude != 0.0 and center.longitude != 0.0:\n",
    "                        centers.append(center)\n",
    "\n",
    "            print(f\"âœ… CSVì—ì„œ {len(centers)}ê°œ ì„¼í„° ë¡œë“œ\")\n",
    "            return centers\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            return self._load_default_centers()\n",
    "\n",
    "    def _load_default_centers(self):\n",
    "        \"\"\"ê¸°ë³¸ ì„¼í„° ë°ì´í„°\"\"\"\n",
    "        default_data = [\n",
    "            {\n",
    "                \"region\": \"ê°•ì›\",\n",
    "                \"name\": \"ê°•ë¦‰ì¤‘ë…ê´€ë¦¬í†µí•©ì§€ì›ì„¼í„°\",\n",
    "                \"address\": \"ê°•ë¦‰ì‹œ ê²½ê°•ë¡œ 2279\",\n",
    "                \"phone\": \"033-653-9668\",\n",
    "                \"website\": \"https://gnamc.or.kr/\",\n",
    "                \"latitude\": 37.7667,\n",
    "                \"longitude\": 128.9110,\n",
    "                \"center_type\": \"ì¤‘ë…ê´€ë¦¬ì„¼í„°\",\n",
    "            },\n",
    "            {\n",
    "                \"region\": \"ê°•ì›\",\n",
    "                \"name\": \"ì›ì£¼ì‹œì¤‘ë…ê´€ë¦¬í†µí•©ì§€ì›ì„¼í„°\",\n",
    "                \"address\": \"ì›ì£¼ì‹œ ì›ì¼ë¡œ 139\",\n",
    "                \"phone\": \"033-748-5119\",\n",
    "                \"website\": \"http://alja.yonsei.ac.kr\",\n",
    "                \"latitude\": 37.3515,\n",
    "                \"longitude\": 127.9468,\n",
    "                \"center_type\": \"ì¤‘ë…ê´€ë¦¬ì„¼í„°\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        return [SupportCenter(**data) for data in default_data]\n",
    "\n",
    "    def find_nearest_centers(\n",
    "        self,\n",
    "        user_coords: Tuple[float, float],\n",
    "        max_distance: float = 50.0,\n",
    "        limit: int = 3,\n",
    "    ):\n",
    "        \"\"\"ê°€ì¥ ê°€ê¹Œìš´ ì„¼í„° ì°¾ê¸°\"\"\"\n",
    "        if not user_coords:\n",
    "            return []\n",
    "\n",
    "        center_distances = []\n",
    "\n",
    "        for center in self.centers:\n",
    "            try:\n",
    "                distance = geodesic(\n",
    "                    user_coords, (center.latitude, center.longitude)\n",
    "                ).kilometers\n",
    "\n",
    "                if distance <= max_distance:\n",
    "                    center_info = {\n",
    "                        \"name\": center.name,\n",
    "                        \"phone\": center.phone,\n",
    "                        \"address\": center.address,\n",
    "                        \"distance\": round(distance, 1),\n",
    "                        \"center_type\": center.center_type,\n",
    "                    }\n",
    "                    center_distances.append(center_info)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # ê±°ë¦¬ìˆœ ì •ë ¬\n",
    "        center_distances.sort(key=lambda x: x[\"distance\"])\n",
    "        return center_distances[:limit]\n",
    "\n",
    "    def get_location_from_text(self, text: str) -> Optional[Tuple[float, float]]:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ì—ì„œ ìœ„ì¹˜ ì¶”ì¶œ\"\"\"\n",
    "        for city, coords in self.city_coords.items():\n",
    "            if city in text:\n",
    "                return coords\n",
    "        return None\n",
    "\n",
    "\n",
    "class LocationHandler:\n",
    "    \"\"\"ìœ„ì¹˜ ì •ë³´ ì²˜ë¦¬\"\"\"\n",
    "\n",
    "    def __init__(self, center_matcher):\n",
    "        self.center_matcher = center_matcher\n",
    "        self.location_cache = {}\n",
    "\n",
    "    def process_user_location(\n",
    "        self,\n",
    "        user_id: str,\n",
    "        latitude: float = None,\n",
    "        longitude: float = None,\n",
    "        location_text: str = None,\n",
    "    ):\n",
    "        \"\"\"ì‚¬ìš©ì ìœ„ì¹˜ ì²˜ë¦¬\"\"\"\n",
    "\n",
    "        # GPS ì¢Œí‘œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©\n",
    "        if latitude and longitude:\n",
    "            coords = (latitude, longitude)\n",
    "            return {\n",
    "                \"coordinates\": coords,\n",
    "                \"location_source\": \"gps\",\n",
    "                \"location_accuracy\": \"high\",\n",
    "            }\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ì—ì„œ ìœ„ì¹˜ ì¶”ì¶œ\n",
    "        if location_text:\n",
    "            coords = self.center_matcher.get_location_from_text(location_text)\n",
    "            if coords:\n",
    "                return {\n",
    "                    \"coordinates\": coords,\n",
    "                    \"location_source\": \"text\",\n",
    "                    \"location_accuracy\": \"medium\",\n",
    "                }\n",
    "\n",
    "        # ìœ„ì¹˜ ì •ë³´ ì—†ìŒ\n",
    "        return {\n",
    "            \"coordinates\": None,\n",
    "            \"location_source\": None,\n",
    "            \"location_accuracy\": \"none\",\n",
    "            \"needs_location_request\": True,\n",
    "        }\n",
    "\n",
    "\n",
    "class YouthLanguageProcessor:\n",
    "    \"\"\"ì²­ì†Œë…„ ì–¸ì–´ ì²˜ë¦¬\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.youth_slang = {\n",
    "            \"ë©˜ë¶•\": \"ë©˜íƒˆ ë¶•ê´´\",\n",
    "            \"ë¹¡ì³\": \"í™”ë‚˜\",\n",
    "            \"ë ˆì•Œ\": \"ì§„ì§œ\",\n",
    "            \"ëŒ€ë°•\": \"ë†€ë¼ì›Œ\",\n",
    "        }\n",
    "\n",
    "    def process_youth_message(self, text: str):\n",
    "        \"\"\"ì²­ì†Œë…„ ë©”ì‹œì§€ ë¶„ì„\"\"\"\n",
    "        detected_slang = []\n",
    "\n",
    "        for slang, meaning in self.youth_slang.items():\n",
    "            if slang in text:\n",
    "                detected_slang.append({\"slang\": slang, \"meaning\": meaning})\n",
    "\n",
    "        # ì–¸ì–´ ìŠ¤íƒ€ì¼ íŒë‹¨\n",
    "        if detected_slang or any(char in text for char in [\"ã… ã… \", \"ã…œã…œ\", \"ã…‹ã…‹\"]):\n",
    "            language_style = \"youth_casual\"\n",
    "        else:\n",
    "            language_style = \"formal\"\n",
    "\n",
    "        return {\n",
    "            \"detected_slang\": detected_slang,\n",
    "            \"language_style\": language_style,\n",
    "            \"emotion_intensity\": (\n",
    "                \"high\" if \"ë„ˆë¬´\" in text or \"ì§„ì§œ\" in text else \"medium\"\n",
    "            ),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5824c",
   "metadata": {},
   "source": [
    "## í…ŒìŠ¤íŠ¸ í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0737e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ EmotionChatbot í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨\n",
      "============================================================\n",
      "\n",
      "ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ì „ì²´ í…ŒìŠ¤íŠ¸\n",
      "2. ê¸°ë³¸ ëŒ€í™”ë§Œ\n",
      "3. ê°ì • ì‘ë‹µë§Œ\n",
      "4. ìœ„í—˜ ìƒí™©ë§Œ\n",
      "5. ë©”ëª¨ë¦¬ ê¸°ëŠ¥ë§Œ\n",
      "ğŸ”§ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...\n",
      "ëª¨ë¸ ë””ë ‰í† ë¦¬: /Users/hwangeunbi/chatnge_AI/chat/model\n",
      "ë””ë°”ì´ìŠ¤: mps\n",
      "ì‹ ë¢°ë„ ì„ê³„ê°’: 0.6\n",
      "ê°ì • íƒì§€ ì„ê³„ê°’: 0.3\n",
      "1ë‹¨ê³„ : íŒŒì¼ í™•ì¸\n",
      "âœ… level1_best_model.pt íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level2_best_model.pt íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level3_best_model.pt íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level1_label_encoder.pkl íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level2_label_encoder.pkl íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "âœ… level3_label_encoder.pkl íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "2ë‹¨ê³„: ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ\n",
      "level1_label_encoder.pkl íŒŒì¼ì—ì„œ level1_encoder ë¡œë“œ ì™„ë£Œ\n",
      "level2_label_encoder.pkl íŒŒì¼ì—ì„œ level2_encoder ë¡œë“œ ì™„ë£Œ\n",
      "level3_label_encoder.pkl íŒŒì¼ì—ì„œ level3_encoder ë¡œë“œ ì™„ë£Œ\n",
      "3ë‹¨ê³„: BERT ëª¨ë¸ ë¡œë“œ\n",
      "BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ˜Š ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì¤‘...\n",
      "  ğŸ”„ level1_best_model.pt ë¡œë“œ ì¤‘...\n",
      "  âœ… level1_best_model.pt ë¡œë“œ ì™„ë£Œ\n",
      "  ğŸ”„ level2_best_model.pt ë¡œë“œ ì¤‘...\n",
      "  âœ… level2_best_model.pt ë¡œë“œ ì™„ë£Œ\n",
      "  ğŸ”„ level3_best_model.pt ë¡œë“œ ì¤‘...\n",
      "  âœ… level3_best_model.pt ë¡œë“œ ì™„ë£Œ\n",
      "ğŸŒŸì¼ë°˜ëŒ€í™”ìš© GPT3.5 ì´ˆê¸°í™”ì™„ë£Œ\n",
      "ğŸŒŸê°ì •ëŒ€í™”ìš© GPT4 ì´ˆê¸°í™”ì™„ë£Œ\n",
      "ğŸŒŸìœ„í—˜ëŒ€í™”ìš© Cluade ì´ˆê¸°í™”ì™„ë£Œ\n",
      "ê³µìœ  ë©”ëª¨ë¦¬ ì„¤ì • ì™„ë£Œ\n",
      "ê³µìœ  ë©”ëª¨ë¦¬ ë° ê¸°ë³¸ ì²´ì¸ ì„¤ì • ì™„ë£Œ\n",
      "âœ… ì²­ì†Œë…„ ì•ˆì „ ê¸°ëŠ¥ í™œì„±í™”ë¨\n",
      "âœ… ì±—ë´‡ ì´ˆê¸°í™” ì„±ê³µ!\n",
      "\n",
      "ğŸš¨ ìœ„í—˜ ìƒí™© í…ŒìŠ¤íŠ¸\n",
      "==================================================\n",
      "\n",
      "ğŸ‘¤ ì‚¬ìš©ì: ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ì„œ ì£½ê³  ì‹¶ì–´ìš”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_2862/3263581887.py:410: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.shared_memory = ConversationSummaryBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– AI: ğŸ’™ ë§ì´ í˜ë“œì‹œêµ°ìš”. í˜¼ìê°€ ì•„ë‹ˆì—ìš”.\n",
      "\n",
      "ğŸš¨ **ì¦‰ì‹œ ë„ì›€ì´ í•„ìš”í•˜ë‹¤ë©´:**\n",
      "â€¢ ì‘ê¸‰ìƒí™©: 112\n",
      "â€¢ ì²­ì†Œë…„ì „í™”: 1388 (24ì‹œê°„)\n",
      "â€¢ ìì‚´ì˜ˆë°©ìƒë‹´: 1393\n",
      "â€¢ ìœ„ê¸°ìƒë‹´: 1577-0199\n",
      "\n",
      "í˜¼ìê°€ ì•„ë‹ˆë¼ëŠ” ê±¸ ê¸°ì–µí•´ì£¼ì„¸ìš”. ğŸ’™\n",
      "âš ï¸ ìœ„í—˜ë„: critical\n",
      "ğŸ¥ ì¦‰ì‹œ ë„ì›€ í•„ìš”: True\n",
      "\n",
      "ğŸ‘¤ ì‚¬ìš©ì: ì•„ë¬´ë„ ë‚  ì´í•´í•´ì£¼ì§€ ì•Šì•„... í˜¼ì ìˆê³  ì‹¶ì–´\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– AI: í˜ë“  ë§ˆìŒì„ ë§ì”€í•´ì£¼ì…¨êµ°ìš”. ê·¸ë ‡ê²Œ ëŠë¼ê³  ìˆë‹¤ë‹ˆ ì •ë§ í˜ë“¤ê² ì–´ìš”. ì•„ë¬´ë„ ë‹¹ì‹ ì„ ì´í•´í•´ì£¼ì§€ ì•ŠëŠ”ë‹¤ê³  ëŠë‚„ ë•Œ, ê·¸ ì™¸ë¡œì›€ê³¼ ìƒì²˜ê°€ ì–¼ë§ˆë‚˜ ê¹Šì„ì§€ ìƒìƒí•  ìˆ˜ ìˆì–´ìš”. ì§€ê¸ˆ ì–´ë–¤ ìƒí™©ì´ë‚˜ ê°ì •ì´ ì´ëŸ° ìƒê°ì„ í•˜ê²Œ ë§Œë“¤ì—ˆì„ê¹Œìš”? í˜¼ì ìˆê³  ì‹¶ë‹¤ëŠ” ë§ˆìŒì´ ë“¤ ë•Œ, ê·¸ ê³µê°„ì—ì„œ ì–´ë–¤ ê²ƒë“¤ì„ ëŠë¼ê³  ì‹¶ì€ì§€ ê¶ê¸ˆí•´ìš”. ë‹¹ì‹ ì˜ ê°ì •ì„ ì´ë ‡ê²Œ ì†”ì§í•˜ê²Œ í‘œí˜„í•´ì¤˜ì„œ ê³ ë§ˆì›Œìš”.\n",
      "âš ï¸ ìœ„í—˜ë„: low\n",
      "ğŸ¥ ì¦‰ì‹œ ë„ì›€ í•„ìš”: False\n",
      "\n",
      "ğŸ‘¤ ì‚¬ìš©ì: ëª¨ë“  ê²Œ ì˜ë¯¸ì—†ì–´ ë³´ì—¬ìš”\n",
      "ğŸ¤– AI: í˜ë“  ë§ˆìŒì„ ë§ì”€í•´ì£¼ì…¨êµ°ìš”. ëª¨ë“  ê²ƒì´ ì˜ë¯¸ ì—†ì–´ ë³´ì¸ë‹¤ê³  ëŠë‚„ ë•Œ, ì •ë§ ë¬´ê¸°ë ¥í•˜ê³  ì§€ì¹œ ê¸°ë¶„ì¼ ê²ƒ ê°™ì•„ìš”. ê·¸ëŸ° ê°ì • ì†ì—ì„œ í•˜ë£¨í•˜ë£¨ë¥¼ ë³´ë‚´ëŠ” ê²Œ ì‰½ì§€ ì•Šì„ ê±°ì˜ˆìš”. í˜¹ì‹œ ìµœê·¼ì— ì´ëŸ° ê°ì •ì„ ë” ê°•í•˜ê²Œ ëŠë¼ê²Œ ëœ ì–´ë–¤ ì‚¬ê±´ì´ë‚˜ ë³€í™”ê°€ ìˆì—ˆì„ê¹Œìš”? ë˜ëŠ”, ì˜ˆì „ì—ëŠ” ì˜ë¯¸ê°€ ìˆì—ˆë˜ ê²ƒë“¤ì´ ì§€ê¸ˆì€ ì™œ ê·¸ë ‡ê²Œ ëŠê»´ì§€ëŠ”ì§€ ìƒê°í•´ë³¸ ì  ìˆë‚˜ìš”? ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê³  ì‹¶ì–´ìš”. í•¨ê»˜ ì´ ê°ì •ì„ ì¡°ê¸ˆì”© í’€ì–´ê°€ ë´ìš”.\n",
      "âš ï¸ ìœ„í—˜ë„: low\n",
      "ğŸ¥ ì¦‰ì‹œ ë„ì›€ í•„ìš”: False\n",
      "\n",
      "ğŸ‘¤ ì‚¬ìš©ì: ìí•´í•˜ê³  ì‹¶ì€ ì¶©ë™ì´ ë“¤ì–´ìš”\n",
      "ğŸ¤– AI: ğŸ’™ ë§ì´ í˜ë“œì‹œêµ°ìš”. í˜¼ìê°€ ì•„ë‹ˆì—ìš”.\n",
      "\n",
      "ğŸš¨ **ì¦‰ì‹œ ë„ì›€ì´ í•„ìš”í•˜ë‹¤ë©´:**\n",
      "â€¢ ì‘ê¸‰ìƒí™©: 112\n",
      "â€¢ ì²­ì†Œë…„ì „í™”: 1388 (24ì‹œê°„)\n",
      "â€¢ ìì‚´ì˜ˆë°©ìƒë‹´: 1393\n",
      "â€¢ ìœ„ê¸°ìƒë‹´: 1577-0199\n",
      "\n",
      "í˜¼ìê°€ ì•„ë‹ˆë¼ëŠ” ê±¸ ê¸°ì–µí•´ì£¼ì„¸ìš”. ğŸ’™\n",
      "âš ï¸ ìœ„í—˜ë„: critical\n",
      "ğŸ¥ ì¦‰ì‹œ ë„ì›€ í•„ìš”: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "\n",
    "class EmotionChatbotTester:\n",
    "    def __init__(self):\n",
    "        self.test_results = []\n",
    "        self.chatbot = None\n",
    "\n",
    "    def setup_chatbot(self):\n",
    "        \"\"\"ì±—ë´‡ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"ğŸ”§ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...\")\n",
    "        try:\n",
    "            self.chatbot = EmotionChatbot(\n",
    "                model_dir=\"/Users/hwangeunbi/chatnge_AI/chat/model\",\n",
    "                confidence_threshold=0.6,\n",
    "                emotion_threshold=0.3,\n",
    "                enable_safety_features=True,\n",
    "            )\n",
    "            print(\"âœ… ì±—ë´‡ ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "    def test_basic_conversation(self):\n",
    "        \"\"\"ê¸°ë³¸ ëŒ€í™” í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nğŸ“ ê¸°ë³¸ ëŒ€í™” í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        test_messages = [\n",
    "            \"ì•ˆë…•í•˜ì„¸ìš”!\",\n",
    "            \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”\",\n",
    "            \"ì ì‹¬ ë­ ë¨¹ì„ê¹Œìš”?\",\n",
    "            \"ì£¼ë§ì— ì˜í™” ë³´ë ¤ê³  í•´ìš”\",\n",
    "        ]\n",
    "\n",
    "        for msg in test_messages:\n",
    "            try:\n",
    "                print(f\"\\nğŸ‘¤ ì‚¬ìš©ì: {msg}\")\n",
    "\n",
    "                # ìŠ¤ë§ˆíŠ¸ ì‘ë‹µ í…ŒìŠ¤íŠ¸\n",
    "                if hasattr(self.chatbot, \"generate_smart_response\"):\n",
    "                    result = self.chatbot.generate_smart_response(msg)\n",
    "                    print(f\"ğŸ¤– AI ({result['model_used']}): {result['ai_response']}\")\n",
    "\n",
    "                    if \"emotion_analysis\" in result:\n",
    "                        emotion = result[\"emotion_analysis\"][\"final\"][\"prediction\"]\n",
    "                        confidence = result[\"emotion_analysis\"][\"final\"][\"confidence\"]\n",
    "                        print(f\"ğŸ“Š ê°ì •: {emotion} (ì‹ ë¢°ë„: {confidence:.2f})\")\n",
    "                else:\n",
    "                    # ê¸°ë³¸ ì‘ë‹µ í…ŒìŠ¤íŠ¸\n",
    "                    response = self.chatbot.generate_response(msg)\n",
    "                    print(f\"ğŸ¤– AI: {response}\")\n",
    "\n",
    "                time.sleep(1)  # API í˜¸ì¶œ ê°„ê²©\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def test_emotion_responses(self):\n",
    "        \"\"\"ê°ì • ì‘ë‹µ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nğŸ’­ ê°ì • ì‘ë‹µ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        emotion_messages = [\n",
    "            \"ì˜¤ëŠ˜ ì •ë§ ìš°ìš¸í•´ìš”...\",\n",
    "            \"ì‹œí—˜ì—ì„œ ë–¨ì–´ì ¸ì„œ ë„ˆë¬´ ì†ìƒí•´ìš”\",\n",
    "            \"ì¹œêµ¬ì™€ ì‹¸ì›Œì„œ í™”ê°€ ë‚˜ìš”\",\n",
    "            \"ì·¨ì—…ì´ ì•ˆë˜ì„œ ë¶ˆì•ˆí•´ìš”\",\n",
    "            \"ì—°ì¸ê³¼ í—¤ì–´ì ¸ì„œ ìŠ¬í¼ìš”\",\n",
    "        ]\n",
    "\n",
    "        for msg in emotion_messages:\n",
    "            try:\n",
    "                print(f\"\\nğŸ‘¤ ì‚¬ìš©ì: {msg}\")\n",
    "\n",
    "                if hasattr(self.chatbot, \"generate_smart_response\"):\n",
    "                    result = self.chatbot.generate_smart_response(msg)\n",
    "                    print(f\"ğŸ¤– AI ({result['model_used']}): {result['ai_response']}\")\n",
    "\n",
    "                    emotion = result[\"emotion_analysis\"][\"final\"][\"prediction\"]\n",
    "                    confidence = result[\"emotion_analysis\"][\"final\"][\"confidence\"]\n",
    "                    print(f\"ğŸ“Š ê°ì •: {emotion} (ì‹ ë¢°ë„: {confidence:.2f})\")\n",
    "                else:\n",
    "                    response = self.chatbot.generate_response_with_emotion_detection(\n",
    "                        msg\n",
    "                    )\n",
    "                    print(f\"ğŸ¤– AI: {response}\")\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def test_risk_scenarios(self):\n",
    "        \"\"\"ìœ„í—˜ ìƒí™© í…ŒìŠ¤íŠ¸ (ì•ˆì „ ê¸°ëŠ¥ í™œì„±í™” í•„ìš”)\"\"\"\n",
    "        print(\"\\nğŸš¨ ìœ„í—˜ ìƒí™© í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        risk_messages = [\n",
    "            \"ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ì„œ ì£½ê³  ì‹¶ì–´ìš”\",\n",
    "            \"ì•„ë¬´ë„ ë‚  ì´í•´í•´ì£¼ì§€ ì•Šì•„... í˜¼ì ìˆê³  ì‹¶ì–´\",\n",
    "            \"ëª¨ë“  ê²Œ ì˜ë¯¸ì—†ì–´ ë³´ì—¬ìš”\",\n",
    "            \"ìí•´í•˜ê³  ì‹¶ì€ ì¶©ë™ì´ ë“¤ì–´ìš”\",\n",
    "        ]\n",
    "\n",
    "        for msg in risk_messages:\n",
    "            try:\n",
    "                print(f\"\\nğŸ‘¤ ì‚¬ìš©ì: {msg}\")\n",
    "\n",
    "                if hasattr(self.chatbot, \"process_youth_message\"):\n",
    "                    result = self.chatbot.process_youth_message(\n",
    "                        text=msg,\n",
    "                        user_id=\"test_user\",\n",
    "                        latitude=37.5665,  # ì„œìš¸ ì¢Œí‘œ\n",
    "                        longitude=126.9780,\n",
    "                    )\n",
    "\n",
    "                    print(f\"ğŸ¤– AI: {result['ai_response']}\")\n",
    "                    print(\n",
    "                        f\"âš ï¸ ìœ„í—˜ë„: {result.get('final_risk_analysis', {}).get('risk_level', 'unknown')}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"ğŸ¥ ì¦‰ì‹œ ë„ì›€ í•„ìš”: {result.get('requires_immediate_help', False)}\"\n",
    "                    )\n",
    "\n",
    "                    if result.get(\"nearby_centers\"):\n",
    "                        print(f\"ğŸ¥ ê·¼ì²˜ ì„¼í„°: {len(result['nearby_centers'])}ê°œ ë°œê²¬\")\n",
    "                else:\n",
    "                    response = self.chatbot.generate_response(msg)\n",
    "                    print(f\"ğŸ¤– AI: {response}\")\n",
    "\n",
    "                time.sleep(2)  # ìœ„í—˜ ìƒí™©ì´ë¯€ë¡œ ë” ê¸´ ê°„ê²©\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def test_memory_functionality(self):\n",
    "        \"\"\"ë©”ëª¨ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nğŸ§  ë©”ëª¨ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        conversation_flow = [\n",
    "            \"ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì˜ˆìš”.\",\n",
    "            \"ì €ëŠ” ëŒ€í•™ìƒì´ê³  ì»´í“¨í„°ê³µí•™ê³¼ì— ë‹¤ë…€ìš”.\",\n",
    "            \"ì œ ì´ë¦„ì´ ë­ì˜€ì£ ?\",\n",
    "            \"ì œê°€ ì–´ë–¤ ì „ê³µì´ë¼ê³  í–ˆì£ ?\",\n",
    "        ]\n",
    "\n",
    "        for msg in conversation_flow:\n",
    "            try:\n",
    "                print(f\"\\nğŸ‘¤ ì‚¬ìš©ì: {msg}\")\n",
    "\n",
    "                response = self.chatbot.generate_response(msg)\n",
    "                print(f\"ğŸ¤– AI: {response}\")\n",
    "\n",
    "                # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "                if hasattr(self.chatbot, \"get_memory_status\"):\n",
    "                    memory_status = self.chatbot.get_memory_status()\n",
    "                    print(\n",
    "                        f\"ğŸ’­ ë©”ëª¨ë¦¬: {memory_status.get('message_count', 0)}ê°œ ë©”ì‹œì§€\"\n",
    "                    )\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def test_model_selection(self):\n",
    "        \"\"\"ëª¨ë¸ ì„ íƒ ë¡œì§ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nğŸ¤– ëª¨ë¸ ì„ íƒ ë¡œì§ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        test_scenarios = [\n",
    "            (\"ì¼ë°˜ëŒ€í™”\", \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œìš”?\"),\n",
    "            (\"ê°ì •ìƒë‹´\", \"ìš”ì¦˜ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë„ˆë¬´ ì‹¬í•´ìš”\"),\n",
    "            (\"ìœ„í—˜ìƒí™©\", \"ì‚¶ì´ ë„ˆë¬´ í˜ë“¤ì–´ì„œ í¬ê¸°í•˜ê³  ì‹¶ì–´ìš”\"),\n",
    "        ]\n",
    "\n",
    "        for scenario_type, msg in test_scenarios:\n",
    "            try:\n",
    "                print(f\"\\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤: {scenario_type}\")\n",
    "                print(f\"ğŸ‘¤ ì‚¬ìš©ì: {msg}\")\n",
    "\n",
    "                if hasattr(self.chatbot, \"_choose_model\"):\n",
    "                    model, emotion_result, risk_analysis = self.chatbot._choose_model(\n",
    "                        msg\n",
    "                    )\n",
    "                    print(f\"ğŸ¯ ì„ íƒëœ ëª¨ë¸: {model}\")\n",
    "                    print(f\"ğŸ“Š ê°ì •: {emotion_result['final']['prediction']}\")\n",
    "                    if risk_analysis:\n",
    "                        print(f\"âš ï¸ ìœ„í—˜ë„: {risk_analysis.get('risk_level', 'N/A')}\")\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def test_threshold_adjustment(self):\n",
    "        \"\"\"ì„ê³„ê°’ ì¡°ì • í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nâš™ï¸ ì„ê³„ê°’ ì¡°ì • í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        try:\n",
    "            # í˜„ì¬ ì„ê³„ê°’ í™•ì¸\n",
    "            if hasattr(self.chatbot, \"get_thresholds\"):\n",
    "                current = self.chatbot.get_thresholds()\n",
    "                print(f\"í˜„ì¬ ì„ê³„ê°’: {current}\")\n",
    "\n",
    "            # ì„ê³„ê°’ ë³€ê²½\n",
    "            if hasattr(self.chatbot, \"set_thresholds\"):\n",
    "                self.chatbot.set_thresholds(\n",
    "                    confidence_threshold=0.8, emotion_threshold=0.4\n",
    "                )\n",
    "                print(\"ì„ê³„ê°’ ë³€ê²½ ì™„ë£Œ\")\n",
    "\n",
    "                # ë³€ê²½ëœ ì„ê³„ê°’ í™•ì¸\n",
    "                new_thresholds = self.chatbot.get_thresholds()\n",
    "                print(f\"ìƒˆ ì„ê³„ê°’: {new_thresholds}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def test_conversation_summary(self):\n",
    "        \"\"\"ëŒ€í™” ìš”ì•½ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        print(\"\\nğŸ“„ ëŒ€í™” ìš”ì•½ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        try:\n",
    "            # ëŒ€í™” ê¸°ë¡ í™•ì¸\n",
    "            if hasattr(self.chatbot, \"get_chat_history\"):\n",
    "                history = self.chatbot.get_chat_history()\n",
    "                print(f\"ğŸ“ ëŒ€í™” ê¸°ë¡: {len(history)}ê°œ ë©”ì‹œì§€\")\n",
    "\n",
    "            # ëŒ€í™” ìš”ì•½ ìƒì„±\n",
    "            if hasattr(self.chatbot, \"get_conversation_summary\"):\n",
    "                summary = self.chatbot.get_conversation_summary()\n",
    "                print(f\"ğŸ“‹ ëŒ€í™” ìš”ì•½:\\n{summary}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    def run_all_tests(self):\n",
    "        \"\"\"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "        print(\"ğŸ§ª EmotionChatbot ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # ì±—ë´‡ ì´ˆê¸°í™”\n",
    "        if not self.setup_chatbot():\n",
    "            print(\"âŒ ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨\")\n",
    "            return\n",
    "\n",
    "        tests = [\n",
    "            (\"ê¸°ë³¸ ëŒ€í™”\", self.test_basic_conversation),\n",
    "            (\"ê°ì • ì‘ë‹µ\", self.test_emotion_responses),\n",
    "            (\"ë©”ëª¨ë¦¬ ê¸°ëŠ¥\", self.test_memory_functionality),\n",
    "            (\"ëª¨ë¸ ì„ íƒ\", self.test_model_selection),\n",
    "            (\"ì„ê³„ê°’ ì¡°ì •\", self.test_threshold_adjustment),\n",
    "            (\"ëŒ€í™” ìš”ì•½\", self.test_conversation_summary),\n",
    "            (\"ìœ„í—˜ ìƒí™©\", self.test_risk_scenarios),  # ë§ˆì§€ë§‰ì— ì‹¤í–‰ (ë¯¼ê°í•œ ë‚´ìš©)\n",
    "        ]\n",
    "\n",
    "        for test_name, test_func in tests:\n",
    "            try:\n",
    "                print(f\"\\nğŸ§ª {test_name} í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "                test_func()\n",
    "                print(f\"âœ… {test_name} í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "            time.sleep(2)  # í…ŒìŠ¤íŠ¸ ê°„ íœ´ì‹\n",
    "\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        if hasattr(self.chatbot, \"clear_memory\"):\n",
    "            self.chatbot.clear_memory()\n",
    "            print(\"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸš€ EmotionChatbot í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # API í‚¤ í™•ì¸\n",
    "    if (\n",
    "        not os.getenv(\"OPENAI_API_KEY\")\n",
    "        or os.getenv(\"OPENAI_API_KEY\") == \"your-openai-api-key-here\"\n",
    "    ):\n",
    "        print(\"âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!\")\n",
    "        print(\"export OPENAI_API_KEY='your-actual-api-key'\")\n",
    "\n",
    "    if (\n",
    "        not os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        or os.getenv(\"ANTHROPIC_API_KEY\") == \"your-anthropic-api-key-here\"\n",
    "    ):\n",
    "        print(\"âš ï¸ ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!\")\n",
    "        print(\"export ANTHROPIC_API_KEY='your-actual-api-key'\")\n",
    "\n",
    "    print(\"\\nì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:\")\n",
    "\n",
    "    print(\"1. ì „ì²´ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"2. ê¸°ë³¸ ëŒ€í™”ë§Œ\")\n",
    "    print(\"3. ê°ì • ì‘ë‹µë§Œ\")\n",
    "    print(\"4. ìœ„í—˜ ìƒí™©ë§Œ\")\n",
    "    print(\"5. ë©”ëª¨ë¦¬ ê¸°ëŠ¥ë§Œ\")\n",
    "\n",
    "    try:\n",
    "        choice = input(\"\\nì„ íƒ (1-5): \").strip()\n",
    "\n",
    "        tester = EmotionChatbotTester()\n",
    "\n",
    "        if choice == \"1\":\n",
    "            tester.run_all_tests()\n",
    "        elif choice == \"2\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_basic_conversation()\n",
    "        elif choice == \"3\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_emotion_responses()\n",
    "        elif choice == \"4\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_risk_scenarios()\n",
    "        elif choice == \"5\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_memory_functionality()\n",
    "        else:\n",
    "            print(\"âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ›‘ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0a13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
