{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ce73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.get_default_device() 함수가 없다고 떠서 대체 함수 정의\n",
    "\n",
    "\n",
    "def _get_default_device():\n",
    "    \"\"\"torch.get_default_device() 대체 함수\"\"\"\n",
    "\n",
    "    # gpu가 있으면 cuda 디바이스로 반환\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # apple m1,m2 칩이 있으면 mps 디바이스로 반환\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    # 그 외는 cpu 디바이스로 반환\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617dbce",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898ce71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "chatnge_ai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_teddynote import logging\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from langchain_core.prompts import load_prompt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 클로드 api 키를 환경 변수에서 불러옴\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# 제미나이 api 키를 환경 변수에서 불러옴\n",
    "api_key3 = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"chatnge_ai\")\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b0fe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0435c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer 임포트 전에 환경 설정\n",
    "\n",
    "# transformers 라이브러리가 온라인 모드로 동작하도록 설정\n",
    "## 모델 다운로드 설정\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "# KLUE/BERT 모델 사용하기 위해 Hugging Face 모델 접근할 수 있도록 설정\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b638caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformers 라이브러리 로드 완료\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel, logging as transformers_logging\n",
    "\n",
    "    transformers_logging.set_verbosity_error()  # 경고 메시지 최소화\n",
    "    print(\"✅ Transformers 라이브러리 로드 완료\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Transformers 라이브러리 임포트 실패: {e}\")\n",
    "    print(\"pip install transformers를 실행해주세요.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torch에 없는 함수 추가\n",
    "torch.get_default_device = _get_default_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707289",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 불용어 리스트\n",
    "KOREAN_STOPWORDS = [\n",
    "    \"이\",\n",
    "    \"그\",\n",
    "    \"저\",\n",
    "    \"것\",\n",
    "    \"및\",\n",
    "    \"에\",\n",
    "    \"를\",\n",
    "    \"은\",\n",
    "    \"는\",\n",
    "    \"이런\",\n",
    "    \"저런\",\n",
    "    \"그런\",\n",
    "    \"한\",\n",
    "    \"이르\",\n",
    "    \"또한\",\n",
    "    \"있\",\n",
    "    \"하\",\n",
    "    \"에서\",\n",
    "    \"으로\",\n",
    "    \"으로써\",\n",
    "    \"로써\",\n",
    "    \"로서\",\n",
    "    \"로\",\n",
    "    \"와\",\n",
    "    \"과\",\n",
    "    \"이고\",\n",
    "    \"이며\",\n",
    "    \"이다\",\n",
    "    \"있다\",\n",
    "    \"하다\",\n",
    "    \"되다\",\n",
    "    \"이\",\n",
    "    \"가\",\n",
    "    \"을\",\n",
    "    \"를\",\n",
    "    \"에게\",\n",
    "    \"의\",\n",
    "    \"뿐\",\n",
    "    \"다\",\n",
    "    \"적\",\n",
    "    \"데\",\n",
    "    \"때\",\n",
    "    \"나\",\n",
    "    \"도\",\n",
    "    \"만\",\n",
    "    \"께\",\n",
    "    \"에게서\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6f6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 텍스트 전처리\n",
    "def preprocess_korean_text(text):\n",
    "    # 만약에 텍스트가 없으면 그냥 빈칸 반환\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # 반복 문자 정규화\n",
    "    text = re.sub(r\"[^가-힣a-zA-Z0-9\\s\\.,!?]\", \" \", text)  # 특수문자 제거\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 공백 정리\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stopwords=KOREAN_STOPWORDS):\n",
    "    \"\"\"주어진 텍스트에서 불용어 제거\"\"\"\n",
    "    # 아무것도 없으면 그냥 반환\n",
    "    if pd.isna(text) or text is None or len(str(text).strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95013df4",
   "metadata": {},
   "source": [
    "## 감정 분류기 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(torch.nn.Module):\n",
    "    \"\"\"감정 분류기 모델 - BERT 기반의 감정 분류를 위한 신경망 모델\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model, num_classes, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        모델 초기화\n",
    "\n",
    "        Args:\n",
    "            bert_model: 사전 훈련된 BERT 모델 (예: BertModel)\n",
    "            num_classes: 분류할 감정 클래스의 개수\n",
    "            dropout_rate: 드롭아웃 비율 (기본값: 0.3)\n",
    "        \"\"\"\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "\n",
    "        # BERT 모델을 백본으로 사용\n",
    "        self.bert = bert_model\n",
    "        # BERT의 히든 사이즈 (일반적으로 768)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # 과적합 방지를 위한 드롭아웃 레이어\n",
    "        self.dropout1 = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 어텐션 메커니즘: 각 토큰의 중요도를 계산\n",
    "        self.attention = torch.nn.Sequential(\n",
    "            # 히든 사이즈를 256차원으로 축소\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # Tanh 활성화 함수로 비선형성 추가\n",
    "            torch.nn.Tanh(),\n",
    "            # 256차원을 1차원으로 축소하여 어텐션 스코어 생성\n",
    "            torch.nn.Linear(256, 1),\n",
    "            # Softmax로 어텐션 가중치를 정규화 (합이 1이 되도록)\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        # 최종 분류를 위한 분류기\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # 히든 사이즈를 256차원으로 축소\n",
    "            torch.nn.Linear(self.hidden_size, 256),\n",
    "            # ReLU 활성화 함수\n",
    "            torch.nn.ReLU(),\n",
    "            # 배치 정규화로 학습 안정성 향상\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            # 드롭아웃으로 과적합 방지\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            # 최종 감정 클래스 개수만큼 출력\n",
    "            torch.nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            input_ids: 토크나이징된 입력 텍스트의 ID\n",
    "            attention_mask: 패딩 토큰을 무시하기 위한 마스크\n",
    "            token_type_ids: 문장 구분을 위한 토큰 타입 ID\n",
    "\n",
    "        Returns:\n",
    "            logits: 각 감정 클래스에 대한 점수\n",
    "        \"\"\"\n",
    "        # BERT 모델에 입력을 통과시켜 임베딩 생성\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True,  # 딕셔너리 형태로 결과 반환\n",
    "        )\n",
    "\n",
    "        # 모든 토큰의 히든 상태 (배치 크기, 시퀀스 길이, 히든 크기)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        # [CLS] 토큰의 풀링된 표현 (배치 크기, 히든 크기)\n",
    "        pooled_output = outputs.pooler_output\n",
    "\n",
    "        # 어텐션 가중치 계산: 각 토큰의 중요도 결정\n",
    "        attention_weights = self.attention(sequence_output)\n",
    "\n",
    "        # 가중합을 통해 컨텍스트 벡터 생성\n",
    "        # attention_weights와 sequence_output을 곱하고 시퀀스 차원을 따라 합산\n",
    "        context_vector = torch.sum(attention_weights * sequence_output, dim=1)\n",
    "\n",
    "        # 어텐션 기반 컨텍스트 벡터와 BERT의 풀링 출력을 결합\n",
    "        # 두 표현을 더해서 더 풍부한 표현 생성\n",
    "        final_output = context_vector + pooled_output\n",
    "\n",
    "        # 드롭아웃 적용하여 과적합 방지\n",
    "        final_output = self.dropout1(final_output)\n",
    "\n",
    "        # 분류기를 통과시켜 최종 로짓 계산\n",
    "        logits = self.classifier(final_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba10aed",
   "metadata": {},
   "source": [
    "## 계층적 감정 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7057fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalEmotionClassifier:\n",
    "    def __init__(self, model_dir, confidence_threshold=0.6, emotion_threshold=0.3):\n",
    "\n",
    "        self.model_dir = model_dir  # 모델 경로 설정\n",
    "        self.device = _get_default_device()  # 디바이스 설정\n",
    "        self.max_len = 128  # 최대 길이 설정ㅁ\n",
    "\n",
    "        # 디버깅용\n",
    "        print(f\"모델 디렉토리: {self.model_dir}\")\n",
    "        print(f\"디바이스: {self.device}\")\n",
    "\n",
    "        # 임계값 설정\n",
    "        self.confidence_threshold = confidence_threshold  # 신뢰도 임계값\n",
    "        self.emotion_threshold = emotion_threshold  # 감정 탐지 임계값\n",
    "\n",
    "        print(f\"신뢰도 임계값: {self.confidence_threshold}\")\n",
    "        print(f\"감정 탐지 임계값: {self.emotion_threshold}\")\n",
    "\n",
    "        # 변수 초기화\n",
    "        self.tokenizer = None\n",
    "        self.bert_model = None\n",
    "        self.level1_model = None\n",
    "        self.level2_model = None\n",
    "        self.level3_model = None\n",
    "        self.level1_labels = None\n",
    "        self.level2_labels = None\n",
    "        self.level3_labels = None\n",
    "\n",
    "        # 모델 로드\n",
    "        self._load_models()\n",
    "\n",
    "    def _check_files(self):\n",
    "        print(\"1단계 : 파일 확인\")\n",
    "        # 필수 파일들 정의\n",
    "        required_files = [\n",
    "            \"level1_best_model.pt\",\n",
    "            \"level2_best_model.pt\",\n",
    "            \"level3_best_model.pt\",\n",
    "            \"level1_label_encoder.pkl\",\n",
    "            \"level2_label_encoder.pkl\",\n",
    "            \"level3_label_encoder.pkl\",\n",
    "        ]\n",
    "\n",
    "        # 없는 파일 확인 리스트\n",
    "        missing_files = []\n",
    "\n",
    "        for file in required_files:\n",
    "            filepath = os.path.join(self.model_dir, file)\n",
    "            if not os.path.exists(filepath):\n",
    "                missing_files.append(file)\n",
    "            else:\n",
    "                print(f\"✅ {file} 파일이 존재합니다.\")\n",
    "\n",
    "        # 만약에 누락된 파일이 있으면 예외 발생\n",
    "        if missing_files:\n",
    "            raise FileExistsError(f\"파일 누락 목록:{missing_files}\")\n",
    "\n",
    "    # 라벨 인코터 로드\n",
    "    def _load_label_encoders(self):\n",
    "        print(\"2단계: 라벨 인코더 로드\")\n",
    "\n",
    "        encoders = [\n",
    "            (\"level1_label_encoder.pkl\", \"level1_encoder\"),\n",
    "            (\"level2_label_encoder.pkl\", \"level2_encoder\"),\n",
    "            (\"level3_label_encoder.pkl\", \"level3_encoder\"),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name in encoders:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                encoder = pickle.load(f)\n",
    "                setattr(self, attr_name, encoder)\n",
    "            print(f\"{filename} 파일에서 {attr_name} 로드 완료\")\n",
    "\n",
    "    # 3단계 bert 모델 로드\n",
    "    def _load_bert_model(self):\n",
    "\n",
    "        try:\n",
    "            print(\"3단계: BERT 모델 로드\")\n",
    "            # BERT 모델과 토크나이저 로드\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "            self.bert_model = AutoModel.from_pretrained(\"klue/bert-base\")\n",
    "\n",
    "            # 디바이스 이동\n",
    "            self.bert_model = self.bert_model.to(self.device)\n",
    "            print(\"BERT 모델과 토크나이저 로드 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ BERT 모델 로드 실패: {e}\")\n",
    "            raise ImportError(\n",
    "                \"BERT 모델을 로드하는 데 실패했습니다. 'transformers' 라이브러리가 설치되어 있는지 확인하세요.\"\n",
    "            )\n",
    "\n",
    "    def _load_emotion_models(self):\n",
    "        \"\"\"감정 분류 모델들 로드\"\"\"\n",
    "        print(\"😊 감정 분류 모델 로드 중...\")\n",
    "\n",
    "        models = [\n",
    "            (\"level1_best_model.pt\", \"level1_model\", self.level1_encoder),\n",
    "            (\"level2_best_model.pt\", \"level2_model\", self.level2_encoder),\n",
    "            (\"level3_best_model.pt\", \"level3_model\", self.level3_encoder),\n",
    "        ]\n",
    "\n",
    "        for filename, attr_name, encoder in models:\n",
    "            filepath = os.path.join(self.model_dir, filename)\n",
    "\n",
    "            print(f\"  🔄 {filename} 로드 중...\")\n",
    "\n",
    "            # 모델 초기화\n",
    "            model = EmotionClassifier(\n",
    "                copy.deepcopy(self.bert_model.to(\"cpu\")), len(encoder.classes_)\n",
    "            )\n",
    "\n",
    "            # 가중치 로드\n",
    "            try:\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n",
    "            except TypeError:  # 구버전 PyTorch\n",
    "                state_dict = torch.load(filepath, map_location=\"cpu\")\n",
    "\n",
    "            model.load_state_dict(state_dict)\n",
    "\n",
    "            # 디바이스 이동 및 평가 모드\n",
    "            model = model.to(self.device)\n",
    "            model.eval()\n",
    "\n",
    "            setattr(self, attr_name, model)\n",
    "            print(f\"  ✅ {filename} 로드 완료\")\n",
    "\n",
    "    def _load_models(self):\n",
    "        \"\"\"모든 모델 로드\"\"\"\n",
    "        try:\n",
    "            # 1단계 : 파일 존재 확인\n",
    "            self._check_files()\n",
    "\n",
    "            # 2단계 : 라벨 인코더 로드\n",
    "            self._load_label_encoders()\n",
    "\n",
    "            # 3단계\n",
    "            self._load_bert_model()\n",
    "\n",
    "            # 4단계\n",
    "            self._load_emotion_models()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 모델 로드 중 오류 발생: {e}\")\n",
    "            raise\n",
    "\n",
    "    # 단일 모델 분류\n",
    "    def _predict_single(self, model, text):\n",
    "        # 전처리\n",
    "        preprocessed = preprocess_korean_text(text)\n",
    "        preprocessed = remove_stopwords(preprocessed)\n",
    "\n",
    "        # 토큰화\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            preprocessed,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # 디바이스 이동\n",
    "        input_ids = encoding[\"input_ids\"].to(self.device)\n",
    "        attention_mask = encoding[\"attention_mask\"].to(self.device)\n",
    "        token_type_ids = encoding[\"token_type_ids\"].to(self.device)\n",
    "\n",
    "        # 예측\n",
    "        with torch.no_grad():  # 그래디어언트 계산 비활성화 : 메모리 절약 + 속도 향상\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)  # 로짓 출력\n",
    "            probs = torch.nn.functional.softmax(\n",
    "                outputs, dim=1\n",
    "            )  # 확률 변환, 각 클래스별 확률값\n",
    "            _, preds = torch.max(outputs, dim=1)  # 가장 높은 확률을 가진 클래스 선택\n",
    "\n",
    "        return preds.item(), probs[0]\n",
    "\n",
    "    # 계층적 감정 분류\n",
    "    def predict_hierarchical(self, text):\n",
    "        \"\"\"계층적 예측\"\"\"\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"levels\": {},\n",
    "        }\n",
    "\n",
    "        # 1단계\n",
    "        pred1, probs1 = self._predict_single(self.level1_model, text)\n",
    "        label1 = self.level1_encoder.inverse_transform([pred1])[0]\n",
    "\n",
    "        result[\"levels\"][\"level1\"] = {\n",
    "            \"step\": \"1단계: 일반대화 vs 감정\",\n",
    "            \"prediction\": label1,\n",
    "            \"confidence\": float(probs1[pred1]),\n",
    "            \"probabilities\": {\n",
    "                self.level1_encoder.classes_[i]: float(probs1[i])\n",
    "                for i in range(len(self.level1_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label1 == \"일반대화\":\n",
    "            result[\"final\"] = {\n",
    "                \"prediction\": \"일반대화\",\n",
    "                \"confidence\": float(probs1[pred1]),\n",
    "            }\n",
    "            result[\"path\"] = [\"일반대화\"]\n",
    "            return result\n",
    "\n",
    "        # 2단계\n",
    "        pred2, probs2 = self._predict_single(self.level2_model, text)\n",
    "        label2 = self.level2_encoder.inverse_transform([pred2])[0]\n",
    "\n",
    "        result[\"levels\"][\"level2\"] = {\n",
    "            \"step\": \"2단계: 기쁨 vs 기타감정\",\n",
    "            \"prediction\": label2,\n",
    "            \"confidence\": float(probs2[pred2]),\n",
    "            \"probabilities\": {\n",
    "                self.level2_encoder.classes_[i]: float(probs2[i])\n",
    "                for i in range(len(self.level2_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if label2 == \"기쁨\":\n",
    "            result[\"final\"] = {\"prediction\": \"기쁨\", \"confidence\": float(probs2[pred2])}\n",
    "            result[\"path\"] = [\"감정\", \"기쁨\"]\n",
    "            return result\n",
    "\n",
    "        # 3단계\n",
    "        pred3, probs3 = self._predict_single(self.level3_model, text)\n",
    "        label3 = self.level3_encoder.inverse_transform([pred3])[0]\n",
    "\n",
    "        result[\"levels\"][\"level3\"] = {\n",
    "            \"step\": \"3단계: 세부 감정 분류\",\n",
    "            \"prediction\": label3,\n",
    "            \"confidence\": float(probs3[pred3]),\n",
    "            \"probabilities\": {\n",
    "                self.level3_encoder.classes_[i]: float(probs3[i])\n",
    "                for i in range(len(self.level3_encoder.classes_))\n",
    "            },\n",
    "        }\n",
    "\n",
    "        result[\"final\"] = {\"prediction\": label3, \"confidence\": float(probs3[pred3])}\n",
    "        result[\"path\"] = [\"감정\", \"기타감정\", label3]\n",
    "\n",
    "        return result\n",
    "\n",
    "    # 신뢰도 기반 복합 감정 분석\n",
    "    def predict_with_confidence_analysis(self, text, threshold=0.55):\n",
    "        result = self.predict_hierarchical(text)\n",
    "\n",
    "        # 각 단계별 신뢰도 분석\n",
    "        analysis = {\n",
    "            \"original_text\": text,\n",
    "            \"complexity_level\": \"simple\",  # simple, mixed, complex\n",
    "            \"primary_emotion\": result[\"final\"][\"prediction\"],\n",
    "            \"primary_confidence\": result[\"final\"][\"confidence\"],\n",
    "            \"mixed_emotions\": [],\n",
    "            \"uncertainty_indicators\": [],\n",
    "        }\n",
    "\n",
    "        # Level 2에서 기쁨과 기타감정 혼동 체크\n",
    "        if \"level2\" in result[\"levels\"]:\n",
    "            level2_probs = result[\"levels\"][\"level2\"][\"probabilities\"]\n",
    "            joy_prob = level2_probs.get(\"기쁨\", 0)\n",
    "            other_prob = level2_probs.get(\"기타감정\", 0)\n",
    "\n",
    "            # 확률 차이가 작으면 혼합 감정으로 판단\n",
    "            prob_diff = abs(joy_prob - other_prob)\n",
    "\n",
    "            if prob_diff < 0.3:  # 30% 이하 차이면 혼합 감정\n",
    "                analysis[\"complexity_level\"] = \"mixed\"\n",
    "                analysis[\"mixed_emotions\"].append(\n",
    "                    {\"emotion\": \"기쁨\", \"confidence\": joy_prob, \"type\": \"positive\"}\n",
    "                )\n",
    "\n",
    "                # Level 3에서 세부 감정도 추가\n",
    "                if \"level3\" in result[\"levels\"]:\n",
    "                    level3_result = result[\"levels\"][\"level3\"]\n",
    "                    analysis[\"mixed_emotions\"].append(\n",
    "                        {\n",
    "                            \"emotion\": level3_result[\"prediction\"],\n",
    "                            \"confidence\": level3_result[\"confidence\"],\n",
    "                            \"type\": \"negative_or_neutral\",\n",
    "                        }\n",
    "                    )\n",
    "        if threshold is None:\n",
    "            threshold = self.confidence_threshold\n",
    "\n",
    "        # 전반적 신뢰도가 낮으면 복잡한 감정으로 분류\n",
    "        if result[\"final\"][\"confidence\"] < threshold:\n",
    "            analysis[\"complexity_level\"] = \"complex\"\n",
    "            analysis[\"uncertainty_indicators\"].append(\n",
    "                f\"낮은 신뢰도: {result['final']['confidence']:.3f}\"\n",
    "            )\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def predict_multi_emotion_threshold(self, text, threshold=None):\n",
    "        \"\"\"임계값 이상의 모든 감정 반환 (완성된 버전)\"\"\"\n",
    "        # 임계값이 지정되지 않으면 클래스 기본값 사용\n",
    "        if threshold is None:\n",
    "            threshold = self.emotion_threshold\n",
    "\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"preprocessed_text\": remove_stopwords(preprocess_korean_text(text)),\n",
    "            \"detected_emotions\": [],\n",
    "            \"emotion_combination\": None,\n",
    "        }\n",
    "\n",
    "        # 모든 단계에서 임계값 이상인 감정들 수집\n",
    "        hierarchical_result = self.predict_hierarchical(text)\n",
    "\n",
    "        all_emotions = []\n",
    "\n",
    "        # Level 1 체크\n",
    "        if \"level1\" in hierarchical_result[\"levels\"]:\n",
    "            for emotion, prob in hierarchical_result[\"levels\"][\"level1\"][\n",
    "                \"probabilities\"\n",
    "            ].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append(\n",
    "                        {\n",
    "                            \"emotion\": emotion,\n",
    "                            \"probability\": prob,\n",
    "                            \"level\": 1,\n",
    "                            \"category\": \"conversation_type\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Level 2 체크 (기쁨 vs 기타감정)\n",
    "        if \"level2\" in hierarchical_result[\"levels\"]:\n",
    "            for emotion, prob in hierarchical_result[\"levels\"][\"level2\"][\n",
    "                \"probabilities\"\n",
    "            ].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append(\n",
    "                        {\n",
    "                            \"emotion\": emotion,\n",
    "                            \"probability\": prob,\n",
    "                            \"level\": 2,\n",
    "                            \"category\": \"emotion_polarity\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Level 3 체크 (세부 감정)\n",
    "        if \"level3\" in hierarchical_result[\"levels\"]:\n",
    "            for emotion, prob in hierarchical_result[\"levels\"][\"level3\"][\n",
    "                \"probabilities\"\n",
    "            ].items():\n",
    "                if prob >= threshold:\n",
    "                    all_emotions.append(\n",
    "                        {\n",
    "                            \"emotion\": emotion,\n",
    "                            \"probability\": prob,\n",
    "                            \"level\": 3,\n",
    "                            \"category\": \"specific_emotion\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        result[\"detected_emotions\"] = sorted(\n",
    "            all_emotions, key=lambda x: x[\"probability\"], reverse=True\n",
    "        )\n",
    "\n",
    "        # 감정 조합 분석\n",
    "        result[\"emotion_combination\"] = self._analyze_emotion_combination(all_emotions)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _analyze_emotion_combination(self, emotions):\n",
    "        \"\"\"감정 조합 분석\"\"\"\n",
    "        # Level 2에서 기쁨과 기타감정이 모두 임계값 이상인지 체크\n",
    "        level2_emotions = [e for e in emotions if e[\"level\"] == 2]\n",
    "        level3_emotions = [e for e in emotions if e[\"level\"] == 3]\n",
    "\n",
    "        combination_type = \"single\"\n",
    "        details = {}\n",
    "\n",
    "        if len(level2_emotions) >= 2:  # 기쁨과 기타감정 둘 다 높은 확률\n",
    "            joy_emotion = next(\n",
    "                (e for e in level2_emotions if e[\"emotion\"] == \"기쁨\"), None\n",
    "            )\n",
    "            other_emotion = next(\n",
    "                (e for e in level2_emotions if e[\"emotion\"] == \"기타감정\"), None\n",
    "            )\n",
    "\n",
    "            if joy_emotion and other_emotion:\n",
    "                combination_type = \"ambivalent\"  # 양가감정\n",
    "                details = {\n",
    "                    \"positive_aspect\": {\n",
    "                        \"emotion\": \"기쁨\",\n",
    "                        \"strength\": joy_emotion[\"probability\"],\n",
    "                    },\n",
    "                    \"negative_aspect\": {\n",
    "                        \"emotions\": level3_emotions,\n",
    "                        \"primary\": (\n",
    "                            max(level3_emotions, key=lambda x: x[\"probability\"])\n",
    "                            if level3_emotions\n",
    "                            else None\n",
    "                        ),\n",
    "                    },\n",
    "                    \"conflict_intensity\": abs(\n",
    "                        joy_emotion[\"probability\"] - other_emotion[\"probability\"]\n",
    "                    ),\n",
    "                }\n",
    "\n",
    "        return {\"type\": combination_type, \"details\": details}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccf1d9",
   "metadata": {},
   "source": [
    "## 챗봇 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a362c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "class EmotionChatbot:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_dir,\n",
    "        confidence_threshold=0.6,\n",
    "        emotion_threshold=0.3,\n",
    "        centers_csv_path=None,  # 추가 : CSV 파일 경로\n",
    "        enable_safety_features=True,  # 안전 기능 활성화 옵션\n",
    "    ):\n",
    "        # 감정 분류기 초기화\n",
    "        self.classifier = HierarchicalEmotionClassifier(\n",
    "            model_dir,\n",
    "            confidence_threshold=confidence_threshold,\n",
    "            emotion_threshold=emotion_threshold,\n",
    "        )\n",
    "\n",
    "        # 임계값을 챗봇에서도 저장 (필요시 사용)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.emotion_threshold = emotion_threshold\n",
    "\n",
    "        # 프롬프트 로드\n",
    "        self.prompts = self._load_prompts()\n",
    "\n",
    "        # 다중 llm 초기화\n",
    "        self.llms = self._initialize_all_llms()\n",
    "        self.shared_memory = None  # 공유 메모리 변수 추가\n",
    "\n",
    "        # 모델별 메모리와 체인 설정\n",
    "        self._setup_model_chains()\n",
    "\n",
    "        # llm 선정을 위해 여러 API 키를 환경 변수에서 불러옴\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # API 키 가져오기\n",
    "            api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "            api_key2 = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "            if llm_provider == \"openai\":\n",
    "                if not api_key:\n",
    "                    raise ValueError(\"OPENAI_API_KEY 환경변수가 설정되지 않았습니다.\")\n",
    "\n",
    "                self.llm = ChatOpenAI(\n",
    "                    model=\"gpt-4o\", temperature=0.4, max_tokens=1000, api_key=api_key\n",
    "                )\n",
    "\n",
    "            elif llm_provider == \"claude\":\n",
    "                if not api_key2:\n",
    "                    raise ValueError(\n",
    "                        \"ANTHROPIC_API_KEY 환경변수가 설정되지 않았습니다.\"\n",
    "                    )\n",
    "\n",
    "                self.llm = ChatAnthropic(\n",
    "                    model=\"claude-opus-4-20250514\",\n",
    "                    temperature=0.4,\n",
    "                    max_tokens=1000,\n",
    "                    api_key=api_key2,\n",
    "                )\n",
    "\n",
    "            elif llm_provider == \"gemini\":\n",
    "                try:\n",
    "                    if not api_key3:\n",
    "                        raise ValueError(\"GEMINI_API_KEY 환경변수가 설정되지 않았습니다.\")\n",
    "                    \n",
    "                    print(f\"Gemini API key 존재: {bool(api_key3)}\")\n",
    "                    print(\"ChatGoogleGenerativeAI 초기화 시도...\")\n",
    "                    \n",
    "                    self.llm = ChatGoogleGenerativeAI(\n",
    "                        model=\"gemini-1.5-pro-latest\",\n",
    "                        temperature=0.4,\n",
    "                        api_key=api_key3,\n",
    "                        \n",
    "\n",
    "                    )\n",
    "                    print(\"ChatGoogleGenerativeAI 초기화 완료\")\n",
    "        \n",
    "                except Exception as gemini_error:\n",
    "                    print(f\"Gemini 초기화 중 오류: {gemini_error}\")\n",
    "                    raise\n",
    "\n",
    "            # 메모리 초기화\n",
    "            self.shared_memory = ConversationSummaryBufferMemory(\n",
    "                llm=self.llm,\n",
    "                return_messages=True,\n",
    "                max_token_limit=2000,\n",
    "                memory_key=\"chat_history\",\n",
    "            )\n",
    "\n",
    "            # 기본 프롬프트 설정\n",
    "            self.system_prompt_text = self.prompts.get(\"basic_system\")\n",
    "            if not self.system_prompt_text:\n",
    "                raise ValueError(\n",
    "                    \"basic_system 프롬프트가 로드되지 않았습니다. prompts/basic_system.yaml 파일을 확인해주세요.\"\n",
    "                )\n",
    "\n",
    "            self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_prompt_text),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.chain = self.chat_prompt | self.llm\n",
    "            print(\"✅ 챗봇 초기화 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 챗봇 초기화 중 오류 발생: {e}\")\n",
    "            raise\n",
    "        \"\"\"\n",
    "\n",
    "        # 안전 기능 추가 부분\n",
    "        if enable_safety_features:\n",
    "            # 위험 키워드 감지기 추가\n",
    "            self.risk_detector = RiskKeywordDetector()\n",
    "\n",
    "            # CSV 파일에서 센터 정보 로드\n",
    "            if centers_csv_path and os.path.exists(centers_csv_path):\n",
    "                self.center_matcher = LocationBasedCenterMatcher(centers_csv_path)\n",
    "            else:\n",
    "                # 기본 센터 사용\n",
    "                self.center_matcher = LocationBasedCenterMatcher()\n",
    "            # 위치 처리 핸들러\n",
    "            self.location_handler = LocationHandler(self.center_matcher)\n",
    "\n",
    "            # 청소년 언어 처리기\n",
    "            self.youth_processor = YouthLanguageProcessor()\n",
    "\n",
    "            # 위험 상황 로그\n",
    "            self.risk_log = []\n",
    "\n",
    "            print(\"✅ 청소년 안전 기능 활성화됨\")\n",
    "\n",
    "        else:\n",
    "            # 안전 기능 비활성화\n",
    "            self.risk_detector = None\n",
    "            self.center_matcher = None\n",
    "            self.location_handler = None\n",
    "            self.youth_processor = None\n",
    "            self.risk_log = []\n",
    "\n",
    "            print(\"⚠️ 청소년 안전 기능 비활성화됨\")\n",
    "\n",
    "    def _load_prompts(self):\n",
    "        \"\"\"YAML 파일에서 프롬프트들을 로드\"\"\"\n",
    "        prompts = {}\n",
    "\n",
    "        # 프롬프트 파일들 리스트 (복합 감정 프롬프트만)\n",
    "        prompt_files = {\n",
    "            \"basic_system\": \"prompts/basic_system.yaml\",\n",
    "            \"ambivalent_empathy\": \"prompts/ambivalent_empathy.yaml\",\n",
    "            \"mixed_validation\": \"prompts/mixed_validation.yaml\",\n",
    "            \"exploratory_empathy\": \"prompts/exploratory_empathy.yaml\",\n",
    "            \"direct_empathy\": \"prompts/direct_empathy.yaml\",\n",
    "            \"general_conversation\": \"prompts/general_conversation.yaml\",\n",
    "        }\n",
    "\n",
    "        for prompt_name, file_path in prompt_files.items():\n",
    "            try:\n",
    "                if os.path.exists(file_path):\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        data = yaml.safe_load(f)\n",
    "                        # YAML 파일에서 'template' 키를 찾아서 사용\n",
    "                        if isinstance(data, dict) and \"template\" in data:\n",
    "                            prompts[prompt_name] = data[\"template\"]\n",
    "                        elif isinstance(data, str):\n",
    "                            prompts[prompt_name] = data\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"⚠️ {file_path}에서 올바른 템플릿을 찾을 수 없습니다.\"\n",
    "                            )\n",
    "                else:\n",
    "                    print(f\"⚠️ {file_path} 파일이 존재하지 않습니다.\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {file_path} 로드 중 오류: {e}\")\n",
    "\n",
    "        return prompts\n",
    "\n",
    "    def _initialize_all_llms(self):\n",
    "        # 모든 LLM 한번에 초기화\n",
    "        llms = {}\n",
    "\n",
    "        try:\n",
    "            if openai_key:\n",
    "                # 일반 대화용\n",
    "                llms[\"gpt35\"] = ChatOpenAI(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    temperature=0.6,\n",
    "                    max_tokens=800,\n",
    "                    api_key=openai_key,\n",
    "                )\n",
    "            print(\"🌟일반대화용 GPT3.5 초기화완료\")\n",
    "\n",
    "            if openai_key:\n",
    "                # 감정 대화용\n",
    "                llms[\"gpt4o\"] = ChatOpenAI(\n",
    "                    model=\"gpt-4o\", temperature=0.3, max_tokens=1200, api_key=openai_key\n",
    "                )\n",
    "            print(\"🌟감정대화용 GPT4 초기화완료\")\n",
    "\n",
    "            if anthropic_key:\n",
    "                # 위험 키워드 탐지\n",
    "                llms[\"claude\"] = ChatAnthropic(\n",
    "                    model=\"claude-opus-4-20250514\",\n",
    "                    temperature=0.3,\n",
    "                    max_tokens=1200,\n",
    "                    api_key=anthropic_key,\n",
    "                )\n",
    "            print(\"🌟위험대화용 Cluade 초기화완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"🥺 LLM 초기화 오류{e}\")\n",
    "            raise\n",
    "        return llms\n",
    "\n",
    "    def _choose_model(self, text):\n",
    "        # 텍스트 분석후 적절한 모델 선택\n",
    "\n",
    "        # 1. 감정 분석\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "\n",
    "        # 2. 위험도 분석 (안전 기능이 있을 때만)\n",
    "        risk_analysis = None\n",
    "        if hasattr(self, \"risk_detector\") and self.risk_detector:\n",
    "            risk_analysis = self.risk_detector.detect_risk(text)\n",
    "\n",
    "        # 3. 모델 선택 로직\n",
    "        # 위험상황이면 Claude 우선\n",
    "        if risk_analysis and risk_analysis[\"requires_intervention\"]:\n",
    "            if \"claude\" in self.llms:\n",
    "                return \"claude\", emotion_result, risk_analysis\n",
    "            elif \"gpt4o\" in self.llms:  # Claude 없으면 GPT-4o로 폴백\n",
    "                return \"gpt4o\", emotion_result, risk_analysis\n",
    "\n",
    "        # 일반대화면 GPT-3.5\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        confidence = emotion_result[\"final\"][\"confidence\"]\n",
    "\n",
    "        if emotion == \"일반대화\" and confidence > 0.7:\n",
    "            if \"gpt35\" in self.llms:\n",
    "                return \"gpt35\", emotion_result, risk_analysis\n",
    "\n",
    "        # 감정관련이면 GPT-4o\n",
    "        if \"gpt4o\" in self.llms:\n",
    "            return \"gpt4o\", emotion_result, risk_analysis\n",
    "\n",
    "        # 폴백: 사용 가능한 첫 번째 모델\n",
    "        available_model = list(self.llms.keys())[0]\n",
    "        return available_model, emotion_result, risk_analysis\n",
    "\n",
    "    def generate_smart_response(self, text):\n",
    "        \"\"\"상황에 맞는 모델로 스마트 응답 생성\"\"\"\n",
    "\n",
    "        try:\n",
    "            # 1. 모델 선택\n",
    "            selected_model, emotion_result, risk_analysis = self._choose_model(text)\n",
    "\n",
    "            print(f\"🤖 선택된 모델: {selected_model}\")\n",
    "\n",
    "            # 2. 해당 모델로 응답 생성\n",
    "            response = self._generate_with_selected_model(\n",
    "                text, selected_model, emotion_result, risk_analysis\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"ai_response\": response,\n",
    "                \"model_used\": selected_model,\n",
    "                \"emotion_analysis\": emotion_result,\n",
    "                \"risk_analysis\": risk_analysis,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 응답 생성 오류: {e}\")\n",
    "            # 오류시 기본 모델로 폴백\n",
    "            fallback_model = list(self.llms.keys())[0]\n",
    "            fallback_response = (\n",
    "                f\"죄송합니다. 응답 생성 중 문제가 발생했습니다: {str(e)}\"\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"ai_response\": fallback_response,\n",
    "                \"model_used\": fallback_model + \" (fallback)\",\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "\n",
    "    def _generate_with_selected_model(\n",
    "        self, text, model_name, emotion_result, risk_analysis\n",
    "    ):\n",
    "        \"\"\"선택된 모델로 실제 응답 생성\"\"\"\n",
    "\n",
    "        # 공유 메모리에서 대화 기록 가져오기\n",
    "        chat_history = self.shared_memory.chat_memory.messages\n",
    "        llm = self.llms[model_name]\n",
    "\n",
    "        # 🔧 emotion_info 준비 (모든 경우에 사용)\n",
    "        emotion_info = f\"감정: {emotion_result['final']['prediction']}, 신뢰도: {emotion_result['final']['confidence']:.2f}\"\n",
    "\n",
    "        # 위험상황이고 Claude면 특별 처리\n",
    "        if (\n",
    "            risk_analysis\n",
    "            and risk_analysis[\"requires_intervention\"]\n",
    "            and model_name == \"claude\"\n",
    "        ):\n",
    "            response = self._generate_crisis_response_safe(\n",
    "                text, risk_analysis, [], emotion_result\n",
    "            )\n",
    "\n",
    "        elif emotion_result[\"final\"][\"prediction\"] == \"일반대화\":\n",
    "            # 🔧 일반대화: emotion_info 전달 추가\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        self.prompts.get(\n",
    "                            \"general_conversation\", \"당신은 친근한 AI 친구입니다.\"\n",
    "                        ),\n",
    "                    ),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            chain = prompt | llm\n",
    "            llm_response = chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,  # 🔧 추가\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            response = (\n",
    "                llm_response.content\n",
    "                if hasattr(llm_response, \"content\")\n",
    "                else str(llm_response)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # 감정관련: 기존 로직 사용하되 emotion_info 전달\n",
    "            response = self._generate_emotion_response_with_model(\n",
    "                text, emotion_result, chat_history, llm\n",
    "            )\n",
    "\n",
    "        # 공유 메모리에 대화 저장\n",
    "        self.shared_memory.chat_memory.add_user_message(text)\n",
    "        self.shared_memory.chat_memory.add_ai_message(response)\n",
    "\n",
    "        return response\n",
    "\n",
    "    def _generate_emotion_response_with_model(\n",
    "        self, text, emotion_result, chat_history, llm\n",
    "    ):\n",
    "        \"\"\"감정 응답 생성 (기존 로직 활용)\"\"\"\n",
    "\n",
    "        # 기본 감정 프롬프트 사용\n",
    "        system_prompt = self.prompts.get(\n",
    "            \"basic_system\", \"당신은 공감적인 상담사입니다.\"\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm\n",
    "\n",
    "        # 🔧 감정 정보 준비\n",
    "        emotion_info = f\"감정: {emotion_result['final']['prediction']}, 신뢰도: {emotion_result['final']['confidence']:.2f}\"\n",
    "\n",
    "        llm_response = chain.invoke(\n",
    "            {\n",
    "                \"message\": text,\n",
    "                \"emotion_info\": emotion_info,  # 🔧 추가\n",
    "                \"chat_history\": chat_history,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            llm_response.content\n",
    "            if hasattr(llm_response, \"content\")\n",
    "            else str(llm_response)\n",
    "        )\n",
    "\n",
    "    def _setup_model_chains(self):\n",
    "        \"\"\"공유메모리 설정\"\"\"\n",
    "\n",
    "        # 대표 모델 선택\n",
    "        if \"gpt4o\" in self.llms:\n",
    "            primary_llm = self.llms[\"gpt4o\"]\n",
    "        elif \"claude\" in self.llms:\n",
    "            primary_llm = self.llms[\"claude\"]\n",
    "        else:\n",
    "            primary_llm = list(self.llms.values())[0]\n",
    "\n",
    "        self.llm = primary_llm\n",
    "\n",
    "        # 공유메모리 생성\n",
    "        self.shared_memory = ConversationSummaryBufferMemory(\n",
    "            llm=primary_llm,\n",
    "            return_messages=True,\n",
    "            max_token_limit=2000,\n",
    "            memory_key=\"chat_history\",\n",
    "        )\n",
    "\n",
    "        print(\"공유 메모리 설정 완료\")\n",
    "\n",
    "        self.system_prompt_text = self.prompts.get(\"basic_system\")\n",
    "\n",
    "        self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_prompt_text),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.chain = self.chat_prompt | self.llm\n",
    "\n",
    "        print(\"공유 메모리 및 기본 체인 설정 완료\")\n",
    "\n",
    "    def classify_emotion(self, text):\n",
    "        \"\"\"기본 감정 분류\"\"\"\n",
    "        return self.classifier.predict_hierarchical(text)\n",
    "\n",
    "    def format_analysis(self, result):\n",
    "        \"\"\"기본 분석 결과 포맷팅\"\"\"\n",
    "        output = f\"\"\"\n",
    "📝 입력: {result['original_text']}\n",
    "🔍 전처리: {result['preprocessed_text']}\n",
    "\n",
    "🎯 최종 결과: {result['final']['prediction']} (신뢰도: {result['final']['confidence']:.4f})\n",
    "📊 예측 경로: {' → '.join(result['path'])}\n",
    "\n",
    "📈 단계별 분석:\n",
    "\"\"\"\n",
    "\n",
    "        for level, data in result[\"levels\"].items():\n",
    "            output += f\"\\n🔸 {data['step']}\\n\"\n",
    "            output += f\"   결과: {data['prediction']} ({data['confidence']:.4f})\\n\"\n",
    "            output += f\"   확률: \"\n",
    "            for emotion, prob in data[\"probabilities\"].items():\n",
    "                output += f\"{emotion}({prob:.3f}) \"\n",
    "            output += \"\\n\"\n",
    "\n",
    "        return output\n",
    "\n",
    "    def generate_response(self, text):\n",
    "        \"\"\"기본 챗봇 응답 생성 (메모리 추가)\"\"\"\n",
    "        try:\n",
    "            # 기본 감정 분류\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            # 감정 분석 포맷팅\n",
    "            emotion_info = f\"감정: {emotion_result['final']['prediction']}, 신뢰도: {emotion_result['final']['confidence']:.2f}, 경로: {' → '.join(emotion_result['path'])}\"\n",
    "\n",
    "            # 메모리에서 대화 기록 가져오기\n",
    "            chat_history = self.shared_memory.chat_memory.messages\n",
    "\n",
    "            # 체인 실행\n",
    "            response = self.chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # 응답 추출\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # 메모리에 대화저장\n",
    "                self.shared_memory.chat_memory.add_user_message(text)\n",
    "                self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"응답생성에 실패했습니다\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"응답 생성 중 오류 발생: {e}\")\n",
    "            return \"응답 생성 중 오류가 발생했습니다. 다시 시도해주세요.\"\n",
    "\n",
    "    def generate_response_with_emotion_detection(self, text):\n",
    "        \"\"\" \"감정 분류에 따라 응답 생성\"\"\"\n",
    "        try:\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            chat_history = self.shared_memory.chat_memory.messages\n",
    "\n",
    "            # 최종 예측 결과 확인\n",
    "            finally_prediction = emotion_result[\"final\"][\"prediction\"]\n",
    "\n",
    "            if finally_prediction == \"일반대화\":\n",
    "                # 일반 대화 프롬프트 사용\n",
    "                response = self.generate_general_conversation_response(\n",
    "                    text, emotion_result, chat_history\n",
    "                )\n",
    "            else:\n",
    "                # 감정이라면\n",
    "                response = self.generate_emotion_response(\n",
    "                    text, emotion_result, chat_history\n",
    "                )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"감정 분류 및 응답 생성 중 오류 발생: {e}\")\n",
    "            return \"죄송합니다. 응답 생성 중 문제가 발생했네요. 다시 말씀해 주시겠어요?\"\n",
    "\n",
    "    # 일반대화 생성\n",
    "    def generate_general_conversation_response(\n",
    "        self, text, emotion_result, chat_history\n",
    "    ):\n",
    "        \"\"\"일반 대화 응답 생성\"\"\"\n",
    "        try:\n",
    "            # 🔧 감정 정보 준비\n",
    "            emotion_info = f\"감정: {emotion_result['final']['prediction']}, 신뢰도: {emotion_result['final']['confidence']:.2f}\"\n",
    "\n",
    "            # 🔧 일반대화 프롬프트 구성\n",
    "            if \"gpt35\" in self.llms:\n",
    "                llm = self.llms[\"gpt35\"]\n",
    "            else:\n",
    "                llm = list(self.llms.values())[0]  # 폴백\n",
    "\n",
    "            general_chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        self.prompts.get(\n",
    "                            \"general_conversation\", \"당신은 친근한 AI 친구입니다.\"\n",
    "                        ),\n",
    "                    ),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # 체인 실행\n",
    "            chain = general_chat_prompt | llm\n",
    "            response = chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,  # 🔧 추가\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # 🔧 shared_memory에 대화 저장\n",
    "                self.shared_memory.chat_memory.add_user_message(text)\n",
    "                self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"응답 생성에 실패했습니다.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"일반 대화 응답 생성 중 오류 발생: {e}\")\n",
    "            return \"죄송합니다. 일반 대화 응답 생성 중 문제가 발생했네요. 다시 말씀해 주시겠어요?\"\n",
    "\n",
    "    def generate_empathetic_response(self, text):\n",
    "        \"\"\"복합 감정을 고려한 공감 응답 생성\"\"\"\n",
    "        try:\n",
    "            # 복합 감정 분석\n",
    "            emotion_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "            multi_emotion_result = self.classifier.predict_multi_emotion_threshold(text)\n",
    "\n",
    "            # 응답 전략 결정\n",
    "            response_strategy = self._determine_response_strategy(\n",
    "                emotion_analysis, multi_emotion_result\n",
    "            )\n",
    "\n",
    "            # 프롬프트에 복합 감정 정보 추가\n",
    "            emotion_context = self._format_emotion_context(\n",
    "                emotion_analysis, multi_emotion_result, response_strategy\n",
    "            )\n",
    "\n",
    "            # 메모리에서 대화 기록 가져오기\n",
    "            chat_history = self.shared_memory.chat_memory.messages\n",
    "\n",
    "            # 개선된 프롬프트로 응답 생성\n",
    "            response = self._generate_response_with_complex_emotion_context(\n",
    "                text, emotion_context, chat_history\n",
    "            )\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"공감 응답 생성 중 오류: {e}\")\n",
    "            return \"죄송합니다. 응답 생성 중 문제가 발생했네요. 다시 말씀해 주시겠어요?\"\n",
    "\n",
    "    def _determine_response_strategy(self, emotion_analysis, multi_emotion_result):\n",
    "        \"\"\"응답 전략 결정\"\"\"\n",
    "        if emotion_analysis[\"complexity_level\"] == \"mixed\":\n",
    "            if multi_emotion_result[\"emotion_combination\"][\"type\"] == \"ambivalent\":\n",
    "                return \"ambivalent_empathy\"  # 양가감정 공감\n",
    "            else:\n",
    "                return \"mixed_validation\"  # 혼합감정 인정\n",
    "        elif emotion_analysis[\"complexity_level\"] == \"complex\":\n",
    "            return \"exploratory_empathy\"  # 탐색적 공감\n",
    "        else:\n",
    "            return \"direct_empathy\"  # 직접적 공감\n",
    "\n",
    "    def _format_emotion_context(self, emotion_analysis, multi_emotion_result, strategy):\n",
    "        \"\"\"감정 맥락 포맷팅\"\"\"\n",
    "        context = {\n",
    "            \"primary_emotion\": emotion_analysis[\"primary_emotion\"],\n",
    "            \"confidence\": emotion_analysis[\"primary_confidence\"],\n",
    "            \"complexity\": emotion_analysis[\"complexity_level\"],\n",
    "            \"response_strategy\": strategy,\n",
    "        }\n",
    "\n",
    "        # 복합 감정 정보 추가\n",
    "        if emotion_analysis[\"mixed_emotions\"]:\n",
    "            context[\"mixed_emotions\"] = emotion_analysis[\"mixed_emotions\"]\n",
    "\n",
    "        # 양가감정 정보 추가\n",
    "        if multi_emotion_result[\"emotion_combination\"][\"type\"] == \"ambivalent\":\n",
    "            context[\"ambivalent_details\"] = multi_emotion_result[\"emotion_combination\"][\n",
    "                \"details\"\n",
    "            ]\n",
    "\n",
    "        return context\n",
    "\n",
    "    def _generate_response_with_complex_emotion_context(\n",
    "        self, text, emotion_context, chat_history\n",
    "    ):\n",
    "        \"\"\"복합 감정 맥락을 고려한 응답 생성\"\"\"\n",
    "\n",
    "        # 필수 프롬프트들이 모두 로드되었는지 확인\n",
    "        required_prompts = [\n",
    "            \"ambivalent_empathy\",\n",
    "            \"mixed_validation\",\n",
    "            \"exploratory_empathy\",\n",
    "            \"direct_empathy\",\n",
    "        ]\n",
    "        missing_prompts = [\n",
    "            p for p in required_prompts if p not in self.prompts or not self.prompts[p]\n",
    "        ]\n",
    "\n",
    "        if missing_prompts:\n",
    "            raise ValueError(f\"필수 프롬프트가 누락되었습니다: {missing_prompts}\")\n",
    "\n",
    "        # YAML에서 로드된 프롬프트 사용\n",
    "        strategy_prompts = {}\n",
    "        for strategy in required_prompts:\n",
    "            strategy_prompts[strategy] = self.prompts[strategy]\n",
    "\n",
    "        # 감정 정보 문자열 생성\n",
    "        emotion_info_str = f\"\"\"\n",
    "감정 분석 결과:\n",
    "- 주요 감정: {emotion_context['primary_emotion']} (신뢰도: {emotion_context['confidence']:.2f})\n",
    "- 복잡도: {emotion_context['complexity']}\n",
    "- 응답 전략: {emotion_context['response_strategy']}\n",
    "\"\"\"\n",
    "\n",
    "        if \"mixed_emotions\" in emotion_context:\n",
    "            emotion_info_str += \"\\n혼합 감정들:\\n\"\n",
    "            for emotion in emotion_context[\"mixed_emotions\"]:\n",
    "                emotion_info_str += (\n",
    "                    f\"- {emotion['emotion']}: {emotion['confidence']:.2f}\\n\"\n",
    "                )\n",
    "\n",
    "        if \"ambivalent_details\" in emotion_context:\n",
    "            details = emotion_context[\"ambivalent_details\"]\n",
    "            emotion_info_str += f\"\\n양가감정 세부사항:\\n\"\n",
    "            emotion_info_str += f\"- 긍정적 측면: {details['positive_aspect']['emotion']} ({details['positive_aspect']['strength']:.2f})\\n\"\n",
    "            if details[\"negative_aspect\"][\"primary\"]:\n",
    "                emotion_info_str += f\"- 부정적 측면: {details['negative_aspect']['primary']['emotion']} ({details['negative_aspect']['primary']['probability']:.2f})\\n\"\n",
    "\n",
    "        # 전략에 맞는 시스템 프롬프트 선택\n",
    "        system_prompt = strategy_prompts.get(\n",
    "            emotion_context[\"response_strategy\"], strategy_prompts[\"direct_empathy\"]\n",
    "        )\n",
    "\n",
    "        # 프롬프트 구성\n",
    "        chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{message}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 체인 실행\n",
    "        chain = chat_prompt | self.llm\n",
    "        response = chain.invoke(\n",
    "            {\n",
    "                \"message\": text,\n",
    "                \"chat_history\": chat_history,\n",
    "                \"emotion_info\": emotion_info_str,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if hasattr(response, \"content\"):\n",
    "            ai_response = response.content\n",
    "            # 메모리에 대화 저장\n",
    "            self.shared_memory.chat_memory.add_user_message(text)\n",
    "            self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "            return ai_response\n",
    "        else:\n",
    "            return \"응답 생성에 실패했습니다.\"\n",
    "\n",
    "    def reload_prompts(self):\n",
    "        \"\"\"프롬프트 재로드\"\"\"\n",
    "        try:\n",
    "            self.prompts = self._load_prompts()\n",
    "            self.system_prompt_text = self.prompts.get(\"basic_system\")\n",
    "            if not self.system_prompt_text:\n",
    "                print(\"⚠️ basic_system 프롬프트가 로드되지 않았습니다.\")\n",
    "                self.system_prompt_text = \"당신은 공감적인 AI 상담사입니다.\"\n",
    "\n",
    "            # 🔧 기본 체인 재생성 (self.llm 사용)\n",
    "            self.chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_prompt_text),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{message}\"),\n",
    "                ]\n",
    "            )\n",
    "            self.chain = self.chat_prompt | self.llm  # self.llm 사용\n",
    "\n",
    "            print(\"✅ 프롬프트가 성공적으로 재로드되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 프롬프트 재로드 중 오류: {e}\")\n",
    "\n",
    "    def process_message(self, text, include_ai_response=True):\n",
    "        \"\"\"기본 메시지 전체 처리\"\"\"\n",
    "        # 감정 분석\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "        emotion_analysis = self.format_analysis(emotion_result)\n",
    "\n",
    "        result = {\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"emotion_result\": emotion_result,\n",
    "        }\n",
    "\n",
    "        # AI 응답\n",
    "        if include_ai_response:\n",
    "            ai_response = self.generate_response(text)\n",
    "            result[\"ai_response\"] = ai_response\n",
    "            result[\"full_response\"] = f\"{emotion_analysis}\\n💬 AI 상담:\\n{ai_response}\"\n",
    "        else:\n",
    "            result[\"full_response\"] = emotion_analysis\n",
    "\n",
    "        return result\n",
    "\n",
    "    def process_complex_emotion_message(self, text):\n",
    "        \"\"\"복합 감정을 고려한 메시지 처리\"\"\"\n",
    "        # 기본 감정 분석\n",
    "        basic_result = self.classify_emotion(text)\n",
    "\n",
    "        # 복합 감정 분석\n",
    "        confidence_analysis = self.classifier.predict_with_confidence_analysis(text)\n",
    "        multi_emotion_analysis = self.classifier.predict_multi_emotion_threshold(text)\n",
    "\n",
    "        # 공감 응답 생성\n",
    "        ai_response = self.generate_empathetic_response(text)\n",
    "\n",
    "        # 결과 통합\n",
    "        result = {\n",
    "            \"basic_emotion_analysis\": self.format_analysis(basic_result),\n",
    "            \"confidence_analysis\": confidence_analysis,\n",
    "            \"multi_emotion_analysis\": multi_emotion_analysis,\n",
    "            \"ai_response\": ai_response,\n",
    "            \"complexity_insight\": self._generate_complexity_insight(\n",
    "                confidence_analysis, multi_emotion_analysis\n",
    "            ),\n",
    "            \"full_response\": f\"\"\"\n",
    "📊 감정 복잡성 분석:\n",
    "{chr(10).join(self._generate_complexity_insight(confidence_analysis, multi_emotion_analysis))}\n",
    "\n",
    "💬 AI 상담:\n",
    "{ai_response}\n",
    "\"\"\",\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _generate_complexity_insight(self, confidence_analysis, multi_emotion_analysis):\n",
    "        \"\"\"복잡성 인사이트 생성\"\"\"\n",
    "        insights = []\n",
    "\n",
    "        if confidence_analysis[\"complexity_level\"] == \"mixed\":\n",
    "            insights.append(\"🔀 혼합된 감정이 감지되었습니다.\")\n",
    "\n",
    "        if multi_emotion_analysis[\"emotion_combination\"][\"type\"] == \"ambivalent\":\n",
    "            insights.append(\"⚖️ 상반된 감정이 동시에 나타나는 양가감정 상태입니다.\")\n",
    "\n",
    "        if confidence_analysis[\"primary_confidence\"] < 0.6:\n",
    "            insights.append(\"🌊 감정이 복잡하고 미묘한 상태로 보입니다.\")\n",
    "\n",
    "        if len(multi_emotion_analysis[\"detected_emotions\"]) > 3:\n",
    "            insights.append(\"🎭 다양한 감정이 복합적으로 나타나고 있습니다.\")\n",
    "\n",
    "        return insights if insights else [\"💡 비교적 명확한 감정 상태입니다.\"]\n",
    "\n",
    "    # 메모리 관련 유틸리티 메서드들\n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"현재 대화 요약 가져오기\"\"\"\n",
    "        try:\n",
    "            return self.shared_memory.predict_new_summary(\n",
    "                self.shared_memory.chat_memory.messages, \"\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"대화 요약 생성 중 오류: {e}\")\n",
    "            return \"요약을 생성할 수 없습니다.\"\n",
    "\n",
    "    def get_chat_history(self):\n",
    "        \"\"\"전체 대화 기록 가져오기\"\"\"\n",
    "        if hasattr(self, \"shared_memory\") and self.shared_memory:\n",
    "            return self.shared_memory.chat_memory.messages\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def clear_memory(self):\n",
    "        \"\"\"메모리 초기화\"\"\"\n",
    "        if hasattr(self, \"shared_memory\") and self.shared_memory:\n",
    "            self.shared_memory.clear()\n",
    "            print(\"💭 공유 대화 기록이 초기화되었습니다.\")\n",
    "        else:\n",
    "            print(\"⚠️ 초기화할 메모리가 없습니다.\")\n",
    "\n",
    "    def get_memory_status(self):\n",
    "        \"\"\"메모리 상태 확인\"\"\"\n",
    "        try:\n",
    "            messages = self.shared_memory.chat_memory.messages\n",
    "            token_count = self.shared_memory.llm.get_num_tokens_from_messages(messages)\n",
    "\n",
    "            return {\n",
    "                \"message_count\": len(messages),\n",
    "                \"token_count\": token_count,\n",
    "                \"max_token_limit\": self.shared_memory.max_token_limit,\n",
    "                \"is_summarizing\": token_count > self.shared_memory.max_token_limit,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"메모리 상태 확인 중 오류: {e}\")\n",
    "            return {\n",
    "                \"message_count\": 0,\n",
    "                \"token_count\": 0,\n",
    "                \"max_token_limit\": 2000,\n",
    "                \"is_summarizing\": False,\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "\n",
    "    def set_thresholds(self, confidence_threshold=None, emotion_threshold=None):\n",
    "        \"\"\"임계값 동적 변경\"\"\"\n",
    "        if confidence_threshold is not None:\n",
    "            self.confidence_threshold = confidence_threshold\n",
    "            self.classifier.confidence_threshold = confidence_threshold\n",
    "            print(f\"신뢰도 임계값이 {confidence_threshold}로 변경되었습니다.\")\n",
    "\n",
    "        if emotion_threshold is not None:\n",
    "            self.emotion_threshold = emotion_threshold\n",
    "            self.classifier.emotion_threshold = emotion_threshold\n",
    "            print(f\"감정 탐지 임계값이 {emotion_threshold}로 변경되었습니다.\")\n",
    "\n",
    "    def get_thresholds(self):\n",
    "        \"\"\"현재 임계값 조회\"\"\"\n",
    "        return {\n",
    "            \"confidence_threshold\": self.confidence_threshold,\n",
    "            \"emotion_threshold\": self.emotion_threshold,\n",
    "        }\n",
    "\n",
    "    def generate_emotion_response(self, text, emotion_result, chat_history):\n",
    "        \"\"\"감정 관련 프롬프트로 응답 생성 (기존 로직)\"\"\"\n",
    "        try:\n",
    "            # 감정 분석 포맷팅\n",
    "            emotion_info = f\"감정: {emotion_result['final']['prediction']}, 신뢰도: {emotion_result['final']['confidence']:.2f}, 경로: {' → '.join(emotion_result['path'])}\"\n",
    "\n",
    "            # 기본 감정 프롬프트 사용\n",
    "            response = self.chain.invoke(\n",
    "                {\n",
    "                    \"message\": text,\n",
    "                    \"emotion_info\": emotion_info,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if hasattr(response, \"content\"):\n",
    "                ai_response = response.content\n",
    "\n",
    "                # 메모리에 대화 저장\n",
    "                self.shared_memory.chat_memory.add_user_message(text)\n",
    "                self.shared_memory.chat_memory.add_ai_message(ai_response)\n",
    "\n",
    "                return ai_response\n",
    "            else:\n",
    "                return \"응답 생성에 실패했습니다\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"감정 응답 생성 중 오류: {e}\")\n",
    "            return \"죄송합니다. 감정 분석 응답 생성 중 문제가 발생했습니다.\"\n",
    "\n",
    "    def process_message_with_detection(self, text, include_ai_response=True):\n",
    "        \"\"\"일반대화/감정 구분하여 메시지 처리\"\"\"\n",
    "        # 감정 분석\n",
    "        emotion_result = self.classify_emotion(text)\n",
    "        emotion_analysis = self.format_analysis(emotion_result)\n",
    "\n",
    "        result = {\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"emotion_result\": emotion_result,\n",
    "            \"conversation_type\": emotion_result[\"final\"][\n",
    "                \"prediction\"\n",
    "            ],  # 일반대화 vs 감정\n",
    "        }\n",
    "\n",
    "        # AI 응답\n",
    "        if include_ai_response:\n",
    "            ai_response = self.generate_response_with_emotion_detection(text)\n",
    "            result[\"ai_response\"] = ai_response\n",
    "            result[\"full_response\"] = (\n",
    "                f\"{emotion_analysis}\\n\\n💬 AI 응답:\\n{ai_response}\"\n",
    "            )\n",
    "        else:\n",
    "            result[\"full_response\"] = emotion_analysis\n",
    "\n",
    "        return result\n",
    "\n",
    "        # 메서드 추가\n",
    "\n",
    "    def process_youth_message(\n",
    "        self,\n",
    "        text: str,\n",
    "        user_id: str = \"default\",\n",
    "        latitude: float = None,\n",
    "        longitude: float = None,\n",
    "    ) -> Dict:\n",
    "        # 안전 기능이 비활성화되어있으면 기본 처리\n",
    "        if not hasattr(self, \"risk_detector\") or self.risk_detector is None:\n",
    "            return self.process_message(text, include_ai_response=True)\n",
    "\n",
    "        try:\n",
    "            # 1. 기본 감정 분석:\n",
    "            emotion_result = self.classify_emotion(text)\n",
    "\n",
    "            # 2. 위험 키워드 감지\n",
    "            risk_analysis = self.risk_detector.detect_risk(text)\n",
    "\n",
    "            # 3. 위험 정보 처리\n",
    "            location_result = self.location_handler.process_user_location(\n",
    "                user_id=user_id,\n",
    "                latitude=latitude,\n",
    "                longitude=longitude,\n",
    "                location_text=text,\n",
    "            )\n",
    "\n",
    "            # 4. 청소년 언어 분석\n",
    "            youth_analysis = self.youth_processor.process_youth_message(text)\n",
    "\n",
    "            # 5. 감정-위험도 일관성 체크 추가\n",
    "            consistency_check = self._check_emotion_risk_consistency(\n",
    "                emotion_result, risk_analysis\n",
    "            )\n",
    "\n",
    "            # 6. 최종 위험도 조정\n",
    "            final_risk_analysis = self._adjust_final_risk_level(\n",
    "                risk_analysis, emotion_result, consistency_check\n",
    "            )\n",
    "\n",
    "            # 7. 근처 센터 찾기 (조정된 위험도 기준)\n",
    "            nearby_centers = []\n",
    "            if (\n",
    "                final_risk_analysis[\"requires_intervention\"]\n",
    "                and location_result[\"coordinates\"]\n",
    "            ):\n",
    "                nearby_centers = self.center_matcher.find_nearest_centers(\n",
    "                    location_result[\"coordinates\"], max_distance=50.0, limit=3\n",
    "                )\n",
    "\n",
    "            # 8. 응답 생성 (조정된 위험도에 따라 다른 전략)\n",
    "            if final_risk_analysis[\"requires_intervention\"]:\n",
    "                ai_response = self._generate_crisis_response_safe(\n",
    "                    text, final_risk_analysis, nearby_centers, emotion_result\n",
    "                )\n",
    "                # 위험 상황 로깅\n",
    "                self._log_risk_situation_safe(\n",
    "                    text, final_risk_analysis, location_result, user_id\n",
    "                )\n",
    "            else:\n",
    "                ai_response = self._generate_safe_response(\n",
    "                    text, emotion_result, youth_analysis\n",
    "                )\n",
    "\n",
    "            # 9. 결과 통합\n",
    "            result = {\n",
    "                \"original_text\": text,\n",
    "                \"user_id\": user_id,\n",
    "                \"emotion_analysis\": emotion_result,\n",
    "                \"risk_analysis\": risk_analysis,\n",
    "                \"final_risk_analysis\": final_risk_analysis,\n",
    "                \"consistency_check\": consistency_check,\n",
    "                \"youth_analysis\": youth_analysis,\n",
    "                \"location_info\": location_result,\n",
    "                \"nearby_centers\": nearby_centers,\n",
    "                \"ai_response\": ai_response,\n",
    "                \"requires_immediate_help\": final_risk_analysis[\"requires_intervention\"],\n",
    "                \"timestamp\": datetime.now(),\n",
    "            }\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:  # 🆕 이 부분 추가!\n",
    "            print(f\"❌ 청소년 메시지 처리 중 오류: {e}\")\n",
    "            # 오류 시 기본 처리로 폴백\n",
    "            return self.process_message(text, include_ai_response=True)\n",
    "\n",
    "    def _generate_crisis_response_safe(\n",
    "        self,\n",
    "        text: str,\n",
    "        risk_analysis: Dict,\n",
    "        nearby_centers: List[Dict],\n",
    "        emotion_result: Dict,\n",
    "    ) -> str:\n",
    "        \"\"\"🆕 위기 상황 안전 응답 생성\"\"\"\n",
    "\n",
    "        # 기본 공감 메시지\n",
    "        crisis_message = f\"💙 {risk_analysis.get('risk_message', '많이 힘드시군요. 혼자가 아니에요.')}\\n\\n\"\n",
    "\n",
    "        # 근처 센터 정보 추가\n",
    "        if nearby_centers:\n",
    "            crisis_message += \"🏥 **가까운 도움받을 곳:**\\n\"\n",
    "            for i, center in enumerate(nearby_centers[:2], 1):\n",
    "                crisis_message += f\"{i}. {center['name']}\\n\"\n",
    "                crisis_message += f\"   📞 {center['phone']}\\n\"\n",
    "                if \"distance\" in center:\n",
    "                    crisis_message += f\"   🚗 거리: {center['distance']}km\\n\"\n",
    "                crisis_message += \"\\n\"\n",
    "\n",
    "        # 응급 연락처\n",
    "        crisis_message += \"\"\"🚨 **즉시 도움이 필요하다면:**\n",
    "• 응급상황: 112\n",
    "• 청소년전화: 1388 (24시간)\n",
    "• 자살예방상담: 1393\n",
    "• 위기상담: 1577-0199\n",
    "\n",
    "혼자가 아니라는 걸 기억해주세요. 💙\"\"\"\n",
    "\n",
    "        return crisis_message\n",
    "\n",
    "    def _generate_safe_response(\n",
    "        self, text: str, emotion_result: Dict, youth_analysis: Dict\n",
    "    ) -> str:\n",
    "        \"\"\"개선된 일반 상황 안전 응답 생성\"\"\"\n",
    "\n",
    "        # 감정 결과 확인\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        confidence = emotion_result[\"final\"][\"confidence\"]\n",
    "\n",
    "        # 긍정적 감정일 때\n",
    "        if emotion in [\"기쁨\", \"일반대화\"] and confidence > 0.6:\n",
    "            if youth_analysis.get(\"language_style\") == \"youth_casual\":\n",
    "                response_start = \"오늘 기분 좋으시다니 완전 좋네요! 😊 \"\n",
    "            else:\n",
    "                response_start = \"기분이 좋으시다니 정말 다행이에요! 😊 \"\n",
    "        else:\n",
    "            # 기존 로직\n",
    "            if youth_analysis.get(\"language_style\") == \"youth_casual\":\n",
    "                response_start = \"그런 마음 완전 이해해💙 \"\n",
    "            else:\n",
    "                response_start = \"힘든 마음을 말씀해주셨군요. \"\n",
    "\n",
    "        # 기존 generate_response 호출하되 앞에 친화적 메시지 추가\n",
    "        base_response = self.generate_response(text)\n",
    "\n",
    "        return response_start + base_response\n",
    "\n",
    "    def _log_risk_situation_safe(\n",
    "        self, text: str, risk_analysis: Dict, location_result: Dict, user_id: str\n",
    "    ):\n",
    "        \"\"\"🆕 위험 상황 안전 로깅\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"user_id\": user_id,\n",
    "            \"risk_level\": risk_analysis[\"risk_level\"],\n",
    "            \"detected_keywords\": [\n",
    "                r[\"keyword\"] for r in risk_analysis.get(\"detected_risks\", [])\n",
    "            ],\n",
    "            \"has_location\": location_result.get(\"coordinates\") is not None,\n",
    "            \"intervention_provided\": True,\n",
    "        }\n",
    "\n",
    "        self.risk_log.append(log_entry)\n",
    "\n",
    "        # 로그가 너무 길어지면 정리 (최근 50개만 유지)\n",
    "        if len(self.risk_log) > 100:\n",
    "            self.risk_log = self.risk_log[-50:]\n",
    "\n",
    "    def _check_emotion_risk_consistency(\n",
    "        self, emotion_result: Dict, risk_analysis: Dict\n",
    "    ) -> Dict:\n",
    "        \"\"\"감정과 위험도의 일관성 체크\"\"\"\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        risk_level = risk_analysis[\"risk_level\"]\n",
    "        has_positive_context = risk_analysis.get(\"has_positive_context\", False)\n",
    "\n",
    "        # 일관성 점수 계산\n",
    "        consistency_score = 1.0\n",
    "        warnings = []\n",
    "\n",
    "        # 긍정적 감정 + 높은 위험도 = 비일관적\n",
    "        if emotion in [\"기쁨\", \"일반대화\"] and risk_level in [\"high\", \"critical\"]:\n",
    "            if not has_positive_context:\n",
    "                consistency_score -= 0.5\n",
    "                warnings.append(\"긍정적 감정과 높은 위험도 불일치\")\n",
    "\n",
    "        return {\n",
    "            \"consistency_score\": max(0.0, min(1.0, consistency_score)),\n",
    "            \"warnings\": warnings,\n",
    "        }\n",
    "\n",
    "    def _adjust_final_risk_level(\n",
    "        self, risk_analysis: Dict, emotion_result: Dict, consistency: Dict\n",
    "    ) -> Dict:\n",
    "        \"\"\"최종 위험도 조정\"\"\"\n",
    "        base_risk = risk_analysis[\"risk_level\"]\n",
    "        emotion = emotion_result[\"final\"][\"prediction\"]\n",
    "        confidence = emotion_result[\"final\"][\"confidence\"]\n",
    "\n",
    "        # 일관성이 낮으면 위험도 재평가\n",
    "        if consistency[\"consistency_score\"] < 0.5:\n",
    "            # 긍정적 감정이 확실하면 위험도 낮춤\n",
    "            if emotion in [\"기쁨\", \"일반대화\"] and confidence > 0.7:\n",
    "                if base_risk == \"high\":\n",
    "                    base_risk = \"medium\"\n",
    "                elif base_risk == \"medium\":\n",
    "                    base_risk = \"low\"\n",
    "\n",
    "        return {\n",
    "            \"risk_level\": base_risk,\n",
    "            \"requires_intervention\": base_risk in [\"critical\", \"high\"],\n",
    "            \"adjustment_reason\": f\"감정 일관성 고려\",\n",
    "            \"original_risk\": risk_analysis[\"risk_level\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804155b",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8f9f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SupportCenter:\n",
    "    \"\"\"지원센터 정보\"\"\"\n",
    "\n",
    "    region: str\n",
    "    name: str\n",
    "    address: str\n",
    "    phone: str\n",
    "    website: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    center_type: str\n",
    "\n",
    "\n",
    "class RiskKeywordDetector:\n",
    "    \"\"\"개선된 위험 키워드 감지기\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # 위험 키워드를 더 정확하게 정의\n",
    "        self.risk_patterns = {\n",
    "            \"critical\": {\n",
    "                \"patterns\": [\n",
    "                    r\"죽고\\s*싶\",\n",
    "                    r\"자살\",\n",
    "                    r\"자해\",\n",
    "                    r\"사라지고\\s*싶\",\n",
    "                    r\"죽어야지\",\n",
    "                    r\"죽을래\",\n",
    "                    r\"죽었으면\",\n",
    "                ],\n",
    "                \"exclusions\": [],\n",
    "            },\n",
    "            \"high\": {\n",
    "                \"patterns\": [\n",
    "                    r\"가출하고\\s*싶\",\n",
    "                    r\"집에\\s*안\\s*가고\\s*싶\",\n",
    "                    r\"때리고\\s*싶\",\n",
    "                    r\"부모\\s*때리\",\n",
    "                    r\"선생님\\s*때리\",\n",
    "                ],\n",
    "                \"exclusions\": [r\"기분\\s*좋\", r\"행복\", r\"즐거\"],\n",
    "            },\n",
    "            \"medium\": {\n",
    "                \"patterns\": [\n",
    "                    r\"너무\\s*우울\",\n",
    "                    r\"심한\\s*불안\",\n",
    "                    r\"많이\\s*힘들\",\n",
    "                    r\"극심한\\s*스트레스\",\n",
    "                    r\"견딜\\s*수\\s*없\",\n",
    "                ],\n",
    "                \"exclusions\": [r\"기분\\s*좋\", r\"괜찮\", r\"좋아\", r\"행복\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # 긍정적 맥락 키워드\n",
    "        self.positive_context = [\n",
    "            r\"기분\\s*좋\",\n",
    "            r\"행복\",\n",
    "            r\"즐거\",\n",
    "            r\"괜찮\",\n",
    "            r\"좋아\",\n",
    "            r\"재밌\",\n",
    "            r\"신나\",\n",
    "            r\"웃\",\n",
    "            r\"밝\",\n",
    "            r\"희망\",\n",
    "        ]\n",
    "\n",
    "    def detect_risk(self, text: str) -> dict:\n",
    "        \"\"\"개선된 위험도 감지\"\"\"\n",
    "        text_processed = text.lower().strip()\n",
    "        detected_risks = []\n",
    "        max_risk_level = \"low\"\n",
    "\n",
    "        # 1. 긍정적 맥락 체크\n",
    "        has_positive_context = self._check_positive_context(text_processed)\n",
    "\n",
    "        # 2. 각 위험 레벨별로 패턴 매칭\n",
    "        for level, patterns_data in self.risk_patterns.items():\n",
    "            patterns = patterns_data[\"patterns\"]\n",
    "            exclusions = patterns_data[\"exclusions\"]\n",
    "\n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, text_processed)\n",
    "                if matches:\n",
    "                    # 제외 패턴 체크\n",
    "                    is_excluded = False\n",
    "                    for exclusion in exclusions:\n",
    "                        if re.search(exclusion, text_processed):\n",
    "                            is_excluded = True\n",
    "                            break\n",
    "\n",
    "                    # 긍정적 맥락이 있으면 위험도 낮춤\n",
    "                    if has_positive_context and level in [\"medium\", \"high\"]:\n",
    "                        is_excluded = True\n",
    "\n",
    "                    if not is_excluded:\n",
    "                        detected_risks.append(\n",
    "                            {\"keyword\": matches[0], \"category\": level}\n",
    "                        )\n",
    "\n",
    "                        if self._is_higher_risk(level, max_risk_level):\n",
    "                            max_risk_level = level\n",
    "\n",
    "        # 3. 최종 위험도 조정\n",
    "        final_risk_level = self._finalize_risk_level(\n",
    "            max_risk_level, has_positive_context\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"risk_level\": final_risk_level,\n",
    "            \"detected_risks\": detected_risks,\n",
    "            \"requires_intervention\": final_risk_level in [\"critical\", \"high\"],\n",
    "            \"has_positive_context\": has_positive_context,\n",
    "            \"risk_message\": self._get_risk_message(final_risk_level),\n",
    "            \"timestamp\": datetime.now(),\n",
    "        }\n",
    "\n",
    "    def _check_positive_context(self, text: str) -> bool:\n",
    "        \"\"\"긍정적 맥락 체크\"\"\"\n",
    "        for pattern in self.positive_context:\n",
    "            if re.search(pattern, text):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _is_higher_risk(self, level1: str, level2: str) -> bool:\n",
    "        \"\"\"위험도 비교\"\"\"\n",
    "        risk_order = {\"low\": 0, \"medium\": 1, \"high\": 2, \"critical\": 3}\n",
    "        return risk_order.get(level1, 0) > risk_order.get(level2, 0)\n",
    "\n",
    "    def _finalize_risk_level(self, max_risk: str, has_positive: bool) -> str:\n",
    "        \"\"\"최종 위험도 결정\"\"\"\n",
    "        # 긍정적 맥락이 있으면 위험도 낮춤\n",
    "        if has_positive and max_risk in [\"medium\", \"high\"]:\n",
    "            return \"low\"\n",
    "\n",
    "        # critical은 항상 유지 (생명과 직결)\n",
    "        if max_risk == \"critical\":\n",
    "            return \"critical\"\n",
    "\n",
    "        return max_risk\n",
    "\n",
    "    def _get_risk_message(self, risk_level: str) -> str:\n",
    "        \"\"\"위험도별 메시지\"\"\"\n",
    "        messages = {\n",
    "            \"critical\": \"정말 힘든 상황이시군요. 혼자 견디지 마시고 즉시 도움을 받으세요.\",\n",
    "            \"high\": \"어려운 상황에 계시는 것 같아요. 전문가의 도움을 받아보시는 건 어떨까요?\",\n",
    "            \"medium\": \"스트레스가 있으시군요. 마음을 돌볼 필요가 있을 것 같아요.\",\n",
    "            \"low\": \"괜찮으시다니 다행이에요. 좋은 하루 되세요!\",\n",
    "        }\n",
    "        return messages.get(risk_level, \"안녕하세요.\")\n",
    "\n",
    "\n",
    "class LocationBasedCenterMatcher:\n",
    "    \"\"\"위치 기반 센터 매칭 (간단 버전)\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str = None):\n",
    "        if csv_path and os.path.exists(csv_path):\n",
    "            self.centers = self._load_from_csv(csv_path)\n",
    "        else:\n",
    "            self.centers = self._load_default_centers()\n",
    "\n",
    "        # 주요 도시 좌표\n",
    "        self.city_coords = {\n",
    "            \"강릉\": (37.7519, 128.8761),\n",
    "            \"원주\": (37.3422, 127.9202),\n",
    "            \"춘천\": (37.8813, 127.7298),\n",
    "            \"창원\": (35.2281, 128.6811),\n",
    "            \"김해\": (35.2281, 128.8890),\n",
    "            \"진주\": (35.1742, 128.0959),\n",
    "        }\n",
    "\n",
    "    def _load_from_csv(self, csv_path: str):\n",
    "        \"\"\"CSV에서 센터 정보 로드\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "            centers = []\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                if pd.notna(row.get(\"센터명\")) and pd.notna(row.get(\"전화번호\")):\n",
    "                    center = SupportCenter(\n",
    "                        region=str(row.get(\"시도명\", \"N/A\")),\n",
    "                        name=str(row.get(\"센터명\")),\n",
    "                        address=str(row.get(\"소재지\", \"N/A\")),\n",
    "                        phone=str(row.get(\"전화번호\")),\n",
    "                        website=str(row.get(\"홈페이지\", \"\")),\n",
    "                        latitude=float(row.get(\"위도\", 0.0)),\n",
    "                        longitude=float(row.get(\"경도\", 0.0)),\n",
    "                        center_type=str(row.get(\"유형\", \"지원센터\")),\n",
    "                    )\n",
    "                    if center.latitude != 0.0 and center.longitude != 0.0:\n",
    "                        centers.append(center)\n",
    "\n",
    "            print(f\"✅ CSV에서 {len(centers)}개 센터 로드\")\n",
    "            return centers\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ CSV 로드 실패: {e}\")\n",
    "            return self._load_default_centers()\n",
    "\n",
    "    def _load_default_centers(self):\n",
    "        \"\"\"기본 센터 데이터\"\"\"\n",
    "        default_data = [\n",
    "            {\n",
    "                \"region\": \"강원\",\n",
    "                \"name\": \"강릉중독관리통합지원센터\",\n",
    "                \"address\": \"강릉시 경강로 2279\",\n",
    "                \"phone\": \"033-653-9668\",\n",
    "                \"website\": \"https://gnamc.or.kr/\",\n",
    "                \"latitude\": 37.7667,\n",
    "                \"longitude\": 128.9110,\n",
    "                \"center_type\": \"중독관리센터\",\n",
    "            },\n",
    "            {\n",
    "                \"region\": \"강원\",\n",
    "                \"name\": \"원주시중독관리통합지원센터\",\n",
    "                \"address\": \"원주시 원일로 139\",\n",
    "                \"phone\": \"033-748-5119\",\n",
    "                \"website\": \"http://alja.yonsei.ac.kr\",\n",
    "                \"latitude\": 37.3515,\n",
    "                \"longitude\": 127.9468,\n",
    "                \"center_type\": \"중독관리센터\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        return [SupportCenter(**data) for data in default_data]\n",
    "\n",
    "    def find_nearest_centers(\n",
    "        self,\n",
    "        user_coords: Tuple[float, float],\n",
    "        max_distance: float = 50.0,\n",
    "        limit: int = 3,\n",
    "    ):\n",
    "        \"\"\"가장 가까운 센터 찾기\"\"\"\n",
    "        if not user_coords:\n",
    "            return []\n",
    "\n",
    "        center_distances = []\n",
    "\n",
    "        for center in self.centers:\n",
    "            try:\n",
    "                distance = geodesic(\n",
    "                    user_coords, (center.latitude, center.longitude)\n",
    "                ).kilometers\n",
    "\n",
    "                if distance <= max_distance:\n",
    "                    center_info = {\n",
    "                        \"name\": center.name,\n",
    "                        \"phone\": center.phone,\n",
    "                        \"address\": center.address,\n",
    "                        \"distance\": round(distance, 1),\n",
    "                        \"center_type\": center.center_type,\n",
    "                    }\n",
    "                    center_distances.append(center_info)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # 거리순 정렬\n",
    "        center_distances.sort(key=lambda x: x[\"distance\"])\n",
    "        return center_distances[:limit]\n",
    "\n",
    "    def get_location_from_text(self, text: str) -> Optional[Tuple[float, float]]:\n",
    "        \"\"\"텍스트에서 위치 추출\"\"\"\n",
    "        for city, coords in self.city_coords.items():\n",
    "            if city in text:\n",
    "                return coords\n",
    "        return None\n",
    "\n",
    "\n",
    "class LocationHandler:\n",
    "    \"\"\"위치 정보 처리\"\"\"\n",
    "\n",
    "    def __init__(self, center_matcher):\n",
    "        self.center_matcher = center_matcher\n",
    "        self.location_cache = {}\n",
    "\n",
    "    def process_user_location(\n",
    "        self,\n",
    "        user_id: str,\n",
    "        latitude: float = None,\n",
    "        longitude: float = None,\n",
    "        location_text: str = None,\n",
    "    ):\n",
    "        \"\"\"사용자 위치 처리\"\"\"\n",
    "\n",
    "        # GPS 좌표가 있으면 우선 사용\n",
    "        if latitude and longitude:\n",
    "            coords = (latitude, longitude)\n",
    "            return {\n",
    "                \"coordinates\": coords,\n",
    "                \"location_source\": \"gps\",\n",
    "                \"location_accuracy\": \"high\",\n",
    "            }\n",
    "\n",
    "        # 텍스트에서 위치 추출\n",
    "        if location_text:\n",
    "            coords = self.center_matcher.get_location_from_text(location_text)\n",
    "            if coords:\n",
    "                return {\n",
    "                    \"coordinates\": coords,\n",
    "                    \"location_source\": \"text\",\n",
    "                    \"location_accuracy\": \"medium\",\n",
    "                }\n",
    "\n",
    "        # 위치 정보 없음\n",
    "        return {\n",
    "            \"coordinates\": None,\n",
    "            \"location_source\": None,\n",
    "            \"location_accuracy\": \"none\",\n",
    "            \"needs_location_request\": True,\n",
    "        }\n",
    "\n",
    "\n",
    "class YouthLanguageProcessor:\n",
    "    \"\"\"청소년 언어 처리\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.youth_slang = {\n",
    "            \"멘붕\": \"멘탈 붕괴\",\n",
    "            \"빡쳐\": \"화나\",\n",
    "            \"레알\": \"진짜\",\n",
    "            \"대박\": \"놀라워\",\n",
    "        }\n",
    "\n",
    "    def process_youth_message(self, text: str):\n",
    "        \"\"\"청소년 메시지 분석\"\"\"\n",
    "        detected_slang = []\n",
    "\n",
    "        for slang, meaning in self.youth_slang.items():\n",
    "            if slang in text:\n",
    "                detected_slang.append({\"slang\": slang, \"meaning\": meaning})\n",
    "\n",
    "        # 언어 스타일 판단\n",
    "        if detected_slang or any(char in text for char in [\"ㅠㅠ\", \"ㅜㅜ\", \"ㅋㅋ\"]):\n",
    "            language_style = \"youth_casual\"\n",
    "        else:\n",
    "            language_style = \"formal\"\n",
    "\n",
    "        return {\n",
    "            \"detected_slang\": detected_slang,\n",
    "            \"language_style\": language_style,\n",
    "            \"emotion_intensity\": (\n",
    "                \"high\" if \"너무\" in text or \"진짜\" in text else \"medium\"\n",
    "            ),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5824c",
   "metadata": {},
   "source": [
    "## 테스트 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0737e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 EmotionChatbot 테스트 프로그램\n",
      "============================================================\n",
      "\n",
      "실행할 테스트를 선택하세요:\n",
      "1. 전체 테스트\n",
      "2. 기본 대화만\n",
      "3. 감정 응답만\n",
      "4. 위험 상황만\n",
      "5. 메모리 기능만\n",
      "🔧 챗봇 초기화 중...\n",
      "모델 디렉토리: /Users/hwangeunbi/chatnge_AI/chat/model\n",
      "디바이스: mps\n",
      "신뢰도 임계값: 0.6\n",
      "감정 탐지 임계값: 0.3\n",
      "1단계 : 파일 확인\n",
      "✅ level1_best_model.pt 파일이 존재합니다.\n",
      "✅ level2_best_model.pt 파일이 존재합니다.\n",
      "✅ level3_best_model.pt 파일이 존재합니다.\n",
      "✅ level1_label_encoder.pkl 파일이 존재합니다.\n",
      "✅ level2_label_encoder.pkl 파일이 존재합니다.\n",
      "✅ level3_label_encoder.pkl 파일이 존재합니다.\n",
      "2단계: 라벨 인코더 로드\n",
      "level1_label_encoder.pkl 파일에서 level1_encoder 로드 완료\n",
      "level2_label_encoder.pkl 파일에서 level2_encoder 로드 완료\n",
      "level3_label_encoder.pkl 파일에서 level3_encoder 로드 완료\n",
      "3단계: BERT 모델 로드\n",
      "BERT 모델과 토크나이저 로드 완료\n",
      "😊 감정 분류 모델 로드 중...\n",
      "  🔄 level1_best_model.pt 로드 중...\n",
      "  ✅ level1_best_model.pt 로드 완료\n",
      "  🔄 level2_best_model.pt 로드 중...\n",
      "  ✅ level2_best_model.pt 로드 완료\n",
      "  🔄 level3_best_model.pt 로드 중...\n",
      "  ✅ level3_best_model.pt 로드 완료\n",
      "🌟일반대화용 GPT3.5 초기화완료\n",
      "🌟감정대화용 GPT4 초기화완료\n",
      "🌟위험대화용 Cluade 초기화완료\n",
      "공유 메모리 설정 완료\n",
      "공유 메모리 및 기본 체인 설정 완료\n",
      "✅ 청소년 안전 기능 활성화됨\n",
      "✅ 챗봇 초기화 성공!\n",
      "\n",
      "🚨 위험 상황 테스트\n",
      "==================================================\n",
      "\n",
      "👤 사용자: 요즘 너무 힘들어서 죽고 싶어요\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_2862/3263581887.py:410: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.shared_memory = ConversationSummaryBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 AI: 💙 많이 힘드시군요. 혼자가 아니에요.\n",
      "\n",
      "🚨 **즉시 도움이 필요하다면:**\n",
      "• 응급상황: 112\n",
      "• 청소년전화: 1388 (24시간)\n",
      "• 자살예방상담: 1393\n",
      "• 위기상담: 1577-0199\n",
      "\n",
      "혼자가 아니라는 걸 기억해주세요. 💙\n",
      "⚠️ 위험도: critical\n",
      "🏥 즉시 도움 필요: True\n",
      "\n",
      "👤 사용자: 아무도 날 이해해주지 않아... 혼자 있고 싶어\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 AI: 힘든 마음을 말씀해주셨군요. 그렇게 느끼고 있다니 정말 힘들겠어요. 아무도 당신을 이해해주지 않는다고 느낄 때, 그 외로움과 상처가 얼마나 깊을지 상상할 수 있어요. 지금 어떤 상황이나 감정이 이런 생각을 하게 만들었을까요? 혼자 있고 싶다는 마음이 들 때, 그 공간에서 어떤 것들을 느끼고 싶은지 궁금해요. 당신의 감정을 이렇게 솔직하게 표현해줘서 고마워요.\n",
      "⚠️ 위험도: low\n",
      "🏥 즉시 도움 필요: False\n",
      "\n",
      "👤 사용자: 모든 게 의미없어 보여요\n",
      "🤖 AI: 힘든 마음을 말씀해주셨군요. 모든 것이 의미 없어 보인다고 느낄 때, 정말 무기력하고 지친 기분일 것 같아요. 그런 감정 속에서 하루하루를 보내는 게 쉽지 않을 거예요. 혹시 최근에 이런 감정을 더 강하게 느끼게 된 어떤 사건이나 변화가 있었을까요? 또는, 예전에는 의미가 있었던 것들이 지금은 왜 그렇게 느껴지는지 생각해본 적 있나요? 당신의 이야기를 듣고 싶어요. 함께 이 감정을 조금씩 풀어가 봐요.\n",
      "⚠️ 위험도: low\n",
      "🏥 즉시 도움 필요: False\n",
      "\n",
      "👤 사용자: 자해하고 싶은 충동이 들어요\n",
      "🤖 AI: 💙 많이 힘드시군요. 혼자가 아니에요.\n",
      "\n",
      "🚨 **즉시 도움이 필요하다면:**\n",
      "• 응급상황: 112\n",
      "• 청소년전화: 1388 (24시간)\n",
      "• 자살예방상담: 1393\n",
      "• 위기상담: 1577-0199\n",
      "\n",
      "혼자가 아니라는 걸 기억해주세요. 💙\n",
      "⚠️ 위험도: critical\n",
      "🏥 즉시 도움 필요: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "\n",
    "class EmotionChatbotTester:\n",
    "    def __init__(self):\n",
    "        self.test_results = []\n",
    "        self.chatbot = None\n",
    "\n",
    "    def setup_chatbot(self):\n",
    "        \"\"\"챗봇 초기화 테스트\"\"\"\n",
    "        print(\"🔧 챗봇 초기화 중...\")\n",
    "        try:\n",
    "            self.chatbot = EmotionChatbot(\n",
    "                model_dir=\"/Users/hwangeunbi/chatnge_AI/chat/model\",\n",
    "                confidence_threshold=0.6,\n",
    "                emotion_threshold=0.3,\n",
    "                enable_safety_features=True,\n",
    "            )\n",
    "            print(\"✅ 챗봇 초기화 성공!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 챗봇 초기화 실패: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "    def test_basic_conversation(self):\n",
    "        \"\"\"기본 대화 테스트\"\"\"\n",
    "        print(\"\\n📝 기본 대화 테스트\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        test_messages = [\n",
    "            \"안녕하세요!\",\n",
    "            \"오늘 날씨가 좋네요\",\n",
    "            \"점심 뭐 먹을까요?\",\n",
    "            \"주말에 영화 보려고 해요\",\n",
    "        ]\n",
    "\n",
    "        for msg in test_messages:\n",
    "            try:\n",
    "                print(f\"\\n👤 사용자: {msg}\")\n",
    "\n",
    "                # 스마트 응답 테스트\n",
    "                if hasattr(self.chatbot, \"generate_smart_response\"):\n",
    "                    result = self.chatbot.generate_smart_response(msg)\n",
    "                    print(f\"🤖 AI ({result['model_used']}): {result['ai_response']}\")\n",
    "\n",
    "                    if \"emotion_analysis\" in result:\n",
    "                        emotion = result[\"emotion_analysis\"][\"final\"][\"prediction\"]\n",
    "                        confidence = result[\"emotion_analysis\"][\"final\"][\"confidence\"]\n",
    "                        print(f\"📊 감정: {emotion} (신뢰도: {confidence:.2f})\")\n",
    "                else:\n",
    "                    # 기본 응답 테스트\n",
    "                    response = self.chatbot.generate_response(msg)\n",
    "                    print(f\"🤖 AI: {response}\")\n",
    "\n",
    "                time.sleep(1)  # API 호출 간격\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 오류: {e}\")\n",
    "\n",
    "    def test_emotion_responses(self):\n",
    "        \"\"\"감정 응답 테스트\"\"\"\n",
    "        print(\"\\n💭 감정 응답 테스트\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        emotion_messages = [\n",
    "            \"오늘 정말 우울해요...\",\n",
    "            \"시험에서 떨어져서 너무 속상해요\",\n",
    "            \"친구와 싸워서 화가 나요\",\n",
    "            \"취업이 안되서 불안해요\",\n",
    "            \"연인과 헤어져서 슬퍼요\",\n",
    "        ]\n",
    "\n",
    "        for msg in emotion_messages:\n",
    "            try:\n",
    "                print(f\"\\n👤 사용자: {msg}\")\n",
    "\n",
    "                if hasattr(self.chatbot, \"generate_smart_response\"):\n",
    "                    result = self.chatbot.generate_smart_response(msg)\n",
    "                    print(f\"🤖 AI ({result['model_used']}): {result['ai_response']}\")\n",
    "\n",
    "                    emotion = result[\"emotion_analysis\"][\"final\"][\"prediction\"]\n",
    "                    confidence = result[\"emotion_analysis\"][\"final\"][\"confidence\"]\n",
    "                    print(f\"📊 감정: {emotion} (신뢰도: {confidence:.2f})\")\n",
    "                else:\n",
    "                    response = self.chatbot.generate_response_with_emotion_detection(\n",
    "                        msg\n",
    "                    )\n",
    "                    print(f\"🤖 AI: {response}\")\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 오류: {e}\")\n",
    "\n",
    "    def test_risk_scenarios(self):\n",
    "        \"\"\"위험 상황 테스트 (안전 기능 활성화 필요)\"\"\"\n",
    "        print(\"\\n🚨 위험 상황 테스트\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        risk_messages = [\n",
    "            \"요즘 너무 힘들어서 죽고 싶어요\",\n",
    "            \"아무도 날 이해해주지 않아... 혼자 있고 싶어\",\n",
    "            \"모든 게 의미없어 보여요\",\n",
    "            \"자해하고 싶은 충동이 들어요\",\n",
    "        ]\n",
    "\n",
    "        for msg in risk_messages:\n",
    "            try:\n",
    "                print(f\"\\n👤 사용자: {msg}\")\n",
    "\n",
    "                if hasattr(self.chatbot, \"process_youth_message\"):\n",
    "                    result = self.chatbot.process_youth_message(\n",
    "                        text=msg,\n",
    "                        user_id=\"test_user\",\n",
    "                        latitude=37.5665,  # 서울 좌표\n",
    "                        longitude=126.9780,\n",
    "                    )\n",
    "\n",
    "                    print(f\"🤖 AI: {result['ai_response']}\")\n",
    "                    print(\n",
    "                        f\"⚠️ 위험도: {result.get('final_risk_analysis', {}).get('risk_level', 'unknown')}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"🏥 즉시 도움 필요: {result.get('requires_immediate_help', False)}\"\n",
    "                    )\n",
    "\n",
    "                    if result.get(\"nearby_centers\"):\n",
    "                        print(f\"🏥 근처 센터: {len(result['nearby_centers'])}개 발견\")\n",
    "                else:\n",
    "                    response = self.chatbot.generate_response(msg)\n",
    "                    print(f\"🤖 AI: {response}\")\n",
    "\n",
    "                time.sleep(2)  # 위험 상황이므로 더 긴 간격\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 오류: {e}\")\n",
    "\n",
    "    def test_memory_functionality(self):\n",
    "        \"\"\"메모리 기능 테스트\"\"\"\n",
    "        print(\"\\n🧠 메모리 기능 테스트\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        conversation_flow = [\n",
    "            \"안녕하세요! 제 이름은 김철수예요.\",\n",
    "            \"저는 대학생이고 컴퓨터공학과에 다녀요.\",\n",
    "            \"제 이름이 뭐였죠?\",\n",
    "            \"제가 어떤 전공이라고 했죠?\",\n",
    "        ]\n",
    "\n",
    "        for msg in conversation_flow:\n",
    "            try:\n",
    "                print(f\"\\n👤 사용자: {msg}\")\n",
    "\n",
    "                response = self.chatbot.generate_response(msg)\n",
    "                print(f\"🤖 AI: {response}\")\n",
    "\n",
    "                # 메모리 상태 확인\n",
    "                if hasattr(self.chatbot, \"get_memory_status\"):\n",
    "                    memory_status = self.chatbot.get_memory_status()\n",
    "                    print(\n",
    "                        f\"💭 메모리: {memory_status.get('message_count', 0)}개 메시지\"\n",
    "                    )\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 오류: {e}\")\n",
    "\n",
    "    def test_model_selection(self):\n",
    "        \"\"\"모델 선택 로직 테스트\"\"\"\n",
    "        print(\"\\n🤖 모델 선택 로직 테스트\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        test_scenarios = [\n",
    "            (\"일반대화\", \"오늘 점심 뭐 먹을까요?\"),\n",
    "            (\"감정상담\", \"요즘 스트레스가 너무 심해요\"),\n",
    "            (\"위험상황\", \"삶이 너무 힘들어서 포기하고 싶어요\"),\n",
    "        ]\n",
    "\n",
    "        for scenario_type, msg in test_scenarios:\n",
    "            try:\n",
    "                print(f\"\\n📋 시나리오: {scenario_type}\")\n",
    "                print(f\"👤 사용자: {msg}\")\n",
    "\n",
    "                if hasattr(self.chatbot, \"_choose_model\"):\n",
    "                    model, emotion_result, risk_analysis = self.chatbot._choose_model(\n",
    "                        msg\n",
    "                    )\n",
    "                    print(f\"🎯 선택된 모델: {model}\")\n",
    "                    print(f\"📊 감정: {emotion_result['final']['prediction']}\")\n",
    "                    if risk_analysis:\n",
    "                        print(f\"⚠️ 위험도: {risk_analysis.get('risk_level', 'N/A')}\")\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 오류: {e}\")\n",
    "\n",
    "    def test_threshold_adjustment(self):\n",
    "        \"\"\"임계값 조정 테스트\"\"\"\n",
    "        print(\"\\n⚙️ 임계값 조정 테스트\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        try:\n",
    "            # 현재 임계값 확인\n",
    "            if hasattr(self.chatbot, \"get_thresholds\"):\n",
    "                current = self.chatbot.get_thresholds()\n",
    "                print(f\"현재 임계값: {current}\")\n",
    "\n",
    "            # 임계값 변경\n",
    "            if hasattr(self.chatbot, \"set_thresholds\"):\n",
    "                self.chatbot.set_thresholds(\n",
    "                    confidence_threshold=0.8, emotion_threshold=0.4\n",
    "                )\n",
    "                print(\"임계값 변경 완료\")\n",
    "\n",
    "                # 변경된 임계값 확인\n",
    "                new_thresholds = self.chatbot.get_thresholds()\n",
    "                print(f\"새 임계값: {new_thresholds}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류: {e}\")\n",
    "\n",
    "    def test_conversation_summary(self):\n",
    "        \"\"\"대화 요약 테스트\"\"\"\n",
    "        print(\"\\n📄 대화 요약 테스트\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        try:\n",
    "            # 대화 기록 확인\n",
    "            if hasattr(self.chatbot, \"get_chat_history\"):\n",
    "                history = self.chatbot.get_chat_history()\n",
    "                print(f\"📝 대화 기록: {len(history)}개 메시지\")\n",
    "\n",
    "            # 대화 요약 생성\n",
    "            if hasattr(self.chatbot, \"get_conversation_summary\"):\n",
    "                summary = self.chatbot.get_conversation_summary()\n",
    "                print(f\"📋 대화 요약:\\n{summary}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류: {e}\")\n",
    "\n",
    "    def run_all_tests(self):\n",
    "        \"\"\"모든 테스트 실행\"\"\"\n",
    "        print(\"🧪 EmotionChatbot 종합 테스트 시작\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 챗봇 초기화\n",
    "        if not self.setup_chatbot():\n",
    "            print(\"❌ 챗봇 초기화 실패로 테스트 중단\")\n",
    "            return\n",
    "\n",
    "        tests = [\n",
    "            (\"기본 대화\", self.test_basic_conversation),\n",
    "            (\"감정 응답\", self.test_emotion_responses),\n",
    "            (\"메모리 기능\", self.test_memory_functionality),\n",
    "            (\"모델 선택\", self.test_model_selection),\n",
    "            (\"임계값 조정\", self.test_threshold_adjustment),\n",
    "            (\"대화 요약\", self.test_conversation_summary),\n",
    "            (\"위험 상황\", self.test_risk_scenarios),  # 마지막에 실행 (민감한 내용)\n",
    "        ]\n",
    "\n",
    "        for test_name, test_func in tests:\n",
    "            try:\n",
    "                print(f\"\\n🧪 {test_name} 테스트 시작...\")\n",
    "                test_func()\n",
    "                print(f\"✅ {test_name} 테스트 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {test_name} 테스트 실패: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "            time.sleep(2)  # 테스트 간 휴식\n",
    "\n",
    "        print(\"\\n🎉 모든 테스트 완료!\")\n",
    "\n",
    "        # 메모리 정리\n",
    "        if hasattr(self.chatbot, \"clear_memory\"):\n",
    "            self.chatbot.clear_memory()\n",
    "            print(\"🧹 메모리 정리 완료\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"🚀 EmotionChatbot 테스트 프로그램\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # API 키 확인\n",
    "    if (\n",
    "        not os.getenv(\"OPENAI_API_KEY\")\n",
    "        or os.getenv(\"OPENAI_API_KEY\") == \"your-openai-api-key-here\"\n",
    "    ):\n",
    "        print(\"⚠️ OPENAI_API_KEY 환경변수를 설정해주세요!\")\n",
    "        print(\"export OPENAI_API_KEY='your-actual-api-key'\")\n",
    "\n",
    "    if (\n",
    "        not os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        or os.getenv(\"ANTHROPIC_API_KEY\") == \"your-anthropic-api-key-here\"\n",
    "    ):\n",
    "        print(\"⚠️ ANTHROPIC_API_KEY 환경변수를 설정해주세요!\")\n",
    "        print(\"export ANTHROPIC_API_KEY='your-actual-api-key'\")\n",
    "\n",
    "    print(\"\\n실행할 테스트를 선택하세요:\")\n",
    "\n",
    "    print(\"1. 전체 테스트\")\n",
    "    print(\"2. 기본 대화만\")\n",
    "    print(\"3. 감정 응답만\")\n",
    "    print(\"4. 위험 상황만\")\n",
    "    print(\"5. 메모리 기능만\")\n",
    "\n",
    "    try:\n",
    "        choice = input(\"\\n선택 (1-5): \").strip()\n",
    "\n",
    "        tester = EmotionChatbotTester()\n",
    "\n",
    "        if choice == \"1\":\n",
    "            tester.run_all_tests()\n",
    "        elif choice == \"2\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_basic_conversation()\n",
    "        elif choice == \"3\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_emotion_responses()\n",
    "        elif choice == \"4\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_risk_scenarios()\n",
    "        elif choice == \"5\":\n",
    "            if tester.setup_chatbot():\n",
    "                tester.test_memory_functionality()\n",
    "        else:\n",
    "            print(\"❌ 잘못된 선택입니다.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 테스트가 중단되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 실행 중 오류: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0a13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
