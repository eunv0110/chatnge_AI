# chatbot.py
import os
import yaml
import logging
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from langchain.memory import ConversationSummaryBufferMemory
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from emotion_classifier import HierarchicalEmotionClassifier

load_dotenv()


def setup_logger(name: str, log_level: str = "INFO") -> logging.Logger:
    """ë¡œê±° ì„¤ì • í•¨ìˆ˜"""
    logger = logging.getLogger(name)

    # ì´ë¯¸ í•¸ë“¤ëŸ¬ê°€ ìˆìœ¼ë©´ ì¤‘ë³µ ì„¤ì • ë°©ì§€
    if logger.handlers:
        return logger

    logger.setLevel(getattr(logging, log_level.upper()))

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)

    # íŒŒì¼ í•¸ë“¤ëŸ¬ ì„¤ì •
    file_handler = logging.FileHandler(
        log_dir / f"{name}_{datetime.now().strftime('%Y%m%d')}.log", encoding="utf-8"
    )
    file_handler.setLevel(logging.DEBUG)

    # ì½˜ì†” í•¸ë“¤ëŸ¬ ì„¤ì •
    console_handler = logging.StreamHandler()
    console_handler.setLevel(getattr(logging, log_level.upper()))

    # í¬ë§¤í„° ì„¤ì •
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s"
    )
    file_handler.setFormatter(formatter)

    console_formatter = logging.Formatter("%(levelname)s - %(name)s - %(message)s")
    console_handler.setFormatter(console_formatter)

    # í•¸ë“¤ëŸ¬ ì¶”ê°€
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger


class EmotionChatbot:
    def __init__(
        self,
        model_dir,
        confidence_threshold=0.6,
        emotion_threshold=0.3,
        log_level="INFO",
    ):
        # ë¡œê±° ì´ˆê¸°í™”
        self.logger = setup_logger("EmotionChatbot", log_level)
        self.logger.info("EmotionChatbot ì´ˆê¸°í™” ì‹œì‘")

        try:
            # ê°ì • ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
            self.logger.info(f"ê°ì • ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì‹œì‘ - ëª¨ë¸ ê²½ë¡œ: {model_dir}")
            self.classifier = HierarchicalEmotionClassifier(
                model_dir,
                confidence_threshold=confidence_threshold,
                emotion_threshold=emotion_threshold,
            )
            self.logger.info("ê°ì • ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

            self.confidence_threshold = confidence_threshold
            self.emotion_threshold = emotion_threshold

            # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
            self.logger.info("í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹œì‘")
            self.prompts = self._load_prompts()
            self.logger.info("í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ")

            # LLM ì´ˆê¸°í™”
            self.logger.info("LLM ì´ˆê¸°í™” ì‹œì‘")
            self.llms = self._initialize_llms()
            self.logger.info(
                f"LLM ì´ˆê¸°í™” ì™„ë£Œ - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(self.llms.keys())}"
            )

            # ë©”ëª¨ë¦¬ ì„¤ì •
            self.logger.info("ë©”ëª¨ë¦¬ ë° ì²´ì¸ ì„¤ì • ì‹œì‘")
            self._setup_memory_and_chains()
            self.logger.info("ë©”ëª¨ë¦¬ ë° ì²´ì¸ ì„¤ì • ì™„ë£Œ")

            self.logger.info("EmotionChatbot ì´ˆê¸°í™” ì„±ê³µ")

        except Exception as e:
            self.logger.error(f"EmotionChatbot ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
            raise

    def _load_prompts(self):
        """YAML íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë¡œë“œ"""
        prompts = {}

        prompt_files = {
            "basic_system": "prompts/basic_system.yaml",
            "general_conversation": "prompts/general_conversation.yaml",
        }

        for prompt_name, file_path in prompt_files.items():
            try:
                if os.path.exists(file_path):
                    self.logger.debug(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì‹œë„: {file_path}")
                    with open(file_path, "r", encoding="utf-8") as f:
                        data = yaml.safe_load(f)
                        if isinstance(data, dict) and "template" in data:
                            prompts[prompt_name] = data["template"]
                        elif isinstance(data, str):
                            prompts[prompt_name] = data
                        self.logger.info(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì„±ê³µ: {prompt_name}")
                else:
                    self.logger.warning(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©: {file_path}")
                    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •
                    if prompt_name == "basic_system":
                        prompts[prompt_name] = (
                            "ë‹¹ì‹ ì€ ê³µê°ì ì´ê³  ë”°ëœ»í•œ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê°ì •ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”."
                        )
                    elif prompt_name == "general_conversation":
                        prompts[prompt_name] = (
                            "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì¹œêµ¬ì…ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì–´ì£¼ì„¸ìš”."
                        )
            except Exception as e:
                self.logger.error(f"{file_path} ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                # ê¸°ë³¸ê°’ ì„¤ì •
                if prompt_name == "basic_system":
                    prompts[prompt_name] = "ë‹¹ì‹ ì€ ê³µê°ì ì´ê³  ë”°ëœ»í•œ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤."
                elif prompt_name == "general_conversation":
                    prompts[prompt_name] = "ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì¹œêµ¬ì…ë‹ˆë‹¤."

        return prompts

    def _initialize_llms(self):
        """LLM ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        llms = {}

        openai_key = os.getenv("OPENAI_API_KEY")
        anthropic_key = os.getenv("ANTHROPIC_API_KEY")

        self.logger.info(
            f"API í‚¤ í™•ì¸ - OpenAI: {'ì„¤ì •ë¨' if openai_key else 'ì—†ìŒ'}, Anthropic: {'ì„¤ì •ë¨' if anthropic_key else 'ì—†ìŒ'}"
        )

        try:
            if openai_key:
                self.logger.debug("OpenAI ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘")
                # ì¼ë°˜ ëŒ€í™”ìš©
                llms["gpt35"] = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    temperature=0.6,
                    max_tokens=800,
                    api_key=openai_key,
                )

                # ê°ì • ëŒ€í™”ìš©
                llms["gpt4o"] = ChatOpenAI(
                    model="gpt-4o",
                    temperature=0.3,
                    max_tokens=1200,
                    api_key=openai_key,
                )
                self.logger.info("OpenAI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

            if anthropic_key:
                self.logger.debug("Anthropic ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘")
                llms["claude"] = ChatAnthropic(
                    model="claude-3-sonnet-20240229",
                    temperature=0.3,
                    max_tokens=1200,
                    api_key=anthropic_key,
                )
                self.logger.info("Claude ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}", exc_info=True)
            raise

        if not llms:
            error_msg = "ì‚¬ìš© ê°€ëŠ¥í•œ LLMì´ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

        return llms

    def _setup_memory_and_chains(self):
        """ë©”ëª¨ë¦¬ì™€ ì²´ì¸ ì„¤ì •"""
        # ì£¼ìš” ëª¨ë¸ ì„ íƒ
        if "gpt4o" in self.llms:
            primary_llm = self.llms["gpt4o"]
            primary_model_name = "gpt4o"
        elif "claude" in self.llms:
            primary_llm = self.llms["claude"]
            primary_model_name = "claude"
        else:
            primary_llm = list(self.llms.values())[0]
            primary_model_name = list(self.llms.keys())[0]

        self.logger.info(f"ì£¼ìš” LLM ì„ íƒ: {primary_model_name}")
        self.llm = primary_llm

        # ê³µìœ  ë©”ëª¨ë¦¬ ìƒì„±
        try:
            self.shared_memory = ConversationSummaryBufferMemory(
                llm=primary_llm,
                return_messages=True,
                max_token_limit=2000,
                memory_key="chat_history",
            )
            self.logger.debug("ë©”ëª¨ë¦¬ ìƒì„± ì™„ë£Œ")

            # ê¸°ë³¸ ì²´ì¸ ì„¤ì •
            self.system_prompt_text = self.prompts.get("basic_system")
            self.chat_prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", self.system_prompt_text),
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("human", "{message}"),
                ]
            )

            self.chain = self.chat_prompt | self.llm
            self.logger.info("ì²´ì¸ ì„¤ì • ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ë° ì²´ì¸ ì„¤ì • ì˜¤ë¥˜: {e}", exc_info=True)
            raise

    def _choose_model(self, text):
        """í…ìŠ¤íŠ¸ ë¶„ì„ í›„ ì ì ˆí•œ ëª¨ë¸ ì„ íƒ"""
        try:
            self.logger.debug(f"ëª¨ë¸ ì„ íƒì„ ìœ„í•œ ê°ì • ë¶„ì„ ì‹œì‘: {text[:50]}...")
            emotion_result = self.classify_emotion(text)
            emotion = emotion_result["final"]["prediction"]
            confidence = emotion_result["final"]["confidence"]

            self.logger.debug(f"ê°ì • ë¶„ì„ ê²°ê³¼: {emotion} (ì‹ ë¢°ë„: {confidence:.3f})")

            # ì¼ë°˜ëŒ€í™”ë©´ GPT-3.5
            if emotion == "ì¼ë°˜ëŒ€í™”" and confidence > 0.7:
                if "gpt35" in self.llms:
                    self.logger.info(
                        f"GPT-3.5 ì„ íƒ (ì¼ë°˜ëŒ€í™”, ì‹ ë¢°ë„: {confidence:.3f})"
                    )
                    return "gpt35", emotion_result

            # ê°ì •ê´€ë ¨ì´ë©´ GPT-4o ë˜ëŠ” Claude
            if "gpt4o" in self.llms:
                self.logger.info(f"GPT-4o ì„ íƒ (ê°ì • ëŒ€í™”: {emotion})")
                return "gpt4o", emotion_result
            elif "claude" in self.llms:
                self.logger.info(f"Claude ì„ íƒ (ê°ì • ëŒ€í™”: {emotion})")
                return "claude", emotion_result

            # í´ë°±: ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸
            available_model = list(self.llms.keys())[0]
            self.logger.warning(f"í´ë°± ëª¨ë¸ ì‚¬ìš©: {available_model}")
            return available_model, emotion_result

        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ì„ íƒ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            available_model = list(self.llms.keys())[0]
            return available_model, {"error": str(e)}

    def classify_emotion(self, text):
        """ê°ì • ë¶„ë¥˜"""
        try:
            self.logger.debug(f"ê°ì • ë¶„ë¥˜ ì‹œì‘: {text[:100]}...")
            result = self.classifier.predict_hierarchical(text)
            emotion = result["final"]["prediction"]
            confidence = result["final"]["confidence"]
            self.logger.debug(f"ê°ì • ë¶„ë¥˜ ì™„ë£Œ: {emotion} (ì‹ ë¢°ë„: {confidence:.3f})")
            return result
        except Exception as e:
            self.logger.error(f"ê°ì • ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise

    def format_analysis(self, result):
        """ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        try:
            output = f"""
ğŸ“ ì…ë ¥: {result['original_text']}
ğŸ¯ ìµœì¢… ê²°ê³¼: {result['final']['prediction']} (ì‹ ë¢°ë„: {result['final']['confidence']:.4f})
ğŸ“Š ì˜ˆì¸¡ ê²½ë¡œ: {' â†’ '.join(result['path'])}
"""
            return output
        except Exception as e:
            self.logger.error(f"ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
            return "ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨"

    def generate_response(self, text):
        """ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
        try:
            self.logger.debug(f"ê¸°ë³¸ ì‘ë‹µ ìƒì„± ì‹œì‘: {text[:50]}...")

            emotion_result = self.classify_emotion(text)
            emotion_info = f"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}"

            chat_history = self.shared_memory.chat_memory.messages
            self.logger.debug(f"ëŒ€í™” íˆìŠ¤í† ë¦¬ ê¸¸ì´: {len(chat_history)}")

            response = self.chain.invoke(
                {
                    "message": text,
                    "emotion_info": emotion_info,
                    "chat_history": chat_history,
                }
            )

            if hasattr(response, "content"):
                ai_response = response.content
                self.shared_memory.chat_memory.add_user_message(text)
                self.shared_memory.chat_memory.add_ai_message(ai_response)
                self.logger.info("ê¸°ë³¸ ì‘ë‹µ ìƒì„± ì™„ë£Œ")
                return ai_response
            else:
                self.logger.warning("ì‘ë‹µì—ì„œ content ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return "ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        except Exception as e:
            self.logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    def generate_smart_response(self, text):
        """ìƒí™©ì— ë§ëŠ” ëª¨ë¸ë¡œ ìŠ¤ë§ˆíŠ¸ ì‘ë‹µ ìƒì„±"""
        try:
            self.logger.info(f"ìŠ¤ë§ˆíŠ¸ ì‘ë‹µ ìƒì„± ì‹œì‘: {text[:50]}...")

            selected_model, emotion_result = self._choose_model(text)

            chat_history = self.shared_memory.chat_memory.messages
            llm = self.llms[selected_model]

            emotion_info = f"ê°ì •: {emotion_result['final']['prediction']}, ì‹ ë¢°ë„: {emotion_result['final']['confidence']:.2f}"

            # ì¼ë°˜ëŒ€í™”ì¸ê²½ìš° ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            if emotion_result["final"]["prediction"] == "ì¼ë°˜ëŒ€í™”":
                self.logger.debug("ì¼ë°˜ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
                prompt = ChatPromptTemplate.from_messages(
                    [
                        (
                            "system",
                            self.prompts.get(
                                "general_conversation", "ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì¹œêµ¬ì…ë‹ˆë‹¤."
                            ),
                        ),
                        MessagesPlaceholder(variable_name="chat_history"),
                        ("human", "{message}"),
                    ]
                )
            else:
                self.logger.debug("ê°ì • ìƒë‹´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
                prompt = ChatPromptTemplate.from_messages(
                    [
                        ("system", self.system_prompt_text),
                        MessagesPlaceholder(variable_name="chat_history"),
                        ("human", "{message}"),
                    ]
                )

            chain = prompt | llm
            llm_response = chain.invoke(
                {
                    "message": text,
                    "emotion_info": emotion_info,
                    "chat_history": chat_history,
                }
            )

            response = (
                llm_response.content
                if hasattr(llm_response, "content")
                else str(llm_response)
            )

            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
            self.shared_memory.chat_memory.add_user_message(text)
            self.shared_memory.chat_memory.add_ai_message(response)

            self.logger.info(f"ìŠ¤ë§ˆíŠ¸ ì‘ë‹µ ìƒì„± ì™„ë£Œ - ì‚¬ìš© ëª¨ë¸: {selected_model}")

            return {
                "ai_response": response,
                "model_used": selected_model,
                "emotion_analysis": emotion_result,
            }

        except Exception as e:
            self.logger.error(f"ìŠ¤ë§ˆíŠ¸ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}", exc_info=True)
            fallback_model = list(self.llms.keys())[0]
            return {
                "ai_response": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "model_used": fallback_model + " (fallback)",
                "error": str(e),
            }

    def process_message(self, text, include_emotion_analysis=True):
        """ë©”ì‹œì§€ ì „ì²´ ì²˜ë¦¬"""
        try:
            self.logger.info(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘: {text[:50]}...")

            emotion_result = self.classify_emotion(text)

            result = {
                "emotion_result": emotion_result,
            }

            if include_emotion_analysis:
                result["emotion_analysis"] = self.format_analysis(emotion_result)

            ai_response = self.generate_response(text)
            result["ai_response"] = ai_response

            self.logger.info("ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ")
            return result

        except Exception as e:
            self.logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": str(e)}

    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    def get_conversation_summary(self):
        """í˜„ì¬ ëŒ€í™” ìš”ì•½"""
        try:
            self.logger.debug("ëŒ€í™” ìš”ì•½ ìƒì„± ì‹œì‘")
            summary = self.shared_memory.predict_new_summary(
                self.shared_memory.chat_memory.messages, ""
            )
            self.logger.info("ëŒ€í™” ìš”ì•½ ìƒì„± ì™„ë£Œ")
            return summary
        except Exception as e:
            self.logger.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

    def get_chat_history(self):
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        try:
            history = (
                self.shared_memory.chat_memory.messages if self.shared_memory else []
            )
            self.logger.debug(f"ëŒ€í™” ê¸°ë¡ ì¡°íšŒ - ë©”ì‹œì§€ ìˆ˜: {len(history)}")
            return history
        except Exception as e:
            self.logger.error(f"ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def clear_memory(self):
        """ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        try:
            if self.shared_memory:
                self.shared_memory.clear()
                self.logger.info("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì™„ë£Œ")
                print("ğŸ’­ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

    def get_memory_status(self):
        """ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸"""
        try:
            messages = self.shared_memory.chat_memory.messages
            token_count = self.shared_memory.llm.get_num_tokens_from_messages(messages)
            status = {
                "message_count": len(messages),
                "token_count": token_count,
                "max_token_limit": self.shared_memory.max_token_limit,
            }
            self.logger.debug(f"ë©”ëª¨ë¦¬ ìƒíƒœ: {status}")
            return status
        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
